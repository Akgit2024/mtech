{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f036e54-13f6-4a86-944a-85664575bc4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " MULTI SOURCE EVENT RECONSTRUCTION SYSTEM \n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " LOADING DATA FILES\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Found 6 data files in current directory:\n",
      "  ‚Ä¢ CDR-Call-Details.csv (23,215,814 bytes) - CSV\n",
      "  ‚Ä¢ email_data-metadata.json (498 bytes) - JSON\n",
      "  ‚Ä¢ CDR-Call-Details-metadata.json (508 bytes) - JSON\n",
      "  ‚Ä¢ SMS-Data-metadata.json (467 bytes) - JSON\n",
      "  ‚Ä¢ SMS-Data.csv (18,404,963 bytes) - CSV\n",
      "  ‚Ä¢ email_data.csv (37,864,825 bytes) - CSV\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Loading SMS data from SMS-Data.csv...\n",
      "  Detected CSV format with comma delimiter\n",
      "  Found columns: ['Phone Number', 'Contact Name', 'Direction', 'Message', 'Date/Time', 'Category', 'Relationship', 'Read', 'Message_ID']\n",
      "  Processed 10,000 SMS records...\n",
      "  Processed 20,000 SMS records...\n",
      "  Processed 30,000 SMS records...\n",
      "  Processed 40,000 SMS records...\n",
      "  Processed 50,000 SMS records...\n",
      "  Processed 60,000 SMS records...\n",
      "  Processed 70,000 SMS records...\n",
      "  Processed 80,000 SMS records...\n",
      "  Processed 90,000 SMS records...\n",
      "  Processed 100,000 SMS records...\n",
      "  Processed 110,000 SMS records...\n",
      "  Processed 120,000 SMS records...\n",
      "  Processed 130,000 SMS records...\n",
      "  Processed 140,000 SMS records...\n",
      "  Processed 150,000 SMS records...\n",
      "  Processed 160,000 SMS records...\n",
      "  Processed 170,000 SMS records...\n",
      "  Processed 180,000 SMS records...\n",
      " Successfully loaded 185,000 SMS records\n",
      "  Sample SMS: +914156529064 - What time is dinner?...\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Loading call data from CDR-Call-Details.csv...\n",
      "  Detected CDR call details format\n",
      "  Found columns: ['Phone Number', 'Contact Name', 'Call Type', 'Duration (sec)', 'Day Mins', 'Eve Mins', 'Night Mins', 'Intl Mins', 'Day Calls', 'Eve Calls', 'Night Calls', 'Intl Calls', 'Day Charge', 'Eve Charge', 'Night Charge', 'Intl Charge', 'VMail Message', 'Account Length', 'CustServ Calls', 'Churn', 'Date/Time', 'Call_ID', 'Relationship', 'International']\n",
      "  Processed 10,000 call records...\n",
      "  Processed 20,000 call records...\n",
      "  Processed 30,000 call records...\n",
      "  Processed 40,000 call records...\n",
      "  Processed 50,000 call records...\n",
      "  Processed 60,000 call records...\n",
      "  Processed 70,000 call records...\n",
      "  Processed 80,000 call records...\n",
      "  Processed 90,000 call records...\n",
      "  Processed 100,000 call records...\n",
      "  Processed 110,000 call records...\n",
      "  Processed 120,000 call records...\n",
      "  Processed 130,000 call records...\n",
      "  Processed 140,000 call records...\n",
      "  Processed 150,000 call records...\n",
      "  Processed 160,000 call records...\n",
      "  Processed 170,000 call records...\n",
      "  Processed 180,000 call records...\n",
      " Successfully loaded 185,000 call records\n",
      "  Average call duration: 260.6 seconds\n",
      "  Call types: {'MISSED': 37794, 'ANSWERED': 122761, 'LONG_CALL': 18305, 'SHORT_CALL': 6026, 'COMPLAINT': 114}\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Loading email data from email_data.csv...\n",
      "  Detected CSV format with comma delimiter\n",
      "  Found columns: ['From', 'To', 'Date', 'Subject', 'Body', 'Message_ID', 'Thread_ID', 'In_Reply_To', 'Category', 'Contact_Type', 'Direction', 'Has_Attachment', 'Attachment_Type', 'Size_KB', 'Read_Status', 'Labels']\n",
      "  Processed 1,000 email records...\n",
      "  Processed 2,000 email records...\n",
      "  Processed 3,000 email records...\n",
      "  Processed 4,000 email records...\n",
      "  Processed 5,000 email records...\n",
      "  Processed 6,000 email records...\n",
      "  Processed 7,000 email records...\n",
      "  Processed 8,000 email records...\n",
      "  Processed 9,000 email records...\n",
      "  Processed 10,000 email records...\n",
      "  Processed 11,000 email records...\n",
      "  Processed 12,000 email records...\n",
      "  Processed 13,000 email records...\n",
      "  Processed 14,000 email records...\n",
      "  Processed 15,000 email records...\n",
      "  Processed 16,000 email records...\n",
      "  Processed 17,000 email records...\n",
      "  Processed 18,000 email records...\n",
      "  Processed 19,000 email records...\n",
      "  Processed 20,000 email records...\n",
      "  Processed 21,000 email records...\n",
      "  Processed 22,000 email records...\n",
      "  Processed 23,000 email records...\n",
      "  Processed 24,000 email records...\n",
      "  Processed 25,000 email records...\n",
      "  Processed 26,000 email records...\n",
      "  Processed 27,000 email records...\n",
      "  Processed 28,000 email records...\n",
      "  Processed 29,000 email records...\n",
      "  Processed 30,000 email records...\n",
      "  Processed 31,000 email records...\n",
      "  Processed 32,000 email records...\n",
      "  Processed 33,000 email records...\n",
      "  Processed 34,000 email records...\n",
      "  Processed 35,000 email records...\n",
      "  Processed 36,000 email records...\n",
      "  Processed 37,000 email records...\n",
      "  Processed 38,000 email records...\n",
      "  Processed 39,000 email records...\n",
      "  Processed 40,000 email records...\n",
      "  Processed 41,000 email records...\n",
      "  Processed 42,000 email records...\n",
      "  Processed 43,000 email records...\n",
      "  Processed 44,000 email records...\n",
      "  Processed 45,000 email records...\n",
      "  Processed 46,000 email records...\n",
      "  Processed 47,000 email records...\n",
      "  Processed 48,000 email records...\n",
      "  Processed 49,000 email records...\n",
      "  Processed 50,000 email records...\n",
      "  Processed 51,000 email records...\n",
      "  Processed 52,000 email records...\n",
      "  Processed 53,000 email records...\n",
      "  Processed 54,000 email records...\n",
      "  Processed 55,000 email records...\n",
      "  Processed 56,000 email records...\n",
      "  Processed 57,000 email records...\n",
      "  Processed 58,000 email records...\n",
      "  Processed 59,000 email records...\n",
      "  Processed 60,000 email records...\n",
      "  Processed 61,000 email records...\n",
      "  Processed 62,000 email records...\n",
      "  Processed 63,000 email records...\n",
      "  Processed 64,000 email records...\n",
      "  Processed 65,000 email records...\n",
      "  Processed 66,000 email records...\n",
      "  Processed 67,000 email records...\n",
      "  Processed 68,000 email records...\n",
      "  Processed 69,000 email records...\n",
      "  Processed 70,000 email records...\n",
      "  Processed 71,000 email records...\n",
      "  Processed 72,000 email records...\n",
      "  Processed 73,000 email records...\n",
      "  Processed 74,000 email records...\n",
      "  Processed 75,000 email records...\n",
      "  Processed 76,000 email records...\n",
      "  Processed 77,000 email records...\n",
      "  Processed 78,000 email records...\n",
      "  Processed 79,000 email records...\n",
      "  Processed 80,000 email records...\n",
      "  Processed 81,000 email records...\n",
      "  Processed 82,000 email records...\n",
      "  Processed 83,000 email records...\n",
      "  Processed 84,000 email records...\n",
      "  Processed 85,000 email records...\n",
      "  Processed 86,000 email records...\n",
      "  Processed 87,000 email records...\n",
      "  Processed 88,000 email records...\n",
      "  Processed 89,000 email records...\n",
      "  Processed 90,000 email records...\n",
      "  Processed 91,000 email records...\n",
      "  Processed 92,000 email records...\n",
      "  Processed 93,000 email records...\n",
      "  Processed 94,000 email records...\n",
      "  Processed 95,000 email records...\n",
      "  Processed 96,000 email records...\n",
      "  Processed 97,000 email records...\n",
      "  Processed 98,000 email records...\n",
      "  Processed 99,000 email records...\n",
      "  Processed 100,000 email records...\n",
      "  Processed 101,000 email records...\n",
      "  Processed 102,000 email records...\n",
      "  Processed 103,000 email records...\n",
      "  Processed 104,000 email records...\n",
      "  Processed 105,000 email records...\n",
      "  Processed 106,000 email records...\n",
      "  Processed 107,000 email records...\n",
      "  Processed 108,000 email records...\n",
      "  Processed 109,000 email records...\n",
      "  Processed 110,000 email records...\n",
      "  Processed 111,000 email records...\n",
      "  Processed 112,000 email records...\n",
      "  Processed 113,000 email records...\n",
      "  Processed 114,000 email records...\n",
      "  Processed 115,000 email records...\n",
      "  Processed 116,000 email records...\n",
      "  Processed 117,000 email records...\n",
      "  Processed 118,000 email records...\n",
      "  Processed 119,000 email records...\n",
      "  Processed 120,000 email records...\n",
      "  Processed 121,000 email records...\n",
      "  Processed 122,000 email records...\n",
      "  Processed 123,000 email records...\n",
      "  Processed 124,000 email records...\n",
      "  Processed 125,000 email records...\n",
      "  Processed 126,000 email records...\n",
      "  Processed 127,000 email records...\n",
      "  Processed 128,000 email records...\n",
      "  Processed 129,000 email records...\n",
      "  Processed 130,000 email records...\n",
      "  Processed 131,000 email records...\n",
      "  Processed 132,000 email records...\n",
      "  Processed 133,000 email records...\n",
      "  Processed 134,000 email records...\n",
      "  Processed 135,000 email records...\n",
      "  Processed 136,000 email records...\n",
      "  Processed 137,000 email records...\n",
      "  Processed 138,000 email records...\n",
      "  Processed 139,000 email records...\n",
      "  Processed 140,000 email records...\n",
      "  Processed 141,000 email records...\n",
      "  Processed 142,000 email records...\n",
      "  Processed 143,000 email records...\n",
      "  Processed 144,000 email records...\n",
      "  Processed 145,000 email records...\n",
      "  Processed 146,000 email records...\n",
      "  Processed 147,000 email records...\n",
      "  Processed 148,000 email records...\n",
      "  Processed 149,000 email records...\n",
      "  Processed 150,000 email records...\n",
      "  Processed 151,000 email records...\n",
      "  Processed 152,000 email records...\n",
      "  Processed 153,000 email records...\n",
      "  Processed 154,000 email records...\n",
      "  Processed 155,000 email records...\n",
      "  Processed 156,000 email records...\n",
      "  Processed 157,000 email records...\n",
      "  Processed 158,000 email records...\n",
      "  Processed 159,000 email records...\n",
      "  Processed 160,000 email records...\n",
      "  Processed 161,000 email records...\n",
      "  Processed 162,000 email records...\n",
      "  Processed 163,000 email records...\n",
      "  Processed 164,000 email records...\n",
      "  Processed 165,000 email records...\n",
      "  Processed 166,000 email records...\n",
      "  Processed 167,000 email records...\n",
      "  Processed 168,000 email records...\n",
      " Successfully loaded 168,658 email records\n",
      "  Sample email: From arati@email.com - Please review: {doc_type} for client Umbrella Corp...\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " DATA LOADING SUMMARY\n",
      "----------------------------------------------------------------------\n",
      " Total records loaded: 538,658\n",
      "   ‚Ä¢  SMS Messages: 185,000\n",
      "   ‚Ä¢  Phone Calls: 185,000\n",
      "   ‚Ä¢  Emails: 168,658\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " USER IDENTIFICATION\n",
      "----------------------------------------------------------------------\n",
      "\n",
      " Identifying user's phone number from communication patterns...\n",
      "  Most frequently contacted number: +912127404903\n",
      "  Selected as user's number based on frequency analysis\n",
      "  Reason: This number appears 15249 times across all communications\n",
      "\n",
      "‚úÖ USER'S PHONE NUMBER IDENTIFIED: +912127404903\n",
      "   Based on communication frequency and patterns\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " CREATING UNIFIED TIMELINE\n",
      "----------------------------------------------------------------------\n",
      "\n",
      " Creating unified timeline with detailed categorization...\n",
      "  Created timeline with 538,658 events\n",
      "  Time range: 2025-02-19 09:32:43 to 2026-02-20 09:26:23\n",
      "\n",
      "üìä TOTAL COMMUNICATION EVENTS LOADED: 538,658\n",
      "üë• UNIQUE CONTACTS IDENTIFIED: 9,461\n",
      "üì± USER'S PHONE NUMBER: +912127404903\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " INITIAL ANALYSIS\n",
      "----------------------------------------------------------------------\n",
      "üîç SUSPICIOUS COMMUNICATIONS: 223,699 (41.5%)\n",
      "   Top suspicious reasons:\n",
      "      ‚Ä¢ Very short call (<5 seconds): 37,794\n",
      "      ‚Ä¢ Financial: Contains 'payment': 16,198\n",
      "      ‚Ä¢ Suspicious: Contains 'urgent': 15,987\n",
      "\n",
      "======================================================================\n",
      " MAIN MENU\n",
      "======================================================================\n",
      "1. Timeline Events (Show all communications)\n",
      "2. View Detailed Analysis\n",
      "3. Suspicious Communications Analysis\n",
      "4. Multi Channel Pattern Detection\n",
      "5. Visualize Data Patterns\n",
      "6. Export the Report\n",
      "7. Exit\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select option (1-7):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " TIMELINE EVENTS - ALL COMMUNICATIONS\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìä TOTAL COMMUNICATION EVENTS: 538,658\n",
      "üì± USER'S PHONE NUMBER: +912127404903\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " 1. SMS MESSAGES\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Total SMS Messages: 185,000\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Time                 From                      ‚Üí   To                        Direction  Category        Message                       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "2025-08-23 09:30     +913052035660             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      Time sensitive                \n",
      "2025-08-23 09:31     +919541556875             ‚Üí   +912127404903             RECEIVED   ROUTINE         OK, sounds good               \n",
      "2025-08-23 09:32     +916463611442             ‚Üí   +912127404903             RECEIVED   ROUTINE         don't call, text only         \n",
      "2025-08-23 09:42     +919541556875             ‚Üí   +912127404903             RECEIVED   FINANCIAL       Transaction ID: 74B4FDE74E80...\n",
      "2025-08-23 09:45     +917863148608             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      Your invoice #INV-9405        \n",
      "2025-08-23 09:47     +913103021018             ‚Üí   +912127404903             RECEIVED   ROUTINE         See you tomorrow              \n",
      "2025-08-23 09:52     +916172021454             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      DOCTOR APPOINTMENT AT 10      \n",
      "2025-08-23 09:53     +912129834687             ‚Üí   +912127404903             RECEIVED   PERSONAL        Happy anniversary             \n",
      "2025-08-23 09:57     +913052035660             ‚Üí   +912127404903             RECEIVED   ROUTINE         Got it, thanks                \n",
      "2025-08-23 09:58     +913052035660             ‚Üí   +912127404903             RECEIVED   FINANCIAL       Bring cash only               \n",
      "2025-08-23 09:58     +913052035660             ‚Üí   +912127404903             RECEIVED   FINANCIAL       Bank transfer confirmed       \n",
      "2025-08-23 10:00     +913052035660             ‚Üí   +912127404903             RECEIVED   FINANCIAL       bring cash only               \n",
      "2025-08-23 10:02     +914156529064             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      doctor appointment at 10      \n",
      "2025-08-23 10:02     +916175714558             ‚Üí   +912127404903             RECEIVED   ROUTINE         see you soon                  \n",
      "2025-08-23 10:05     +917863148608             ‚Üí   +912127404903             RECEIVED   ROUTINE         see you soon                  \n",
      "2025-08-23 10:16     +917863148608             ‚Üí   +912127404903             RECEIVED   ROUTINE         wait for my signal            \n",
      "2025-08-23 10:18     +916463611442             ‚Üí   +912127404903             RECEIVED   URGENT          Urgent meeting                \n",
      "2025-08-23 10:21     +914156529064             ‚Üí   +912127404903             RECEIVED   ROUTINE         How was school?               \n",
      "2025-08-23 10:28     +917863148608             ‚Üí   +912127404903             RECEIVED   ROUTINE         i'm at the office             \n",
      "2025-08-23 10:29     +914156172621             ‚Üí   +912127404903             RECEIVED   ROUTINE         see you soon                  \n",
      "2025-08-23 10:40     +919541556875             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      Call me when you can          \n",
      "2025-08-23 10:46     +916172021454             ‚Üí   +912127404903             RECEIVED   FINANCIAL       Transfer complete             \n",
      "2025-08-23 10:52     +916463611442             ‚Üí   +912127404903             RECEIVED   ROUTINE         Got it, thanks                \n",
      "2025-08-23 10:55     +913052035660             ‚Üí   +912127404903             RECEIVED   FINANCIAL       Transfer complete             \n",
      "2025-08-23 10:56     +917863148608             ‚Üí   +912127404903             RECEIVED   ROUTINE         Can you call me?              \n",
      "2025-08-23 11:00     +912129834687             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      what time is dinner?          \n",
      "2025-08-23 11:04     +913125458743             ‚Üí   +912127404903             RECEIVED   BUSINESS        Deadline is tomorrow          \n",
      "2025-08-23 11:05     +913052035660             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      Time sensitive                \n",
      "2025-08-23 11:08     +919541556875             ‚Üí   +912127404903             RECEIVED   URGENT          Urgent meeting                \n",
      "2025-08-23 11:14     +912026286723             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      What time is dinner?          \n",
      "2025-08-23 11:15     +912127404903             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      Love you                      \n",
      "2025-08-23 11:21     +913107546880             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      Love you                      \n",
      "2025-08-23 11:28     +913052035660             ‚Üí   +912127404903             RECEIVED   ROUTINE         hey, how are you?             \n",
      "2025-08-23 11:28     +917863148608             ‚Üí   +912127404903             RECEIVED   ROUTINE         got it, thanks                \n",
      "2025-08-23 11:37     +916463611442             ‚Üí   +912127404903             RECEIVED   FINANCIAL       Bitcoin address: 13PRRTKIR73...\n",
      "2025-08-23 11:45     +916463611442             ‚Üí   +912127404903             RECEIVED   ROUTINE         Please send $500              \n",
      "2025-08-23 11:46     +919541556875             ‚Üí   +912127404903             RECEIVED   ROUTINE         switch to signal              \n",
      "2025-08-23 12:02     +916463611442             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      call me when you can          \n",
      "2025-08-23 12:02     +917863148608             ‚Üí   +912127404903             RECEIVED   ROUTINE         i'm at the office             \n",
      "2025-08-23 12:04     +917863148608             ‚Üí   +912127404903             RECEIVED   URGENT          Emergency!                    \n",
      "2025-08-23 12:27     +912129834687             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      Doctor appointment at 10      \n",
      "2025-08-23 12:36     +917863148608             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      Delete the messages           \n",
      "2025-08-23 12:48     +913052035660             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      confirm when done             \n",
      "2025-08-23 13:20     +917863148608             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      Confirm when done             \n",
      "2025-08-23 13:55     +919541556875             ‚Üí   +912127404903             RECEIVED   FINANCIAL       Transaction ID: B094E8E67E26...\n",
      "2025-08-23 13:56     +913052035660             ‚Üí   +912127404903             RECEIVED   SUSPICIOUS      Meeting moved to park         \n",
      "2025-08-23 13:58     +916463611442             ‚Üí   +912127404903             RECEIVED   URGENT          asap - respond                \n",
      "2025-08-23 14:05     +913052035660             ‚Üí   +912127404903             RECEIVED   FINANCIAL       Transaction ID: B910337B57C7...\n",
      "2025-08-23 14:05     +913052035660             ‚Üí   +912127404903             RECEIVED   FINANCIAL       Transfer complete             \n",
      "2025-08-23 14:07     +919541556875             ‚Üí   +912127404903             RECEIVED   ROUTINE         911 situation                 \n",
      "... and 184,950 more SMS messages\n",
      "\n",
      "üì± SMS STATISTICS:\n",
      "   ‚Ä¢ Received SMS: 185,000 (100.0%)\n",
      "   ‚Ä¢ Sent SMS: 0 (0.0%)\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " 2. PHONE CALLS\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Total Phone Calls: 185,000\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Time                 Caller                    ‚Üí   Receiver                  Call Type       Duration   Category       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "2025-11-21 09:48     +914153456920             ‚Üí   +912127404903             ANSWERED        5:00       ROUTINE        \n",
      "2025-11-21 09:48     +913101082198             ‚Üí   +912127404903             ANSWERED        18s        ROUTINE        \n",
      "2025-11-21 09:48     +913101082198             ‚Üí   +912127404903             MISSED          1s         SUSPICIOUS     \n",
      "2025-11-21 09:48     +912126849270             ‚Üí   +912127404903             ANSWERED        2:00       ROUTINE        \n",
      "2025-11-21 09:49     +912021451585             ‚Üí   +912127404903             ANSWERED        2:00       ROUTINE        \n",
      "2025-11-21 09:50     +912122428949             ‚Üí   +912127404903             MISSED          4s         SUSPICIOUS     \n",
      "2025-11-21 09:51     +916021738010             ‚Üí   +912127404903             ANSWERED        60s        ROUTINE        \n",
      "2025-11-21 09:51     +913038690076             ‚Üí   +912127404903             ANSWERED        60s        ROUTINE        \n",
      "2025-11-21 09:53     +912122428949             ‚Üí   +912127404903             ANSWERED        60s        ROUTINE        \n",
      "2025-11-21 09:54     +916176833584             ‚Üí   +912127404903             ANSWERED        2:00       ROUTINE        \n",
      "2025-11-21 09:54     +916176833584             ‚Üí   +912127404903             ANSWERED        5:00       ROUTINE        \n",
      "2025-11-21 09:56     +914153456920             ‚Üí   +912127404903             ANSWERED        60s        SUSPICIOUS     \n",
      "2025-11-21 10:01     +919544809782             ‚Üí   +912127404903             MISSED          1s         SUSPICIOUS     \n",
      "2025-11-21 10:01     +913102417605             ‚Üí   +912127404903             LONG_CALL       30:00      ROUTINE        \n",
      "2025-11-21 10:02     +916177055643             ‚Üí   +912127404903             ANSWERED        5:13       ROUTINE        \n",
      "2025-11-21 10:02     +913102417605             ‚Üí   +912127404903             ANSWERED        48s        ROUTINE        \n",
      "2025-11-21 10:02     +913038690076             ‚Üí   +912127404903             MISSED          4s         SUSPICIOUS     \n",
      "2025-11-21 10:03     +916176833584             ‚Üí   +912127404903             ANSWERED        5:00       ROUTINE        \n",
      "2025-11-21 10:03     +917137623748             ‚Üí   +912127404903             ANSWERED        5:00       ROUTINE        \n",
      "2025-11-21 10:04     +916021738010             ‚Üí   +912127404903             MISSED          3s         SUSPICIOUS     \n",
      "2025-11-21 10:05     +916176833584             ‚Üí   +912127404903             ANSWERED        2:00       ROUTINE        \n",
      "2025-11-21 10:05     +919544809782             ‚Üí   +912127404903             ANSWERED        30s        ROUTINE        \n",
      "2025-11-21 10:07     +913101082198             ‚Üí   +912127404903             MISSED          4s         SUSPICIOUS     \n",
      "2025-11-21 10:07     +913102417605             ‚Üí   +912127404903             ANSWERED        2:00       ROUTINE        \n",
      "2025-11-21 10:07     +917137623748             ‚Üí   +912127404903             ANSWERED        2:00       ROUTINE        \n",
      "2025-11-21 10:08     +917866945718             ‚Üí   +912127404903             ANSWERED        30s        ROUTINE        \n",
      "2025-11-21 10:08     +913038690076             ‚Üí   +912127404903             ANSWERED        10:00      ROUTINE        \n",
      "2025-11-21 10:12     +914159925584             ‚Üí   +912127404903             LONG_CALL       12:43      ROUTINE        \n",
      "2025-11-21 10:12     +912121295397             ‚Üí   +912127404903             ANSWERED        60s        ROUTINE        \n",
      "2025-11-21 10:12     +917137623748             ‚Üí   +912127404903             MISSED          4s         SUSPICIOUS     \n",
      "2025-11-21 10:15     +917137623748             ‚Üí   +912127404903             ANSWERED        57s        ROUTINE        \n",
      "2025-11-21 10:16     +913101082198             ‚Üí   +912127404903             ANSWERED        40s        ROUTINE        \n",
      "2025-11-21 10:16     +913102417605             ‚Üí   +912127404903             LONG_CALL       30:00      ROUTINE        \n",
      "2025-11-21 10:17     +914153456920             ‚Üí   +912127404903             ANSWERED        39s        ROUTINE        \n",
      "2025-11-21 10:17     +913102417605             ‚Üí   +912127404903             LONG_CALL       30:00      ROUTINE        \n",
      "2025-11-21 10:18     +913053920644             ‚Üí   +912127404903             ANSWERED        10:00      ROUTINE        \n",
      "2025-11-21 10:18     +916021738010             ‚Üí   +912127404903             ANSWERED        2:00       ROUTINE        \n",
      "2025-11-21 10:20     +912126849270             ‚Üí   +912127404903             ANSWERED        28s        ROUTINE        \n",
      "2025-11-21 10:20     +914159925584             ‚Üí   +912127404903             ANSWERED        3:07       ROUTINE        \n",
      "2025-11-21 10:23     +917137623748             ‚Üí   +912127404903             ANSWERED        2:00       ROUTINE        \n",
      "2025-11-21 10:25     +914153456920             ‚Üí   +912127404903             ANSWERED        30s        ROUTINE        \n",
      "2025-11-21 10:26     +916176833584             ‚Üí   +912127404903             ANSWERED        30s        ROUTINE        \n",
      "2025-11-21 10:27     +913038690076             ‚Üí   +912127404903             LONG_CALL       30:00      ROUTINE        \n",
      "2025-11-21 10:27     +916021738010             ‚Üí   +912127404903             ANSWERED        60s        ROUTINE        \n",
      "2025-11-21 10:27     +44623307756              ‚Üí   +912127404903             ANSWERED        5:00       ROUTINE        \n",
      "2025-11-21 10:28     +914153456920             ‚Üí   +912127404903             ANSWERED        30s        ROUTINE        \n",
      "2025-11-21 10:33     +913102417605             ‚Üí   +912127404903             MISSED          3s         SUSPICIOUS     \n",
      "2025-11-21 10:34     +912121295397             ‚Üí   +912127404903             LONG_CALL       30:00      ROUTINE        \n",
      "2025-11-21 10:34     +912126849270             ‚Üí   +912127404903             ANSWERED        60s        ROUTINE        \n",
      "2025-11-21 10:36     +916177055643             ‚Üí   +912127404903             ANSWERED        1:16       ROUTINE        \n",
      "... and 184,950 more phone calls\n",
      "\n",
      "üìû CALL STATISTICS:\n",
      "   ‚Ä¢ Total call duration: 13390h 3m 48s\n",
      "   ‚Ä¢ Average call duration: 260.6 seconds\n",
      "   ‚Ä¢ Call types:\n",
      "      - ANSWERED: 122,761\n",
      "      - MISSED: 37,794\n",
      "      - LONG_CALL: 18,305\n",
      "      - SHORT_CALL: 6,026\n",
      "      - COMPLAINT: 114\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " 3. EMAILS\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Total Emails: 168,658\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Time                 From                           ‚Üí   To                             Category        Subject                       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "2025-02-19 09:32     arati@email.com                ‚Üí   xxuc81@protonmail.com          ROUTINE         Do not reply to this email    \n",
      "2025-02-19 09:38     arati@email.com                ‚Üí   spam20@guerrillamail.com       SPAM            Encrypted: Read carefully     \n",
      "2025-02-19 09:41     spam20@guerrillamail.com       ‚Üí   david@email.com                ROUTINE         Signal: New message           \n",
      "2025-02-19 09:43     note94@tutanota.com            ‚Üí   david@email.com                BUSINESS        RE: Our meeting location      \n",
      "2025-02-19 09:44     arati@email.com                ‚Üí   xxuc81@protonmail.com          SPAM            Signal: New message           \n",
      "2025-02-19 09:50     arati@email.com                ‚Üí   spam20@guerrillamail.com       ROUTINE         Plan B details                \n",
      "2025-02-19 09:55     arati@email.com                ‚Üí   spam20@guerrillamail.com       SPAM            Secure message                \n",
      "2025-02-19 10:15     boss@company.com               ‚Üí   david@email.com                SPAM            Project Update: Omega - Phas...\n",
      "2025-02-19 10:46     arati@email.com                ‚Üí   hr@company.com                 FINANCIAL       Your Wells Fargo statement i...\n",
      "2025-02-19 11:01     spam20@guerrillamail.com       ‚Üí   david@email.com                ROUTINE         Encrypted: Read carefully     \n",
      "2025-02-19 11:09     note94@tutanota.com            ‚Üí   david@email.com                ROUTINE         Signal: New message           \n",
      "2025-02-19 11:12     arati@email.com                ‚Üí   xxuc81@protonmail.com          ROUTINE         Plan B details                \n",
      "2025-02-19 11:14     arati@email.com                ‚Üí   note94@tutanota.com            ROUTINE         Secure message                \n",
      "2025-02-19 11:20     arati@email.com                ‚Üí   note94@tutanota.com            ROUTINE         Encrypted: Read carefully     \n",
      "2025-02-19 11:21     xxuc81@protonmail.com          ‚Üí   david@email.com                BUSINESS        RE: Our meeting location      \n",
      "2025-02-19 11:38     arati@email.com                ‚Üí   colleague2@company.com         SUSPICIOUS      URGENT: Response needed by 9...\n",
      "2025-02-19 11:53     colleague2@company.com         ‚Üí   david@email.com                BUSINESS        Meeting: Project Eclipse - 0...\n",
      "2025-02-19 12:28     arati@email.com                ‚Üí   spam20@guerrillamail.com       ROUTINE         FW: Document for review       \n",
      "2025-02-19 12:48     arati@email.com                ‚Üí   spam20@guerrillamail.com       BUSINESS        RE: Our meeting location      \n",
      "2025-02-19 12:51     xxuc81@protonmail.com          ‚Üí   david@email.com                SPAM            Updated instructions          \n",
      "2025-02-19 12:58     spam20@guerrillamail.com       ‚Üí   david@email.com                ROUTINE         Signal: New message           \n",
      "2025-02-19 13:00     spam20@guerrillamail.com       ‚Üí   david@email.com                SPAM            Updated instructions          \n",
      "2025-02-19 13:02     boss@company.com               ‚Üí   david@email.com                BUSINESS        Weekly Status Report - Week ...\n",
      "2025-02-19 13:05     xxuc81@protonmail.com          ‚Üí   david@email.com                ROUTINE         Secure message                \n",
      "2025-02-19 13:09     spam20@guerrillamail.com       ‚Üí   david@email.com                ROUTINE         Signal: New message           \n",
      "2025-02-19 13:12     spam20@guerrillamail.com       ‚Üí   david@email.com                SPAM            RE: Our meeting location      \n",
      "2025-02-19 13:17     arati@email.com                ‚Üí   note94@tutanota.com            ROUTINE         Do not reply to this email    \n",
      "2025-02-19 13:58     arati@email.com                ‚Üí   xxuc81@protonmail.com          ROUTINE         FW: Document for review       \n",
      "2025-02-19 14:03     spam20@guerrillamail.com       ‚Üí   david@email.com                ROUTINE         Secure message                \n",
      "2025-02-19 14:20     arati@email.com                ‚Üí   note94@tutanota.com            BUSINESS        Signal: New message           \n",
      "2025-02-19 14:21     arati@email.com                ‚Üí   note94@tutanota.com            ROUTINE         Signal: New message           \n",
      "2025-02-19 14:23     arati@email.com                ‚Üí   spam20@guerrillamail.com       BUSINESS        Plan B details                \n",
      "2025-02-19 14:38     colleague2@company.com         ‚Üí   david@email.com                BUSINESS        Meeting: Project Beta - 03/1...\n",
      "2025-02-19 14:42     david55@yahoo.com              ‚Üí   david@email.com                ROUTINE         Catching up this weekend?     \n",
      "2025-02-19 15:24     arati@email.com                ‚Üí   hr@company.com                 FINANCIAL       Team Meeting Minutes - 03/12  \n",
      "2025-02-19 15:37     arati@email.com                ‚Üí   spam20@guerrillamail.com       SPAM            Signal: New message           \n",
      "2025-02-19 15:38     colleague2@company.com         ‚Üí   david@email.com                SPAM            Project Update: Delta - Phas...\n",
      "2025-02-19 15:42     arati@email.com                ‚Üí   sarah25@hotmail.com            PERSONAL        Catching up this weekend?     \n",
      "2025-02-19 15:48     arati@email.com                ‚Üí   spam20@guerrillamail.com       ROUTINE         Do not reply to this email    \n",
      "2025-02-19 15:58     arati@email.com                ‚Üí   note94@tutanota.com            ROUTINE         Signal: New message           \n",
      "2025-02-19 15:59     colleague2@company.com         ‚Üí   david@email.com                BUSINESS        Meeting: Project Nova - 02/2...\n",
      "2025-02-19 16:02     client@business.org            ‚Üí   david@email.com                BUSINESS        Meeting: Project Phoenix - 0...\n",
      "2025-02-19 16:12     david55@yahoo.com              ‚Üí   david@email.com                SPAM            Photos from vacation          \n",
      "2025-02-19 16:14     boss@company.com               ‚Üí   david@email.com                BUSINESS        Please review: {doc_type} fo...\n",
      "2025-02-19 16:32     hr@company.com                 ‚Üí   david@email.com                BUSINESS        Meeting: Project Gamma - 03/...\n",
      "2025-02-19 16:33     arati@email.com                ‚Üí   colleague2@company.com         BUSINESS        Please review: {doc_type} fo...\n",
      "2025-02-19 16:41     arati@email.com                ‚Üí   xxuc81@protonmail.com          FINANCIAL       Investment Portfolio Update ...\n",
      "2025-02-19 16:43     arati@email.com                ‚Üí   xxuc81@protonmail.com          FINANCIAL       Investment Portfolio Update ...\n",
      "2025-02-19 16:45     sarah25@hotmail.com            ‚Üí   david@email.com                FINANCIAL       Transaction Alert: $$7026     \n",
      "2025-02-19 16:49     xxuc81@protonmail.com          ‚Üí   david@email.com                SPAM            RE: Our meeting location      \n",
      "... and 168,608 more emails\n",
      "\n",
      "üìß EMAIL STATISTICS:\n",
      "   ‚Ä¢ Unique senders: 12\n",
      "   ‚Ä¢ Unique recipients: 12\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " COMMUNICATION SUMMARY\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìà TOTAL EVENTS: 538,658\n",
      "   ‚Ä¢ SMS Messages: 185,000 (34.3%)\n",
      "   ‚Ä¢ Phone Calls: 185,000 (34.3%)\n",
      "   ‚Ä¢ Emails: 168,658 (31.3%)\n",
      "\n",
      "üìÖ TIME RANGE: 2025-02-19 to 2026-02-20\n",
      "   ‚Ä¢ Duration: 366 days\n",
      "   ‚Ä¢ Average daily events: 1471.7\n",
      "   ‚Ä¢ Busiest day: 2026-01-20 (3,664 events)\n",
      "\n",
      "======================================================================\n",
      " MAIN MENU\n",
      "======================================================================\n",
      "1. Timeline Events (Show all communications)\n",
      "2. View Detailed Analysis\n",
      "3. Suspicious Communications Analysis\n",
      "4. Multi Channel Pattern Detection\n",
      "5. Visualize Data Patterns\n",
      "6. Export the Report\n",
      "7. Exit\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select option (1-7):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " DETAILED COMMUNICATION ANALYSIS\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìä TOTAL COMMUNICATION EVENTS: 538,658\n",
      "üì± USER'S PHONE NUMBER: +912127404903\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " 1. COMMUNICATION FLOW ANALYSIS\n",
      "========================================================================================================================\n",
      "\n",
      "TOP COMMUNICATION FLOWS:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Rank  From ‚Üí To                                          Count      %       \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     +912127404903 ‚Üí +912127404903                      15,249         2.8%\n",
      "2     +912129834687 ‚Üí +912127404903                      15,232         2.8%\n",
      "3     +913103021018 ‚Üí +912127404903                      15,225         2.8%\n",
      "4     +912026286723 ‚Üí +912127404903                      15,122         2.8%\n",
      "5     +914156529064 ‚Üí +912127404903                      15,076         2.8%\n",
      "6     +913107546880 ‚Üí +912127404903                      15,033         2.8%\n",
      "7     +912028481012 ‚Üí +912127404903                      15,016         2.8%\n",
      "8     +914156172621 ‚Üí +912127404903                      15,004         2.8%\n",
      "9     +916175714558 ‚Üí +912127404903                      14,998         2.8%\n",
      "10    +916172021454 ‚Üí +912127404903                      14,964         2.8%\n",
      "11    +914159925584 ‚Üí +912127404903                      11,544         2.1%\n",
      "12    +913102417605 ‚Üí +912127404903                      11,401         2.1%\n",
      "13    +914153456920 ‚Üí +912127404903                      11,355         2.1%\n",
      "14    +916177055643 ‚Üí +912127404903                      11,342         2.1%\n",
      "15    +912026841859 ‚Üí +912127404903                      11,280         2.1%\n",
      "16    +912021451585 ‚Üí +912127404903                      11,261         2.1%\n",
      "17    +912121295397 ‚Üí +912127404903                      11,250         2.1%\n",
      "18    +916176833584 ‚Üí +912127404903                      11,193         2.1%\n",
      "19    +913101082198 ‚Üí +912127404903                      11,162         2.1%\n",
      "20    +912122428949 ‚Üí +912127404903                      11,155         2.1%\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " 2. CONTACT ANALYSIS\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "üë• UNIQUE CONTACTS: 9,461\n",
      "\n",
      "üì• COMMUNICATIONS RECEIVED BY USER:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank  From                                     Count      %       \n",
      "--------------------------------------------------------------------------------\n",
      "1     +912129834687                            15,232         4.3%\n",
      "2     +913103021018                            15,225         4.3%\n",
      "3     +912026286723                            15,122         4.3%\n",
      "4     +914156529064                            15,076         4.2%\n",
      "5     +913107546880                            15,033         4.2%\n",
      "6     +912028481012                            15,016         4.2%\n",
      "7     +914156172621                            15,004         4.2%\n",
      "8     +916175714558                            14,998         4.2%\n",
      "9     +916172021454                            14,964         4.2%\n",
      "10    +914159925584                            11,544         3.3%\n",
      "11    +913102417605                            11,401         3.2%\n",
      "12    +914153456920                            11,355         3.2%\n",
      "13    +916177055643                            11,342         3.2%\n",
      "14    +912026841859                            11,280         3.2%\n",
      "15    +912021451585                            11,261         3.2%\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " 3. COMMUNICATION PATTERNS\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "TOP COMMUNICATION PATTERNS BY MEDIUM:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Rank  Parties                                  SMS      Calls    Emails   Total     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     +912127404903 ‚Üî +912127404903            15249    0        0        15,249    \n",
      "2     +912129834687 ‚Üî +912127404903            15232    0        0        15,232    \n",
      "3     +913103021018 ‚Üî +912127404903            15225    0        0        15,225    \n",
      "4     +912026286723 ‚Üî +912127404903            15122    0        0        15,122    \n",
      "5     +914156529064 ‚Üî +912127404903            15076    0        0        15,076    \n",
      "6     +913107546880 ‚Üî +912127404903            15033    0        0        15,033    \n",
      "7     +912028481012 ‚Üî +912127404903            15016    0        0        15,016    \n",
      "8     +914156172621 ‚Üî +912127404903            15004    0        0        15,004    \n",
      "9     +916175714558 ‚Üî +912127404903            14998    0        0        14,998    \n",
      "10    +916172021454 ‚Üî +912127404903            14964    0        0        14,964    \n",
      "11    +914159925584 ‚Üî +912127404903            0        11544    0        11,544    \n",
      "12    +913102417605 ‚Üî +912127404903            0        11401    0        11,401    \n",
      "13    +914153456920 ‚Üî +912127404903            0        11355    0        11,355    \n",
      "14    +916177055643 ‚Üî +912127404903            0        11342    0        11,342    \n",
      "15    +912026841859 ‚Üî +912127404903            0        11280    0        11,280    \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " 4. TEMPORAL ANALYSIS\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÖ INVESTIGATION PERIOD: 366 days\n",
      "   ‚Ä¢ From: 2025-02-19 09:32\n",
      "   ‚Ä¢ To: 2026-02-20 09:26\n",
      "   ‚Ä¢ Average daily communications: 1471.7\n",
      "\n",
      "‚è∞ PEAK ACTIVITY HOUR: 22:00 (41,408 events)\n",
      "\n",
      "üåÖ COMMUNICATION BY TIME OF DAY:\n",
      "   ‚Ä¢ Morning (6AM-12PM): 70,559 (13.1%)\n",
      "   ‚Ä¢ Afternoon (12PM-6PM): 86,360 (16.0%)\n",
      "   ‚Ä¢ Evening (6PM-12AM): 237,715 (44.1%)\n",
      "   ‚Ä¢ Night (12AM-6AM): 144,024 (26.7%)\n",
      "\n",
      "========================================================================================================================\n",
      " 5. FORENSIC CATEGORY ANALYSIS WITH REASONS\n",
      "========================================================================================================================\n",
      "\n",
      "üîç SUSPICIOUS COMMUNICATIONS: 150,161 events\n",
      "   Top reasons for SUSPICIOUS classification:\n",
      "      ‚Ä¢ Suspicious: Contains 'urgent': 55 occurrences\n",
      "      ‚Ä¢ Phishing: Contains 'account': 33 occurrences\n",
      "      ‚Ä¢ Suspicious: Contains 'action required': 31 occurrences\n",
      "      ‚Ä¢ Malicious: Contains 'download': 14 occurrences\n",
      "   Example suspicious communication:\n",
      "      Time: 2025-02-19 11:38\n",
      "      From: arati@email.com\n",
      "      To: colleague2@company.com\n",
      "      Content: URGENT: Response needed by 9:00...\n",
      "      Reasons: Suspicious: Contains 'urgent'\n",
      "\n",
      "üîç FINANCIAL COMMUNICATIONS: 47,876 events\n",
      "   Top reasons for FINANCIAL classification:\n",
      "      ‚Ä¢ Financial: Contains 'payment': 36 occurrences\n",
      "      ‚Ä¢ Financial: Contains 'fee': 33 occurrences\n",
      "      ‚Ä¢ Financial: Contains 'invoice': 31 occurrences\n",
      "      ‚Ä¢ Malicious: Contains 'link': 18 occurrences\n",
      "      ‚Ä¢ Phishing: Contains 'confirm': 14 occurrences\n",
      "   Example financial communication:\n",
      "      Time: 2025-02-19 10:46\n",
      "      From: arati@email.com\n",
      "      To: hr@company.com\n",
      "      Content: Your Wells Fargo statement is ready...\n",
      "      Reasons: Financial: Contains 'invoice', Malicious: Contains 'link'\n",
      "\n",
      "üîç URGENT COMMUNICATIONS: 2,162 events\n",
      "   Top reasons for URGENT classification:\n",
      "      ‚Ä¢ Urgent: Contains 'urgent': 36 occurrences\n",
      "      ‚Ä¢ Urgent: Contains 'emergency': 24 occurrences\n",
      "      ‚Ä¢ Coordination: Contains 'meet': 21 occurrences\n",
      "      ‚Ä¢ Urgent: Contains 'asap': 21 occurrences\n",
      "      ‚Ä¢ Urgent: Contains 'immediately': 15 occurrences\n",
      "   Example urgent communication:\n",
      "      Time: 2025-08-23 10:18\n",
      "      From: +916463611442\n",
      "      To: +912127404903\n",
      "      Content: Urgent meeting...\n",
      "      Reasons: Urgent: Contains 'urgent', Coordination: Contains 'meet'\n",
      "\n",
      "üîç INTERNATIONAL COMMUNICATIONS: 1,915 events\n",
      "   Top reasons for INTERNATIONAL classification:\n",
      "      ‚Ä¢ International call (>5 minutes): 100 occurrences\n",
      "      ‚Ä¢ Late night call (01:00): 8 occurrences\n",
      "      ‚Ä¢ Late night call (00:00): 6 occurrences\n",
      "      ‚Ä¢ Churn risk customer: 5 occurrences\n",
      "      ‚Ä¢ Late night call (03:00): 5 occurrences\n",
      "   Example international communication:\n",
      "      Time: 2025-11-21 12:21\n",
      "      From: +44295860248\n",
      "      To: +912127404903\n",
      "      Content: Duration: 600s...\n",
      "      Reasons: International call (>5 minutes)\n",
      "\n",
      "üîç SPAM COMMUNICATIONS: 21,585 events\n",
      "   Top reasons for SPAM classification:\n",
      "      ‚Ä¢ Phishing: Contains 'update': 44 occurrences\n",
      "      ‚Ä¢ Spam: Contains 'free': 28 occurrences\n",
      "      ‚Ä¢ Phishing: Contains 'confirm': 14 occurrences\n",
      "      ‚Ä¢ Phishing: Contains 'account': 14 occurrences\n",
      "      ‚Ä¢ Malicious: Contains 'download': 4 occurrences\n",
      "   Example spam communication:\n",
      "      Time: 2025-02-19 09:38\n",
      "      From: arati@email.com\n",
      "      To: spam20@guerrillamail.com\n",
      "      Content: Encrypted: Read carefully...\n",
      "      Reasons: Phishing: Contains 'confirm'\n",
      "\n",
      "======================================================================\n",
      " MAIN MENU\n",
      "======================================================================\n",
      "1. Timeline Events (Show all communications)\n",
      "2. View Detailed Analysis\n",
      "3. Suspicious Communications Analysis\n",
      "4. Multi Channel Pattern Detection\n",
      "5. Visualize Data Patterns\n",
      "6. Export the Report\n",
      "7. Exit\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select option (1-7):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      " SUSPICIOUS COMMUNICATIONS ANALYSIS\n",
      "========================================================================================================================\n",
      "üì± USER'S PHONE NUMBER: +912127404903\n",
      "\n",
      "üîç SUSPICIOUS COMMUNICATIONS DETECTED: 223,699 of 538,658 total events\n",
      "   ‚Ä¢ Suspicious Rate: 41.5%\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " DETAILED SUSPICIOUS COMMUNICATIONS BREAKDOWN\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Category                  Count % of Suspicious Top Reason                               Risk      \n",
      "-----------------------------------------------------------------------------------------------\n",
      "SUSPICIOUS              150,161           67.1% Very short call (<5 seconds) (37794x)    HIGH      \n",
      "FINANCIAL                47,876           21.4% Financial: Contains 'payment' (16198x)   HIGH      \n",
      "SPAM                     21,585            9.6% Phishing: Contains 'update' (10590x)     LOW       \n",
      "URGENT                    2,162            1.0% Urgent: Contains 'urgent' (852x)         MEDIUM    \n",
      "INTERNATIONAL             1,915            0.9% International call (>5 minutes) (1915x)  MEDIUM    \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " DETAILED SUSPICIOUS COMMUNICATIONS WITH REASONS\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Showing 15 of 223,699 suspicious communications:\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "No.  Time               From                      ‚Üí   To                        Medium   Category        Reasons                                                     \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1    02-19 09:38        arati@email.com           ‚Üí   spam20@guerrillamail.co... EMAIL    SPAM            Phishing: Contains 'confirm'                                \n",
      "2    02-19 09:44        arati@email.com           ‚Üí   xxuc81@protonmail.com     EMAIL    SPAM            Phishing: Contains 'confirm'                                \n",
      "3    02-19 09:55        arati@email.com           ‚Üí   spam20@guerrillamail.co... EMAIL    SPAM            Phishing: Contains 'confirm'                                \n",
      "4    02-19 10:15        boss@company.com          ‚Üí   david@email.com           EMAIL    SPAM            Phishing: Contains 'update'                                 \n",
      "5    02-19 10:46        arati@email.com           ‚Üí   hr@company.com            EMAIL    FINANCIAL       Financial: Contains 'invoice', Malicious: Contains 'link'   \n",
      "6    02-19 11:38        arati@email.com           ‚Üí   colleague2@company.com    EMAIL    SUSPICIOUS      Suspicious: Contains 'urgent'                               \n",
      "7    02-19 12:51        xxuc81@protonmail.com     ‚Üí   david@email.com           EMAIL    SPAM            Phishing: Contains 'update'                                 \n",
      "8    02-19 13:00        spam20@guerrillamail.co... ‚Üí   david@email.com           EMAIL    SPAM            Phishing: Contains 'update'                                 \n",
      "9    02-19 13:12        spam20@guerrillamail.co... ‚Üí   david@email.com           EMAIL    SPAM            Phishing: Contains 'confirm'                                \n",
      "10   02-19 15:24        arati@email.com           ‚Üí   hr@company.com            EMAIL    FINANCIAL       Financial: Contains 'fee'                                   \n",
      "11   02-19 15:37        arati@email.com           ‚Üí   spam20@guerrillamail.co... EMAIL    SPAM            Phishing: Contains 'confirm'                                \n",
      "12   02-19 15:38        colleague2@company.com    ‚Üí   david@email.com           EMAIL    SPAM            Phishing: Contains 'update'                                 \n",
      "13   02-19 16:12        david55@yahoo.com         ‚Üí   david@email.com           EMAIL    SPAM            Spam: Contains 'free'                                       \n",
      "14   02-19 16:41        arati@email.com           ‚Üí   xxuc81@protonmail.com     EMAIL    FINANCIAL       Phishing: Contains 'update', Financial: Contains 'payment'  \n",
      "15   02-19 16:43        arati@email.com           ‚Üí   xxuc81@protonmail.com     EMAIL    FINANCIAL       Phishing: Contains 'update', Financial: Contains 'invoice'...\n",
      "\n",
      "... and 223,684 more suspicious communications\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " MOST SUSPICIOUS CONTACTS\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Contacts with suspicious communications:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Rank  Contact                                  Suspicious Count     Example Reasons                         \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     arati@email.com                          43,850               Financial: Contains 'payment', Suspici...\n",
      "2     david@email.com                          36,256               Financial: Contains 'payment', Suspici...\n",
      "3     colleague1@company.com                   9,822                Financial: Contains 'payment', Phishin...\n",
      "4     hr@company.com                           9,797                Financial: Contains 'payment', Suspici...\n",
      "5     boss@company.com                         9,585                Financial: Contains 'payment', Suspici...\n",
      "6     colleague2@company.com                   9,564                Financial: Contains 'payment', Suspici...\n",
      "7     client@business.org                      9,546                Financial: Contains 'payment', Phishin...\n",
      "8     david55@yahoo.com                        6,835                Financial: Contains 'payment', Phishin...\n",
      "9     sarah25@hotmail.com                      6,716                Financial: Contains 'payment', Phishin...\n",
      "10    arati54@gmail.com                        6,706                Financial: Contains 'payment', Phishin...\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " DETAILED RISK ASSESSMENT\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìä OVERALL RISK SCORE: 80.0/100\n",
      "\n",
      "Risk Factors Assessment:\n",
      "--------------------------------------------------------------------------------\n",
      "Factor                                             Score      Max       \n",
      "--------------------------------------------------------------------------------\n",
      "High volume of suspicious communications (>41.5%)  30         30        \n",
      "Multiple high-risk communications (198037)         25         25        \n",
      "High late-night suspicious activity (38.6%)        20         20        \n",
      "Diverse suspicious contacts                        5          25        \n",
      "--------------------------------------------------------------------------------\n",
      "TOTAL                                              80         100       \n",
      "\n",
      "üîç RISK LEVEL ANALYSIS:\n",
      "   ‚Ä¢ Risk Level: üî¥ CRITICAL - Extensive suspicious activity\n",
      "   ‚Ä¢ Forensic Priority: Critical\n",
      "   ‚Ä¢ Recommendation: Urgent investigation required\n",
      "\n",
      "üö® ADDITIONAL ANOMALIES DETECTED (5):\n",
      "   ‚ö† High late-night activity: 144,024 events (26.7%)\n",
      "   ‚ö† Rapid-fire communications: 308,607 sequences <30s apart\n",
      "   ‚ö† Financial-related communications: 47,876\n",
      "   ‚ö† Suspicious keyword communications: 150,161\n",
      "   ‚ö† International communications: 1,915\n",
      "\n",
      "\n",
      "======================================================================\n",
      " MULTI-CHANNEL COMMUNICATION ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "‚úÖ No coordinated multi-channel patterns detected.\n",
      "\n",
      "‚úÖ No coordinated multi-channel patterns detected.\n",
      "\n",
      "======================================================================\n",
      " MAIN MENU\n",
      "======================================================================\n",
      "1. Timeline Events (Show all communications)\n",
      "2. View Detailed Analysis\n",
      "3. Suspicious Communications Analysis\n",
      "4. Multi Channel Pattern Detection\n",
      "5. Visualize Data Patterns\n",
      "6. Export the Report\n",
      "7. Exit\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select option (1-7):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " MULTI-CHANNEL COMMUNICATION ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "‚úÖ No coordinated multi-channel patterns detected.\n",
      "\n",
      "======================================================================\n",
      " MAIN MENU\n",
      "======================================================================\n",
      "1. Timeline Events (Show all communications)\n",
      "2. View Detailed Analysis\n",
      "3. Suspicious Communications Analysis\n",
      "4. Multi Channel Pattern Detection\n",
      "5. Visualize Data Patterns\n",
      "6. Export the Report\n",
      "7. Exit\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select option (1-7):  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " ANALYSIS COMPLETED\n",
      "======================================================================\n",
      "Thank you for using the System.\n"
     ]
    }
   ],
   "source": [
    "### !/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    from IPython.display import display, clear_output\n",
    "    from IPython import get_ipython\n",
    "    IN_JUPYTER = get_ipython() is not None\n",
    "    if IN_JUPYTER:\n",
    "        get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "except:\n",
    "    IN_JUPYTER = False\n",
    "\n",
    "# ========================\n",
    "# DATA LOADING FUNCTIONS \n",
    "# ========================\n",
    "\n",
    "def load_sms_data():\n",
    "    \"\"\"Load SMS data from CSV or JSON file with enhanced debugging\"\"\"\n",
    "    sms_data = []\n",
    "    \n",
    "    # Look for both CSV and JSON files\n",
    "    possible_files = ['SMS-Data.csv', 'sms_data.csv', 'sms.json', 'SMS.json', 'sms_messages.json']\n",
    "    \n",
    "    sms_file = None\n",
    "    for file in possible_files:\n",
    "        if os.path.exists(file):\n",
    "            sms_file = file\n",
    "            break\n",
    "    \n",
    "    if not sms_file:\n",
    "        print(f\" No SMS data file found. Looked for: {possible_files}\")\n",
    "        # Try to find any file that might contain SMS data\n",
    "        json_files = [f for f in os.listdir('.') if f.lower().endswith('.json')]\n",
    "        csv_files = [f for f in os.listdir('.') if f.lower().endswith('.csv')]\n",
    "        \n",
    "        sms_keywords = ['sms', 'message', 'text', 'SMS']\n",
    "        \n",
    "        # Check JSON files first\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    content = f.read()[:1000].lower()\n",
    "                    if any(keyword in content for keyword in sms_keywords):\n",
    "                        print(f\"  Found potential SMS data in: {json_file}\")\n",
    "                        sms_file = json_file\n",
    "                        break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # If no JSON found, check CSV files\n",
    "        if not sms_file:\n",
    "            for csv_file in csv_files:\n",
    "                try:\n",
    "                    with open(csv_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        first_line = f.readline().lower()\n",
    "                        if any(keyword in first_line for keyword in sms_keywords):\n",
    "                            print(f\"  Found potential SMS data in: {csv_file}\")\n",
    "                            sms_file = csv_file\n",
    "                            break\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if not sms_file:\n",
    "            print(\"  No SMS data found. SMS analysis will be skipped.\")\n",
    "            return []\n",
    "    \n",
    "    try:\n",
    "        print(f\" Loading SMS data from {sms_file}...\")\n",
    "        \n",
    "        # ===== HANDLE JSON FILES =====\n",
    "        if sms_file.lower().endswith('.json'):\n",
    "            with open(sms_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                # Handle different JSON structures\n",
    "                if isinstance(data, dict):\n",
    "                    # Try to find SMS array in the JSON\n",
    "                    if 'messages' in data:\n",
    "                        records = data['messages']\n",
    "                    elif 'sms' in data:\n",
    "                        records = data['sms']\n",
    "                    elif 'data' in data:\n",
    "                        records = data['data']\n",
    "                    else:\n",
    "                        # Assume the dict itself contains records\n",
    "                        records = [data]\n",
    "                elif isinstance(data, list):\n",
    "                    records = data\n",
    "                else:\n",
    "                    records = []\n",
    "                \n",
    "                print(f\"  Found {len(records)} records in JSON file\")\n",
    "                \n",
    "                for i, record in enumerate(records):\n",
    "                    if isinstance(record, dict):\n",
    "                        # Extract SMS data from JSON fields\n",
    "                        contact = None\n",
    "                        message = None\n",
    "                        timestamp_str = None\n",
    "                        direction = None\n",
    "                        \n",
    "                        # Common JSON field names for SMS data\n",
    "                        contact = (record.get('phone') or record.get('number') or \n",
    "                                  record.get('contact') or record.get('from') or \n",
    "                                  record.get('address') or None)\n",
    "                        \n",
    "                        message = (record.get('body') or record.get('message') or \n",
    "                                  record.get('text') or record.get('content') or \n",
    "                                  record.get('msg') or None)\n",
    "                        \n",
    "                        timestamp_str = (record.get('date') or record.get('time') or \n",
    "                                        record.get('timestamp') or record.get('datetime') or \n",
    "                                        record.get('received_date') or None)\n",
    "                        \n",
    "                        direction = (record.get('type') or record.get('direction') or \n",
    "                                    record.get('status') or None)\n",
    "                        \n",
    "                        # Parse timestamp\n",
    "                        timestamp = parse_timestamp(timestamp_str)\n",
    "                        if not timestamp:\n",
    "                            timestamp = datetime.now() - timedelta(\n",
    "                                days=np.random.randint(1, 90),\n",
    "                                hours=np.random.randint(0, 24)\n",
    "                            )\n",
    "                        \n",
    "                        # Clean up contact\n",
    "                        if not contact or str(contact).strip() == '':\n",
    "                            contact = f\"+1{np.random.randint(200, 999):03}{np.random.randint(1000, 9999):04}\"\n",
    "                        else:\n",
    "                            contact = extract_phone_number(str(contact))\n",
    "                        \n",
    "                        # Clean up message\n",
    "                        if not message or str(message).strip() == '':\n",
    "                            message = f\"SMS message {i+1}\"\n",
    "                        else:\n",
    "                            message = str(message).strip()\n",
    "                        \n",
    "                        # Determine direction\n",
    "                        if direction:\n",
    "                            dir_str = str(direction).lower()\n",
    "                            if any(keyword in dir_str for keyword in ['incoming', 'received', 'in', 'recv']):\n",
    "                                direction = 'INCOMING'\n",
    "                            elif any(keyword in dir_str for keyword in ['outgoing', 'sent', 'out', 'send']):\n",
    "                                direction = 'OUTGOING'\n",
    "                            else:\n",
    "                                direction = 'OUTGOING' if np.random.random() > 0.5 else 'INCOMING'\n",
    "                        else:\n",
    "                            direction = 'OUTGOING' if np.random.random() > 0.5 else 'INCOMING'\n",
    "                        \n",
    "                        sms_data.append({\n",
    "                            'id': f\"SMS_{i+1:06d}\",\n",
    "                            'timestamp': timestamp,\n",
    "                            'contact': contact,\n",
    "                            'direction': direction,\n",
    "                            'message': message,\n",
    "                            'source': 'SMS',\n",
    "                            'raw_data': record\n",
    "                        })\n",
    "        \n",
    "        # ===== HANDLE CSV FILES (YOUR ORIGINAL CODE) =====\n",
    "        else:  \n",
    "            with open(sms_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                # First, let's check the file structure\n",
    "                preview_lines = [next(f) for _ in range(5)]\n",
    "                f.seek(0)\n",
    "                \n",
    "                # Try to detect delimiter\n",
    "                first_line = preview_lines[0]\n",
    "                if ',' in first_line:\n",
    "                    delimiter = ','\n",
    "                    print(f\"  Detected CSV format with comma delimiter\")\n",
    "                elif ';' in first_line:\n",
    "                    delimiter = ';'\n",
    "                    print(f\"  Detected CSV format with semicolon delimiter\")\n",
    "                elif '\\t' in first_line:\n",
    "                    delimiter = '\\t'\n",
    "                    print(f\"  Detected TSV format\")\n",
    "                else:\n",
    "                    delimiter = ','\n",
    "                    print(f\"  Using default comma delimiter\")\n",
    "                \n",
    "                # Read the file\n",
    "                reader = csv.DictReader(f, delimiter=delimiter)\n",
    "                fieldnames = reader.fieldnames\n",
    "                print(f\"  Found columns: {fieldnames}\")\n",
    "                \n",
    "                row_count = 0\n",
    "                for i, row in enumerate(reader):\n",
    "                    row_count += 1\n",
    "                    \n",
    "                    # Extract data with flexible column name matching\n",
    "                    contact = None\n",
    "                    message = None\n",
    "                    timestamp_str = None\n",
    "                    direction = None\n",
    "                    \n",
    "                    # Try to find contact/phone number column\n",
    "                    for col in row:\n",
    "                        if not col:\n",
    "                            continue\n",
    "                        col_lower = col.lower()\n",
    "                        val = row[col]\n",
    "                        \n",
    "                        if not contact and any(keyword in col_lower for keyword in ['phone', 'number', 'address', 'contact', 'from']):\n",
    "                            contact = val\n",
    "                        if not message and any(keyword in col_lower for keyword in ['message', 'body', 'content', 'text']):\n",
    "                            message = val\n",
    "                        if not timestamp_str and any(keyword in col_lower for keyword in ['date', 'time', 'timestamp', 'received', 'sent']):\n",
    "                            timestamp_str = val\n",
    "                        if not direction and any(keyword in col_lower for keyword in ['type', 'direction', 'status']):\n",
    "                            direction = val\n",
    "                    \n",
    "                    # Parse timestamp\n",
    "                    timestamp = parse_timestamp(timestamp_str)\n",
    "                    if not timestamp:\n",
    "                        # Generate realistic timestamp\n",
    "                        timestamp = datetime.now() - timedelta(\n",
    "                            days=np.random.randint(1, 90),\n",
    "                            hours=np.random.randint(0, 24),\n",
    "                            minutes=np.random.randint(0, 60)\n",
    "                        )\n",
    "                    \n",
    "                    # Clean up contact - extract phone number\n",
    "                    if not contact or contact.strip() == '':\n",
    "                        # Generate a realistic phone number\n",
    "                        contact = f\"+1{np.random.randint(200, 999):03}{np.random.randint(1000, 9999):04}\"\n",
    "                    else:\n",
    "                        contact = extract_phone_number(contact)\n",
    "                    \n",
    "                    # Clean up message\n",
    "                    if not message or message.strip() == '':\n",
    "                        message = f\"SMS message {i+1}\"\n",
    "                    else:\n",
    "                        message = str(message).strip()\n",
    "                    \n",
    "                    # Determine direction\n",
    "                    if direction:\n",
    "                        direction_lower = str(direction).lower()\n",
    "                        if any(keyword in direction_lower for keyword in ['incoming', 'received', 'in', 'recv']):\n",
    "                            direction = 'INCOMING'\n",
    "                        elif any(keyword in direction_lower for keyword in ['outgoing', 'sent', 'out', 'send']):\n",
    "                            direction = 'OUTGOING'\n",
    "                        else:\n",
    "                            direction = 'OUTGOING' if np.random.random() > 0.5 else 'INCOMING'\n",
    "                    else:\n",
    "                        direction = 'OUTGOING' if np.random.random() > 0.5 else 'INCOMING'\n",
    "                    \n",
    "                    sms_data.append({\n",
    "                        'id': f\"SMS_{i+1:06d}\",\n",
    "                        'timestamp': timestamp,\n",
    "                        'contact': contact,\n",
    "                        'direction': direction,\n",
    "                        'message': message,\n",
    "                        'source': 'SMS',\n",
    "                        'raw_data': {k: v for k, v in row.items() if k}  # Store original data\n",
    "                    })\n",
    "                    \n",
    "                    # Show progress for large files\n",
    "                    if row_count % 10000 == 0:\n",
    "                        print(f\"  Processed {row_count:,} SMS records...\")\n",
    "        \n",
    "        print(f\" Successfully loaded {len(sms_data):,} SMS records\")\n",
    "        \n",
    "        # Show sample of data\n",
    "        if sms_data:\n",
    "            print(f\"  Sample SMS: {sms_data[0]['contact']} - {sms_data[0]['message'][:50]}...\")\n",
    "        \n",
    "        return sms_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error loading SMS data: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "\n",
    "def extract_phone_number(text):\n",
    "    \"\"\"Extract phone number from text\"\"\"\n",
    "    if not text:\n",
    "        return f\"+1{np.random.randint(200, 999):03}{np.random.randint(1000, 9999):04}\"\n",
    "    \n",
    "    text = str(text).strip()\n",
    "    \n",
    "    # Try to find phone number patterns\n",
    "    patterns = [\n",
    "        r'\\+?\\d{1,3}[-.\\s]?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}',  # International format\n",
    "        r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}',  # US format\n",
    "        r'\\d{10,15}',  # Just digits\n",
    "        r'\\d{3}[-.\\s]?\\d{3}[-.\\s]?\\d{4}',  # 123-456-7890\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            # Clean the number\n",
    "            number = re.sub(r'[^\\d+]', '', match.group())\n",
    "            \n",
    "            # Format as +1XXXXXXXXXX if it's 10 digits\n",
    "            if len(number) == 10:\n",
    "                return f\"+1{number}\"\n",
    "            elif len(number) == 11 and number.startswith('1'):\n",
    "                return f\"+{number}\"\n",
    "            elif number.startswith('+'):\n",
    "                return number\n",
    "            else:\n",
    "                return f\"+{number}\"\n",
    "    \n",
    "    # If no pattern found, try to extract any number-like sequence\n",
    "    numbers = re.findall(r'\\d+', text)\n",
    "    if numbers:\n",
    "        # Join all numbers and take first 10-15 digits\n",
    "        combined = ''.join(numbers)\n",
    "        if 10 <= len(combined) <= 15:\n",
    "            return f\"+1{combined[:10]}\"\n",
    "    \n",
    "    # If still no number, generate a realistic one\n",
    "    return f\"+1{np.random.randint(200, 999):03}{np.random.randint(1000, 9999):04}\"\n",
    "\n",
    "def load_call_data():\n",
    "    \"\"\"Load call data from CDR file (CSV or JSON)\"\"\"\n",
    "    call_data = []\n",
    "    \n",
    "    possible_files = ['CDR-Call-Details.csv', 'call_data.csv', 'calls.json', 'call_log.json', 'cdr.json', 'CallDetails.csv']\n",
    "    \n",
    "    call_file = None\n",
    "    for file in possible_files:\n",
    "        if os.path.exists(file):\n",
    "            call_file = file\n",
    "            break\n",
    "    \n",
    "    if not call_file:\n",
    "        print(f\" No call data file found. Looked for: {possible_files}\")\n",
    "        # Try to auto-detect\n",
    "        json_files = [f for f in os.listdir('.') if f.lower().endswith('.json')]\n",
    "        csv_files = [f for f in os.listdir('.') if f.lower().endswith('.csv')]\n",
    "        \n",
    "        call_keywords = ['call', 'cdr', 'phone', 'dial', 'duration', 'minutes', 'churn']\n",
    "        \n",
    "        # Check JSON files\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    content = f.read()[:1000].lower()\n",
    "                    if any(keyword in content for keyword in call_keywords):\n",
    "                        print(f\"  Found potential call data in: {json_file}\")\n",
    "                        call_file = json_file\n",
    "                        break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # If no JSON found, check CSV files\n",
    "        if not call_file:\n",
    "            for csv_file in csv_files:\n",
    "                try:\n",
    "                    with open(csv_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        first_line = f.readline().lower()\n",
    "                        if any(keyword in first_line for keyword in call_keywords):\n",
    "                            print(f\"  Found potential call data in: {csv_file}\")\n",
    "                            call_file = csv_file\n",
    "                            break\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if not call_file:\n",
    "            print(\"  No call data found. Call analysis will be skipped.\")\n",
    "            return []\n",
    "    \n",
    "    try:\n",
    "        print(f\" Loading call data from {call_file}...\")\n",
    "        \n",
    "        # ===== HANDLE JSON FILES =====\n",
    "        if call_file.lower().endswith('.json'):\n",
    "            with open(call_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                # Handle different JSON structures\n",
    "                if isinstance(data, dict):\n",
    "                    if 'calls' in data:\n",
    "                        records = data['calls']\n",
    "                    elif 'call_log' in data:\n",
    "                        records = data['call_log']\n",
    "                    elif 'data' in data:\n",
    "                        records = data['data']\n",
    "                    elif 'records' in data:\n",
    "                        records = data['records']\n",
    "                    else:\n",
    "                        records = [data]\n",
    "                elif isinstance(data, list):\n",
    "                    records = data\n",
    "                else:\n",
    "                    records = []\n",
    "                \n",
    "                print(f\"  Found {len(records)} records in JSON file\")\n",
    "                \n",
    "                # Generate a date range for the calls\n",
    "                start_date = datetime.now() - timedelta(days=90)\n",
    "                \n",
    "                for i, record in enumerate(records):\n",
    "                    if isinstance(record, dict):\n",
    "                        # Extract call data from JSON fields\n",
    "                        phone_number = (record.get('phone') or record.get('number') or \n",
    "                                       record.get('contact') or record.get('caller') or \n",
    "                                       record.get('destination') or record.get('Phone Number') or\n",
    "                                       record.get('phone_number') or None)\n",
    "                        \n",
    "                        # Handle different duration formats\n",
    "                        duration = 0\n",
    "                        duration_fields = ['duration', 'call_duration', 'seconds', 'mins', 'minutes', \n",
    "                                         'Day Mins', 'Eve Mins', 'Night Mins', 'Intl Mins']\n",
    "                        for field in duration_fields:\n",
    "                            if field in record:\n",
    "                                try:\n",
    "                                    val = record[field]\n",
    "                                    if isinstance(val, (int, float)):\n",
    "                                        if 'mins' in field.lower():\n",
    "                                            duration += float(val) * 60  # Convert minutes to seconds\n",
    "                                        else:\n",
    "                                            duration += float(val)\n",
    "                                    elif isinstance(val, str):\n",
    "                                        if 'mins' in field.lower():\n",
    "                                            duration += float(val.strip()) * 60\n",
    "                                        else:\n",
    "                                            duration += float(val.strip())\n",
    "                                except:\n",
    "                                    pass\n",
    "                        \n",
    "                        if duration == 0:\n",
    "                            duration = np.random.randint(30, 1800)\n",
    "                        \n",
    "                        # Extract call type/status\n",
    "                        call_type = (record.get('type') or record.get('call_type') or \n",
    "                                    record.get('status') or record.get('result') or 'ANSWERED')\n",
    "                        \n",
    "                        # Extract timestamp\n",
    "                        timestamp_str = (record.get('date') or record.get('time') or \n",
    "                                        record.get('timestamp') or record.get('datetime') or \n",
    "                                        record.get('call_date') or None)\n",
    "                        \n",
    "                        # Parse phone number\n",
    "                        if phone_number:\n",
    "                            phone_number = extract_phone_number(str(phone_number))\n",
    "                        else:\n",
    "                            phone_number = f\"+1{np.random.randint(200, 999):03}{np.random.randint(1000, 9999):04}\"\n",
    "                        \n",
    "                        # Parse timestamp\n",
    "                        timestamp = parse_timestamp(timestamp_str)\n",
    "                        if not timestamp:\n",
    "                            days_offset = np.random.randint(0, 90)\n",
    "                            hours_offset = np.random.randint(0, 24)\n",
    "                            timestamp = start_date + timedelta(days=days_offset, hours=hours_offset)\n",
    "                        \n",
    "                        # Extract call details\n",
    "                        day_mins = float(record.get('Day Mins', record.get('day_mins', 0)))\n",
    "                        eve_mins = float(record.get('Eve Mins', record.get('eve_mins', 0)))\n",
    "                        night_mins = float(record.get('Night Mins', record.get('night_mins', 0)))\n",
    "                        intl_mins = float(record.get('Intl Mins', record.get('intl_mins', 0)))\n",
    "                        \n",
    "                        call_details = {\n",
    "                            'day_mins': day_mins,\n",
    "                            'eve_mins': eve_mins,\n",
    "                            'night_mins': night_mins,\n",
    "                            'intl_mins': intl_mins,\n",
    "                            'day_calls': int(record.get('Day Calls', record.get('day_calls', 0))),\n",
    "                            'eve_calls': int(record.get('Eve Calls', record.get('eve_calls', 0))),\n",
    "                            'night_calls': int(record.get('Night Calls', record.get('night_calls', 0))),\n",
    "                            'intl_calls': int(record.get('Intl Calls', record.get('intl_calls', 0))),\n",
    "                            'day_charge': float(record.get('Day Charge', record.get('day_charge', 0))),\n",
    "                            'eve_charge': float(record.get('Eve Charge', record.get('eve_charge', 0))),\n",
    "                            'night_charge': float(record.get('Night Charge', record.get('night_charge', 0))),\n",
    "                            'intl_charge': float(record.get('Intl Charge', record.get('intl_charge', 0))),\n",
    "                            'vmail_messages': int(record.get('VMail Message', record.get('vmail_messages', 0))),\n",
    "                            'account_length': int(record.get('Account Length', record.get('account_length', 0))),\n",
    "                            'churn': str(record.get('Churn', record.get('churn', 'FALSE'))).upper(),\n",
    "                            'custserv_calls': int(record.get('CustServ Calls', record.get('custserv_calls', 0)))\n",
    "                        }\n",
    "                        \n",
    "                        call_data.append({\n",
    "                            'id': f\"CALL_{i+1:06d}\",\n",
    "                            'timestamp': timestamp,\n",
    "                            'contact': phone_number,\n",
    "                            'duration': int(duration),\n",
    "                            'type': str(call_type).upper(),\n",
    "                            'call_details': call_details,\n",
    "                            'source': 'CALL'\n",
    "                        })\n",
    "        \n",
    "        # ===== HANDLE CSV FILES (YOUR ORIGINAL CODE) =====\n",
    "        else:  # CSV file\n",
    "            with open(call_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                # First, check if it's actually the CDR file we expect\n",
    "                first_line = f.readline()\n",
    "                f.seek(0)\n",
    "                \n",
    "                if 'Phone Number' in first_line and 'Day Mins' in first_line:\n",
    "                    print(f\"  Detected CDR call details format\")\n",
    "                else:\n",
    "                    print(f\"  Warning: File may not be in expected CDR format\")\n",
    "                \n",
    "                reader = csv.DictReader(f)\n",
    "                fieldnames = reader.fieldnames\n",
    "                print(f\"  Found columns: {fieldnames}\")\n",
    "                \n",
    "                row_count = 0\n",
    "                # Generate a date range for the calls (last 90 days)\n",
    "                start_date = datetime.now() - timedelta(days=90)\n",
    "                \n",
    "                for i, row in enumerate(reader):\n",
    "                    row_count += 1\n",
    "                    phone_number = row.get('Phone Number', '').strip()\n",
    "                    \n",
    "                    if not phone_number:\n",
    "                        phone_number = f\"+1{np.random.randint(200, 999):03}{np.random.randint(1000, 9999):04}\"\n",
    "                    else:\n",
    "                        phone_number = extract_phone_number(phone_number)\n",
    "                    \n",
    "                    # Calculate total call duration\n",
    "                    try:\n",
    "                        day_mins = float(row.get('Day Mins', 0))\n",
    "                        eve_mins = float(row.get('Eve Mins', 0))\n",
    "                        night_mins = float(row.get('Night Mins', 0))\n",
    "                        intl_mins = float(row.get('Intl Mins', 0))\n",
    "                        total_duration = int((day_mins + eve_mins + night_mins) * 60)  # Convert to seconds\n",
    "                    except:\n",
    "                        total_duration = np.random.randint(30, 1800)\n",
    "                        day_mins = eve_mins = night_mins = intl_mins = 0\n",
    "                    \n",
    "                    # Determine call type based on various factors\n",
    "                    churn = row.get('Churn', 'FALSE').upper()\n",
    "                    custserv_calls = int(row.get('CustServ Calls', 0))\n",
    "                    \n",
    "                    # Create realistic call types\n",
    "                    if total_duration <= 5:  # Very short calls\n",
    "                        call_type = 'MISSED'\n",
    "                    elif total_duration <= 15:  # Short calls\n",
    "                        call_type = 'SHORT_CALL'\n",
    "                    elif churn == 'TRUE' and custserv_calls > 2:\n",
    "                        call_type = 'COMPLAINT'\n",
    "                    elif total_duration > 600:  # Long calls (>10 minutes)\n",
    "                        call_type = 'LONG_CALL'\n",
    "                    elif intl_mins > 10:  # International calls\n",
    "                        call_type = 'INTERNATIONAL'\n",
    "                    else:\n",
    "                        call_type = 'ANSWERED'\n",
    "                    \n",
    "                    # Generate realistic timestamp (spread over 90 days)\n",
    "                    days_offset = np.random.randint(0, 90)\n",
    "                    hours_offset = np.random.randint(0, 24)\n",
    "                    minutes_offset = np.random.randint(0, 60)\n",
    "                    \n",
    "                    timestamp = start_date + timedelta(\n",
    "                        days=days_offset,\n",
    "                        hours=hours_offset,\n",
    "                        minutes=minutes_offset\n",
    "                    )\n",
    "                    \n",
    "                    call_data.append({\n",
    "                        'id': f\"CALL_{i+1:06d}\",\n",
    "                        'timestamp': timestamp,\n",
    "                        'contact': phone_number,\n",
    "                        'duration': total_duration,\n",
    "                        'type': call_type,\n",
    "                        'call_details': {\n",
    "                            'day_mins': day_mins,\n",
    "                            'eve_mins': eve_mins,\n",
    "                            'night_mins': night_mins,\n",
    "                            'intl_mins': intl_mins,\n",
    "                            'day_calls': int(row.get('Day Calls', 0)),\n",
    "                            'eve_calls': int(row.get('Eve Calls', 0)),\n",
    "                            'night_calls': int(row.get('Night Calls', 0)),\n",
    "                            'intl_calls': int(row.get('Intl Calls', 0)),\n",
    "                            'day_charge': float(row.get('Day Charge', 0)),\n",
    "                            'eve_charge': float(row.get('Eve Charge', 0)),\n",
    "                            'night_charge': float(row.get('Night Charge', 0)),\n",
    "                            'intl_charge': float(row.get('Intl Charge', 0)),\n",
    "                            'vmail_messages': int(row.get('VMail Message', 0)),\n",
    "                            'account_length': int(row.get('Account Length', 0)),\n",
    "                            'churn': churn,\n",
    "                            'custserv_calls': custserv_calls\n",
    "                        },\n",
    "                        'source': 'CALL'\n",
    "                    })\n",
    "                    \n",
    "                    # Show progress for large files\n",
    "                    if row_count % 10000 == 0:\n",
    "                        print(f\"  Processed {row_count:,} call records...\")\n",
    "        \n",
    "        print(f\" Successfully loaded {len(call_data):,} call records\")\n",
    "        \n",
    "        # Show statistics\n",
    "        if call_data:\n",
    "            total_duration = sum(c['duration'] for c in call_data)\n",
    "            avg_duration = total_duration / len(call_data) if call_data else 0\n",
    "            print(f\"  Average call duration: {avg_duration:.1f} seconds\")\n",
    "            \n",
    "            # Count call types\n",
    "            call_types = Counter(c['type'] for c in call_data)\n",
    "            print(f\"  Call types: {dict(call_types)}\")\n",
    "        \n",
    "        return call_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error loading call data: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "\n",
    "def load_email_data():\n",
    "    \"\"\"Load email data with multiple file format support (CSV or JSON)\"\"\"\n",
    "    email_data = []\n",
    "    \n",
    "    # Try different possible email file names\n",
    "    possible_files = ['emails.csv', 'email_data.csv', 'emails.json', 'email_data.json', \n",
    "                     'email_messages.csv', 'email_messages.json', 'mail.json']\n",
    "    \n",
    "    email_file = None\n",
    "    for file in possible_files:\n",
    "        if os.path.exists(file):\n",
    "            email_file = file\n",
    "            break\n",
    "    \n",
    "    if not email_file:\n",
    "        print(\" No email data file found. Looking for:\")\n",
    "        for file in possible_files:\n",
    "            print(f\"  ‚Ä¢ {file}\")\n",
    "        \n",
    "        # Try to find any file that might contain email data\n",
    "        print(\"\\n Searching for potential email files...\")\n",
    "        json_files = [f for f in os.listdir('.') if f.lower().endswith('.json')]\n",
    "        csv_files = [f for f in os.listdir('.') if f.lower().endswith('.csv')]\n",
    "        \n",
    "        email_keywords = ['email', 'mail', 'message', 'inbox', 'sent', 'from', 'to', 'subject']\n",
    "        \n",
    "        # Check JSON files first\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    content = f.read()[:1000].lower()\n",
    "                    if any(keyword in content for keyword in email_keywords):\n",
    "                        print(f\"  Found potential email data in: {json_file}\")\n",
    "                        email_file = json_file\n",
    "                        break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # If no JSON found, check CSV files\n",
    "        if not email_file:\n",
    "            for csv_file in csv_files:\n",
    "                try:\n",
    "                    with open(csv_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        first_line = f.readline().lower()\n",
    "                        if any(keyword in first_line for keyword in email_keywords):\n",
    "                            print(f\"  Found potential email data in: {csv_file}\")\n",
    "                            email_file = csv_file\n",
    "                            break\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if not email_file:\n",
    "            print(\"  No email data found. Email analysis will be skipped.\")\n",
    "            return []\n",
    "    \n",
    "    try:\n",
    "        print(f\" Loading email data from {email_file}...\")\n",
    "        \n",
    "        # ===== HANDLE JSON FILES =====\n",
    "        if email_file.lower().endswith('.json'):\n",
    "            with open(email_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                # Handle different JSON structures\n",
    "                if isinstance(data, dict):\n",
    "                    if 'emails' in data:\n",
    "                        records = data['emails']\n",
    "                    elif 'messages' in data:\n",
    "                        records = data['messages']\n",
    "                    elif 'data' in data:\n",
    "                        records = data['data']\n",
    "                    elif 'mail' in data:\n",
    "                        records = data['mail']\n",
    "                    else:\n",
    "                        records = [data]\n",
    "                elif isinstance(data, list):\n",
    "                    records = data\n",
    "                else:\n",
    "                    records = []\n",
    "                \n",
    "                print(f\"  Found {len(records)} records in JSON file\")\n",
    "                \n",
    "                # Generate a date range for emails (last 180 days)\n",
    "                start_date = datetime.now() - timedelta(days=180)\n",
    "                \n",
    "                for i, record in enumerate(records):\n",
    "                    if isinstance(record, dict):\n",
    "                        # Try to identify email fields\n",
    "                        sender = (record.get('from') or record.get('sender') or \n",
    "                                 record.get('From') or record.get('author') or None)\n",
    "                        \n",
    "                        recipient = (record.get('to') or record.get('recipient') or \n",
    "                                    record.get('To') or record.get('receiver') or None)\n",
    "                        \n",
    "                        subject = (record.get('subject') or record.get('Subject') or \n",
    "                                  record.get('title') or record.get('Topic') or None)\n",
    "                        \n",
    "                        body = (record.get('body') or record.get('Body') or \n",
    "                               record.get('content') or record.get('message') or \n",
    "                               record.get('text') or None)\n",
    "                        \n",
    "                        timestamp_str = (record.get('date') or record.get('Date') or \n",
    "                                        record.get('time') or record.get('timestamp') or \n",
    "                                        record.get('datetime') or record.get('sent_date') or None)\n",
    "                        \n",
    "                        # Parse timestamp\n",
    "                        timestamp = parse_timestamp(timestamp_str)\n",
    "                        if not timestamp:\n",
    "                            days_offset = np.random.randint(0, 180)\n",
    "                            hours_offset = np.random.randint(0, 24)\n",
    "                            timestamp = start_date + timedelta(days=days_offset, hours=hours_offset)\n",
    "                        \n",
    "                        # Generate realistic email data if missing\n",
    "                        if not sender or str(sender).strip() == '':\n",
    "                            domains = ['gmail.com', 'yahoo.com', 'hotmail.com', 'company.com', 'outlook.com']\n",
    "                            sender = f\"user{np.random.randint(1, 1000)}@{np.random.choice(domains)}\"\n",
    "                        else:\n",
    "                            sender = str(sender).strip()\n",
    "                        \n",
    "                        if not recipient or str(recipient).strip() == '':\n",
    "                            domains = ['gmail.com', 'yahoo.com', 'hotmail.com', 'company.com', 'outlook.com']\n",
    "                            recipient = f\"recipient{np.random.randint(1, 1000)}@{np.random.choice(domains)}\"\n",
    "                        else:\n",
    "                            recipient = str(recipient).strip()\n",
    "                        \n",
    "                        if not subject or str(subject).strip() == '':\n",
    "                            subjects = [\n",
    "                                'Meeting Request', 'Project Update', 'Important Information',\n",
    "                                'Follow Up', 'Action Required', 'Report Attached',\n",
    "                                'Weekly Summary', 'Question Regarding', 'Urgent: Response Needed'\n",
    "                            ]\n",
    "                            subject = f\"{np.random.choice(subjects)} - {np.random.randint(1, 100)}\"\n",
    "                        else:\n",
    "                            subject = str(subject).strip()\n",
    "                        \n",
    "                        if not body or str(body).strip() == '':\n",
    "                            bodies = [\n",
    "                                'Please find attached the requested document.',\n",
    "                                'Looking forward to your feedback on this matter.',\n",
    "                                'Can we schedule a meeting for next week?',\n",
    "                                'Here is the update you requested.',\n",
    "                                'Please review and let me know your thoughts.',\n",
    "                                'This is in reference to our earlier conversation.'\n",
    "                            ]\n",
    "                            body = np.random.choice(bodies)\n",
    "                        else:\n",
    "                            body = str(body).strip()\n",
    "                        \n",
    "                        email_data.append({\n",
    "                            'id': f\"EMAIL_{i+1:06d}\",\n",
    "                            'timestamp': timestamp,\n",
    "                            'sender': sender,\n",
    "                            'recipient': recipient,\n",
    "                            'subject': subject,\n",
    "                            'body': body,\n",
    "                            'source': 'EMAIL'\n",
    "                        })\n",
    "        \n",
    "        # ===== HANDLE CSV FILES (YOUR ORIGINAL CODE) =====\n",
    "        else:  # CSV file\n",
    "            with open(email_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                # First, understand the file structure\n",
    "                preview_lines = []\n",
    "                for _ in range(10):\n",
    "                    try:\n",
    "                        preview_lines.append(f.readline())\n",
    "                    except:\n",
    "                        break\n",
    "                f.seek(0)\n",
    "                \n",
    "                # Try to detect delimiter\n",
    "                first_line = preview_lines[0]\n",
    "                if ',' in first_line:\n",
    "                    delimiter = ','\n",
    "                    print(f\"  Detected CSV format with comma delimiter\")\n",
    "                elif ';' in first_line:\n",
    "                    delimiter = ';'\n",
    "                    print(f\"  Detected CSV format with semicolon delimiter\")\n",
    "                elif '\\t' in first_line:\n",
    "                    delimiter = '\\t'\n",
    "                    print(f\"  Detected TSV format\")\n",
    "                else:\n",
    "                    delimiter = ','\n",
    "                    print(f\"  Using default comma delimiter\")\n",
    "                \n",
    "                # Try to read as CSV\n",
    "                reader = csv.DictReader(f, delimiter=delimiter)\n",
    "                fieldnames = reader.fieldnames\n",
    "                print(f\"  Found columns: {fieldnames}\")\n",
    "                \n",
    "                # Generate a date range for emails (last 180 days)\n",
    "                start_date = datetime.now() - timedelta(days=180)\n",
    "                \n",
    "                row_count = 0\n",
    "                for i, row in enumerate(reader):\n",
    "                    row_count += 1\n",
    "                    \n",
    "                    # Try to identify email columns\n",
    "                    sender = None\n",
    "                    recipient = None\n",
    "                    subject = None\n",
    "                    body = None\n",
    "                    timestamp_str = None\n",
    "                    \n",
    "                    for col in row:\n",
    "                        if not col:\n",
    "                            continue\n",
    "                        col_lower = col.lower()\n",
    "                        val = row[col]\n",
    "                        \n",
    "                        if not sender and any(keyword in col_lower for keyword in ['from', 'sender', 'author']):\n",
    "                            sender = val\n",
    "                        if not recipient and any(keyword in col_lower for keyword in ['to', 'recipient', 'receiver']):\n",
    "                            recipient = val\n",
    "                        if not subject and any(keyword in col_lower for keyword in ['subject', 'title', 'topic']):\n",
    "                            subject = val\n",
    "                        if not body and any(keyword in col_lower for keyword in ['body', 'content', 'message', 'text']):\n",
    "                            body = val\n",
    "                        if not timestamp_str and any(keyword in col_lower for keyword in ['date', 'time', 'timestamp', 'sent', 'received']):\n",
    "                            timestamp_str = val\n",
    "                    \n",
    "                    # Parse timestamp\n",
    "                    timestamp = parse_timestamp(timestamp_str)\n",
    "                    if not timestamp:\n",
    "                        # Generate realistic timestamp\n",
    "                        days_offset = np.random.randint(0, 180)\n",
    "                        hours_offset = np.random.randint(0, 24)\n",
    "                        timestamp = start_date + timedelta(days=days_offset, hours=hours_offset)\n",
    "                    \n",
    "                    # Generate realistic email data if missing\n",
    "                    if not sender or sender.strip() == '':\n",
    "                        domains = ['gmail.com', 'yahoo.com', 'hotmail.com', 'company.com', 'outlook.com']\n",
    "                        sender = f\"user{np.random.randint(1, 1000)}@{np.random.choice(domains)}\"\n",
    "                    else:\n",
    "                        sender = sender.strip()\n",
    "                    \n",
    "                    if not recipient or recipient.strip() == '':\n",
    "                        domains = ['gmail.com', 'yahoo.com', 'hotmail.com', 'company.com', 'outlook.com']\n",
    "                        recipient = f\"recipient{np.random.randint(1, 1000)}@{np.random.choice(domains)}\"\n",
    "                    else:\n",
    "                        recipient = recipient.strip()\n",
    "                    \n",
    "                    if not subject or subject.strip() == '':\n",
    "                        subjects = [\n",
    "                            'Meeting Request', 'Project Update', 'Important Information',\n",
    "                            'Follow Up', 'Action Required', 'Report Attached',\n",
    "                            'Weekly Summary', 'Question Regarding', 'Urgent: Response Needed'\n",
    "                        ]\n",
    "                        subject = f\"{np.random.choice(subjects)} - {np.random.randint(1, 100)}\"\n",
    "                    else:\n",
    "                        subject = subject.strip()\n",
    "                    \n",
    "                    if not body or body.strip() == '':\n",
    "                        bodies = [\n",
    "                            'Please find attached the requested document.',\n",
    "                            'Looking forward to your feedback on this matter.',\n",
    "                            'Can we schedule a meeting for next week?',\n",
    "                            'Here is the update you requested.',\n",
    "                            'Please review and let me know your thoughts.',\n",
    "                            'This is in reference to our earlier conversation.'\n",
    "                        ]\n",
    "                        body = np.random.choice(bodies)\n",
    "                    else:\n",
    "                        body = body.strip()\n",
    "                    \n",
    "                    email_data.append({\n",
    "                        'id': f\"EMAIL_{i+1:06d}\",\n",
    "                        'timestamp': timestamp,\n",
    "                        'sender': sender,\n",
    "                        'recipient': recipient,\n",
    "                        'subject': subject,\n",
    "                        'body': body,\n",
    "                        'source': 'EMAIL'\n",
    "                    })\n",
    "                    \n",
    "                    # Show progress\n",
    "                    if row_count % 1000 == 0:\n",
    "                        print(f\"  Processed {row_count:,} email records...\")\n",
    "        \n",
    "        print(f\" Successfully loaded {len(email_data):,} email records\")\n",
    "        \n",
    "        if email_data:\n",
    "            print(f\"  Sample email: From {email_data[0]['sender']} - {email_data[0]['subject'][:50]}...\")\n",
    "        \n",
    "        return email_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error loading email data: {e}\")\n",
    "        print(\"  Generating sample email data instead...\")\n",
    "        return generate_sample_email_data()\n",
    "\n",
    "def generate_sample_email_data():\n",
    "    \"\"\"Generate realistic sample email data\"\"\"\n",
    "    print(\" Generating sample email data...\")\n",
    "    \n",
    "    email_data = []\n",
    "    domains = ['gmail.com', 'yahoo.com', 'hotmail.com', 'company.com', 'outlook.com']\n",
    "    \n",
    "    subjects = [\n",
    "        'Meeting Request', 'Project Update', 'Important Information',\n",
    "        'Follow Up', 'Action Required', 'Report Attached',\n",
    "        'Weekly Summary', 'Question Regarding', 'Urgent: Response Needed',\n",
    "        'Budget Approval', 'Team Meeting Notes', 'Client Feedback',\n",
    "        'Contract Review', 'Security Alert', 'System Maintenance'\n",
    "    ]\n",
    "    \n",
    "    bodies = [\n",
    "        'Please find attached the requested document for your review.',\n",
    "        'Looking forward to your feedback on this matter at your earliest convenience.',\n",
    "        'Can we schedule a meeting for next week to discuss the project timeline?',\n",
    "        'Here is the update you requested regarding the quarterly performance.',\n",
    "        'Please review the attached report and let me know your thoughts.',\n",
    "        'This is in reference to our earlier conversation about the budget allocation.',\n",
    "        'The team has completed the first phase of the project successfully.',\n",
    "        'We need to address the security concerns raised in the last audit.',\n",
    "        'Please confirm your availability for the training session next month.',\n",
    "        'Attached are the meeting minutes from yesterday\\'s conference call.'\n",
    "    ]\n",
    "    \n",
    "    # Generate realistic email data\n",
    "    start_date = datetime.now() - timedelta(days=180)\n",
    "    \n",
    "    for i in range(1000):  # Generate 1000 sample emails\n",
    "        days_offset = np.random.randint(0, 180)\n",
    "        hours_offset = np.random.randint(0, 24)\n",
    "        timestamp = start_date + timedelta(days=days_offset, hours=hours_offset)\n",
    "        \n",
    "        sender_domain = np.random.choice(domains)\n",
    "        recipient_domain = np.random.choice(domains)\n",
    "        \n",
    "        sender = f\"user{np.random.randint(1, 100)}@{sender_domain}\"\n",
    "        recipient = f\"contact{np.random.randint(1, 100)}@{recipient_domain}\"\n",
    "        subject = f\"{np.random.choice(subjects)} - Ref: {np.random.randint(1000, 9999)}\"\n",
    "        body = np.random.choice(bodies)\n",
    "        \n",
    "        email_data.append({\n",
    "            'id': f\"SAMPLE_EMAIL_{i+1:06d}\",\n",
    "            'timestamp': timestamp,\n",
    "            'sender': sender,\n",
    "            'recipient': recipient,\n",
    "            'subject': subject,\n",
    "            'body': body,\n",
    "            'source': 'EMAIL'\n",
    "        })\n",
    "    \n",
    "    print(f\"   Generated {len(email_data):,} sample email records\")\n",
    "    return email_data\n",
    "\n",
    "def parse_timestamp(timestamp_str):\n",
    "    \"\"\"Enhanced timestamp parsing with more formats\"\"\"\n",
    "    if not timestamp_str:\n",
    "        return None\n",
    "    \n",
    "    timestamp_str = str(timestamp_str).strip()\n",
    "    \n",
    "    # Common timestamp formats\n",
    "    formats = [\n",
    "        '%Y-%m-%d %H:%M:%S',\n",
    "        '%Y/%m/%d %H:%M:%S',\n",
    "        '%d-%m-%Y %H:%M:%S',\n",
    "        '%d/%m/%Y %H:%M:%S',\n",
    "        '%m/%d/%Y %H:%M:%S',\n",
    "        '%Y-%m-%d %H:%M',\n",
    "        '%Y/%m/%d %H:%M',\n",
    "        '%d-%m-%Y %H:%M',\n",
    "        '%d/%m/%Y %H:%M',\n",
    "        '%m/%d/%Y %H:%M',\n",
    "        '%Y%m%d %H:%M:%S',\n",
    "        '%Y-%m-%d',\n",
    "        '%Y/%m/%d',\n",
    "        '%d-%m-%Y',\n",
    "        '%d/%m/%Y',\n",
    "        '%m/%d/%Y',\n",
    "        '%Y-%m-%dT%H:%M:%S',  # ISO format\n",
    "        '%Y-%m-%dT%H:%M:%SZ',  # ISO with Z\n",
    "        '%Y-%m-%dT%H:%M:%S.%f',  # ISO with microseconds\n",
    "        '%Y-%m-%dT%H:%M:%S.%fZ',  # ISO with microseconds and Z\n",
    "    ]\n",
    "    \n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return datetime.strptime(timestamp_str, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # Try to extract date from string using regex\n",
    "    try:\n",
    "        # Look for date patterns\n",
    "        date_patterns = [\n",
    "            r'(\\d{4})[-/](\\d{1,2})[-/](\\d{1,2})',  # YYYY-MM-DD or YYYY/MM/DD\n",
    "            r'(\\d{1,2})[-/](\\d{1,2})[-/](\\d{4})',  # DD-MM-YYYY or DD/MM/YYYY\n",
    "            r'(\\d{1,2})[-/](\\d{1,2})[-/](\\d{2})',  # DD-MM-YY or DD/MM/YY\n",
    "        ]\n",
    "        \n",
    "        time_patterns = [\n",
    "            r'(\\d{1,2}):(\\d{2}):(\\d{2})',  # HH:MM:SS\n",
    "            r'(\\d{1,2}):(\\d{2})',  # HH:MM\n",
    "        ]\n",
    "        \n",
    "        date_match = None\n",
    "        time_match = None\n",
    "        \n",
    "        for pattern in date_patterns:\n",
    "            match = re.search(pattern, timestamp_str)\n",
    "            if match:\n",
    "                date_match = match\n",
    "                break\n",
    "        \n",
    "        for pattern in time_patterns:\n",
    "            match = re.search(pattern, timestamp_str)\n",
    "            if match:\n",
    "                time_match = match\n",
    "                break\n",
    "        \n",
    "        if date_match:\n",
    "            groups = date_match.groups()\n",
    "            if len(groups[0]) == 4:  # YYYY-MM-DD format\n",
    "                year, month, day = int(groups[0]), int(groups[1]), int(groups[2])\n",
    "            else:\n",
    "                # Try to determine format\n",
    "                if len(groups[2]) == 4:  # DD-MM-YYYY\n",
    "                    day, month, year = int(groups[0]), int(groups[1]), int(groups[2])\n",
    "                else:  # DD-MM-YY\n",
    "                    day, month, year = int(groups[0]), int(groups[1]), int('20' + groups[2])\n",
    "            \n",
    "            hour = minute = second = 0\n",
    "            \n",
    "            if time_match:\n",
    "                time_groups = time_match.groups()\n",
    "                if len(time_groups) == 3:\n",
    "                    hour, minute, second = int(time_groups[0]), int(time_groups[1]), int(time_groups[2])\n",
    "                else:\n",
    "                    hour, minute = int(time_groups[0]), int(time_groups[1])\n",
    "            \n",
    "            return datetime(year, month, day, hour, minute, second)\n",
    "    \n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "def data():\n",
    "    \"\"\"Main data loading function with comprehensive reporting\"\"\"\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\" LOADING DATA FILES\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Check what files exist (both CSV and JSON)\n",
    "    files = os.listdir('.')\n",
    "    data_files = [f for f in files if f.lower().endswith(('.csv', '.json'))]\n",
    "    \n",
    "    print(f\"\\nFound {len(data_files)} data files in current directory:\")\n",
    "    for data_file in data_files:\n",
    "        size = os.path.getsize(data_file)\n",
    "        file_type = \"JSON\" if data_file.lower().endswith('.json') else \"CSV\"\n",
    "        print(f\"  ‚Ä¢ {data_file} ({size:,} bytes) - {file_type}\")\n",
    "    \n",
    "    # Load all three data sources\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    sms_data = load_sms_data()  # Modified to handle JSON\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    call_data = load_call_data()  # Modified to handle JSON\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    email_data = load_email_data()  # Modified to handle JSON\n",
    "    \n",
    "    # Summary\n",
    "    total_records = len(sms_data) + len(call_data) + len(email_data)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\" DATA LOADING SUMMARY\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\" Total records loaded: {total_records:,}\")\n",
    "    print(f\"   ‚Ä¢  SMS Messages: {len(sms_data):,}\")\n",
    "    print(f\"   ‚Ä¢  Phone Calls: {len(call_data):,}\")\n",
    "    print(f\"   ‚Ä¢  Emails: {len(email_data):,}\")\n",
    "    \n",
    "    if total_records == 0:\n",
    "        print(\"\\n  WARNING: No data loaded!\")\n",
    "        print(\"Please ensure you have the following files in the current directory:\")\n",
    "        print(\"  1. SMS-Data.csv\")\n",
    "        print(\"  2. CDR-Call-Details.csv\")\n",
    "        print(\"  3. emails.csv (or any CSV with email data)\")\n",
    "    \n",
    "    return sms_data, call_data, email_data\n",
    "\n",
    "# ============================================================================\n",
    "# ANALYSIS FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def extract_contacts(sms_data, call_data, email_data):\n",
    "    \"\"\"Extract and count contacts from all data sources\"\"\"\n",
    "    contact_counts = Counter()\n",
    "    contact_details = defaultdict(dict)\n",
    "    \n",
    "    # Count SMS contacts\n",
    "    for record in sms_data:\n",
    "        contact = record.get('contact', '').strip()\n",
    "        if contact and contact.lower() not in ['unknown', '', 'null', 'none']:\n",
    "            contact_counts[contact] += 1\n",
    "            if 'sms_count' not in contact_details[contact]:\n",
    "                contact_details[contact]['sms_count'] = 0\n",
    "                contact_details[contact]['last_contact'] = record['timestamp']\n",
    "            contact_details[contact]['sms_count'] += 1\n",
    "            if record['timestamp'] > contact_details[contact]['last_contact']:\n",
    "                contact_details[contact]['last_contact'] = record['timestamp']\n",
    "    \n",
    "    # Count call contacts\n",
    "    for record in call_data:\n",
    "        contact = record.get('contact', '').strip()\n",
    "        if contact and contact.lower() not in ['unknown', '', 'null', 'none']:\n",
    "            contact_counts[contact] += 1\n",
    "            if 'call_count' not in contact_details[contact]:\n",
    "                contact_details[contact]['call_count'] = 0\n",
    "                contact_details[contact]['total_call_duration'] = 0\n",
    "                contact_details[contact]['last_call'] = record['timestamp']\n",
    "            contact_details[contact]['call_count'] += 1\n",
    "            contact_details[contact]['total_call_duration'] += record.get('duration', 0)\n",
    "            if record['timestamp'] > contact_details[contact]['last_call']:\n",
    "                contact_details[contact]['last_call'] = record['timestamp']\n",
    "    \n",
    "    # Count email contacts\n",
    "    for record in email_data:\n",
    "        sender = record.get('sender', '').strip()\n",
    "        recipient = record.get('recipient', '').strip()\n",
    "        \n",
    "        if sender and sender.lower() not in ['unknown', '', 'null', 'none']:\n",
    "            contact_counts[sender] += 1\n",
    "            if 'sent_email_count' not in contact_details[sender]:\n",
    "                contact_details[sender]['sent_email_count'] = 0\n",
    "                contact_details[sender]['last_email_sent'] = record['timestamp']\n",
    "            contact_details[sender]['sent_email_count'] += 1\n",
    "            if record['timestamp'] > contact_details[sender]['last_email_sent']:\n",
    "                contact_details[sender]['last_email_sent'] = record['timestamp']\n",
    "        \n",
    "        if recipient and recipient.lower() not in ['unknown', '', 'null', 'none']:\n",
    "            contact_counts[recipient] += 1\n",
    "            if 'received_email_count' not in contact_details[recipient]:\n",
    "                contact_details[recipient]['received_email_count'] = 0\n",
    "                contact_details[recipient]['last_email_received'] = record['timestamp']\n",
    "            contact_details[recipient]['received_email_count'] += 1\n",
    "            if record['timestamp'] > contact_details[recipient]['last_email_received']:\n",
    "                contact_details[recipient]['last_email_received'] = record['timestamp']\n",
    "    \n",
    "    return contact_counts, contact_details\n",
    "\n",
    "def find_user_phone_number(sms_data, call_data):\n",
    "    \"\"\"Find user's phone number by analyzing communication patterns\"\"\"\n",
    "    print(\"\\n Identifying user's phone number from communication patterns...\")\n",
    "    \n",
    "    # Strategy: Look for a number that appears in multiple contexts but is NOT the main contact\n",
    "    \n",
    "    # Count all phone numbers in SMS data\n",
    "    sms_numbers = Counter()\n",
    "    for sms in sms_data:\n",
    "        number = sms.get('contact', '')\n",
    "        if number and number.startswith('+'):\n",
    "            sms_numbers[number] += 1\n",
    "    \n",
    "    # Count all phone numbers in call data\n",
    "    call_numbers = Counter()\n",
    "    for call in call_data:\n",
    "        number = call.get('contact', '')\n",
    "        if number and number.startswith('+'):\n",
    "            call_numbers[number] += 1\n",
    "    \n",
    "    # Analyze patterns to find user's number\n",
    "    # Typically, user's number is NOT in the call data (CDR shows calls TO user)\n",
    "    # User's number might appear in SMS data if there are multiple devices\n",
    "    \n",
    "    # Find numbers that appear in both incoming and outgoing SMS\n",
    "    outgoing_sms_contacts = Counter()\n",
    "    incoming_sms_contacts = Counter()\n",
    "    \n",
    "    for sms in sms_data:\n",
    "        number = sms.get('contact', '')\n",
    "        if not number or not number.startswith('+'):\n",
    "            continue\n",
    "        \n",
    "        if sms.get('direction') == 'OUTGOING':\n",
    "            outgoing_sms_contacts[number] += 1\n",
    "        elif sms.get('direction') == 'INCOMING':\n",
    "            incoming_sms_contacts[number] += 1\n",
    "    \n",
    "    # Look for the most common pattern:\n",
    "    # 1. Numbers that receive many incoming SMS (could be user)\n",
    "    # 2. But also appear in outgoing SMS (unlikely for user's own number)\n",
    "    \n",
    "    # For forensic analysis, we need to find a number that appears frequently\n",
    "    # but might not be in the contact list\n",
    "    \n",
    "    # Try to find the most frequent number\n",
    "    all_numbers = sms_numbers + call_numbers\n",
    "    if all_numbers:\n",
    "        most_frequent = all_numbers.most_common(1)[0][0]\n",
    "        print(f\"  Most frequently contacted number: {most_frequent}\")\n",
    "        \n",
    "        # Check if this could be the user's number\n",
    "        # Usually, user's own number wouldn't appear in their SMS log\n",
    "        # unless it's synced from another device\n",
    "        \n",
    "        # For demonstration, we'll use the most frequent number as user's number\n",
    "        # In real forensic analysis, this would be verified with other evidence\n",
    "        user_number = most_frequent\n",
    "        \n",
    "        # Provide reasoning\n",
    "        print(f\"  Selected as user's number based on frequency analysis\")\n",
    "        print(f\"  Reason: This number appears {all_numbers[user_number]} times across all communications\")\n",
    "        \n",
    "        return user_number\n",
    "    \n",
    "    return None\n",
    "\n",
    "def categorize_event_with_reasons(record, source_type):\n",
    "    \"\"\"Categorize events for forensic investigation with specific reasons\"\"\"\n",
    "    content = ''\n",
    "    reasons = []\n",
    "    \n",
    "    if source_type == 'SMS':\n",
    "        message = str(record.get('message', '')).lower()\n",
    "        content = message\n",
    "        \n",
    "        # Check for specific suspicious patterns\n",
    "        suspicious_keywords = {\n",
    "            'Financial': ['payment', 'bank', 'transfer', 'money', 'bitcoin', 'crypto', 'pay', 'fund', 'transaction', 'cash', 'deposit', 'withdrawal'],\n",
    "            'Suspicious': ['delete', 'burner', 'encrypt', 'vpn', 'tor', 'secret', 'confidential', 'hide', 'cover', 'erase', 'destroy'],\n",
    "            'Urgent': ['urgent', 'emergency', 'asap', 'immediately', 'quick', 'rush', 'now', 'stat'],\n",
    "            'Coordination': ['meet', 'location', 'address', 'time', 'place', 'venue', 'coordinates', 'where', 'when', 'parking'],\n",
    "            'Spam': ['win', 'free', 'prize', 'offer', 'discount', 'click', 'link', 'http', 'www.', 'congratulations', 'selected'],\n",
    "            'Threatening': ['threat', 'danger', 'warning', 'alert', 'risk', 'dangerous', 'careful'],\n",
    "        }\n",
    "        \n",
    "        for category, keywords in suspicious_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in message:\n",
    "                    reasons.append(f\"{category}: Contains '{keyword}'\")\n",
    "                    break\n",
    "        \n",
    "        # Check for unusual patterns\n",
    "        if len(message) < 10:\n",
    "            reasons.append(\"Short message: Message length < 10 characters\")\n",
    "        \n",
    "        # Check for code words or unusual combinations\n",
    "        unusual_patterns = [r'\\d{4,}', r'[a-z]\\d{3,}', r'\\d{3,}[a-z]']  # 4+ digits, letter+3+digits, 3+digits+letter\n",
    "        for pattern in unusual_patterns:\n",
    "            if re.search(pattern, message):\n",
    "                reasons.append(f\"Unusual pattern: Contains '{pattern}'\")\n",
    "                break\n",
    "    \n",
    "    elif source_type == 'EMAIL':\n",
    "        subject = str(record.get('subject', '')).lower()\n",
    "        body = str(record.get('body', '')).lower()\n",
    "        content = subject + ' ' + body\n",
    "        \n",
    "        # Check for suspicious email content\n",
    "        email_red_flags = {\n",
    "            'Phishing': ['password', 'login', 'account', 'verify', 'security', 'update', 'confirm'],\n",
    "            'Financial': ['invoice', 'payment', 'billing', 'overdue', 'refund', 'charge', 'fee'],\n",
    "            'Suspicious': ['urgent', 'action required', 'immediately', 'important', 'attention'],\n",
    "            'Spam': ['winner', 'selected', 'free', 'offer', 'discount', 'limited time'],\n",
    "            'Malicious': ['attachment', 'download', 'click here', 'link', 'update now'],\n",
    "        }\n",
    "        \n",
    "        for category, keywords in email_red_flags.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in content:\n",
    "                    reasons.append(f\"{category}: Contains '{keyword}'\")\n",
    "                    break\n",
    "        \n",
    "        # Check for suspicious sender/recipient patterns\n",
    "        sender = record.get('sender', '')\n",
    "        if sender and ('anonymous' in sender.lower() or 'noreply' in sender.lower()):\n",
    "            reasons.append(\"Anonymous sender\")\n",
    "        \n",
    "        # Check for suspicious domains\n",
    "        suspicious_domains = ['.ru', '.cn', '.tk', '.ml', '.ga', '.cf', '.xyz']\n",
    "        if any(domain in sender.lower() for domain in suspicious_domains):\n",
    "            reasons.append(\"Suspicious sender domain\")\n",
    "    \n",
    "    elif source_type == 'CALL':\n",
    "        call_type = str(record.get('type', '')).lower()\n",
    "        duration = record.get('duration', 0)\n",
    "        \n",
    "        # Check for suspicious call patterns\n",
    "        if duration <= 5:  # Very short calls\n",
    "            reasons.append(\"Very short call (<5 seconds)\")\n",
    "        elif duration > 3600:  # > 1 hour\n",
    "            reasons.append(\"Extended communication (>1 hour)\")\n",
    "        \n",
    "        # Check international calls\n",
    "        if record.get('call_details', {}).get('intl_mins', 0) > 5:\n",
    "            reasons.append(\"International call (>5 minutes)\")\n",
    "        \n",
    "        # Check for churn risk\n",
    "        if record.get('call_details', {}).get('churn', 'FALSE') == 'TRUE':\n",
    "            reasons.append(\"Churn risk customer\")\n",
    "        \n",
    "        # Check customer service calls\n",
    "        custserv_calls = record.get('call_details', {}).get('custserv_calls', 0)\n",
    "        if custserv_calls > 3:\n",
    "            reasons.append(f\"Multiple customer service calls ({custserv_calls})\")\n",
    "        \n",
    "        # Late night calls\n",
    "        hour = record['timestamp'].hour\n",
    "        if 0 <= hour <= 5:\n",
    "            reasons.append(f\"Late night call ({hour:02d}:00)\")\n",
    "    \n",
    "    # Determine category based on reasons\n",
    "    if reasons:\n",
    "        if any('Financial' in r for r in reasons):\n",
    "            return 'FINANCIAL', reasons\n",
    "        elif any('Suspicious' in r or 'Anonymous' in r for r in reasons):\n",
    "            return 'SUSPICIOUS', reasons\n",
    "        elif any('Urgent' in r for r in reasons):\n",
    "            return 'URGENT', reasons\n",
    "        elif any('International' in r for r in reasons):\n",
    "            return 'INTERNATIONAL', reasons\n",
    "        elif any('Extended' in r or 'long' in r.lower() for r in reasons):\n",
    "            return 'EXTENDED_COMM', reasons\n",
    "        elif any('Spam' in r or 'Phishing' in r for r in reasons):\n",
    "            return 'SPAM', reasons\n",
    "        else:\n",
    "            return 'SUSPICIOUS', reasons\n",
    "    else:\n",
    "        # Check for routine communications\n",
    "        routine_keywords = {\n",
    "            'BUSINESS': ['meeting', 'project', 'report', 'deadline', 'client', 'customer', 'business', 'work'],\n",
    "            'PERSONAL': ['love', 'dear', 'family', 'friend', 'happy', 'birthday', 'miss', 'home', 'dinner'],\n",
    "            'ROUTINE': ['hello', 'hi', 'ok', 'yes', 'no', 'thanks', 'thank you', 'please'],\n",
    "        }\n",
    "        \n",
    "        for category, keywords in routine_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in content.lower():\n",
    "                    return category, [\"Routine communication\"]\n",
    "        \n",
    "        return 'ROUTINE', [\"Normal communication\"]\n",
    "\n",
    "def create_timeline(sms_data, call_data, email_data, user_phone=None):\n",
    "    \"\"\"Create unified timeline from all data sources with reasons\"\"\"\n",
    "    timeline = []\n",
    "    \n",
    "    print(\"\\n Creating unified timeline with detailed categorization...\")\n",
    "    \n",
    "    # Add SMS events\n",
    "    for record in sms_data:\n",
    "        category, reasons = categorize_event_with_reasons(record, 'SMS')\n",
    "        timeline.append({\n",
    "            'id': record['id'],\n",
    "            'timestamp': record['timestamp'],\n",
    "            'contact': record.get('contact', 'Unknown'),\n",
    "            'source': 'SMS',\n",
    "            'type': record.get('direction', 'UNKNOWN'),\n",
    "            'content': str(record.get('message', ''))[:200],\n",
    "            'forensic_tag': category,\n",
    "            'reasons': reasons,\n",
    "            'details': {\n",
    "                'direction': record.get('direction'),\n",
    "                'message_length': len(str(record.get('message', ''))),\n",
    "                'user_involved': user_phone if user_phone else 'Unknown'\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Add call events\n",
    "    for record in call_data:\n",
    "        category, reasons = categorize_event_with_reasons(record, 'CALL')\n",
    "        timeline.append({\n",
    "            'id': record['id'],\n",
    "            'timestamp': record['timestamp'],\n",
    "            'contact': record.get('contact', 'Unknown'),\n",
    "            'source': 'CALL',\n",
    "            'type': record.get('type', 'UNKNOWN'),\n",
    "            'content': f\"Duration: {record.get('duration', 0)}s | Type: {record.get('type', '')}\",\n",
    "            'forensic_tag': category,\n",
    "            'reasons': reasons,\n",
    "            'details': {\n",
    "                'duration': record.get('duration', 0),\n",
    "                'call_type': record.get('type'),\n",
    "                'churn': record.get('call_details', {}).get('churn', 'FALSE'),\n",
    "                'user_involved': user_phone if user_phone else 'Unknown'\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Add email events\n",
    "    for record in email_data:\n",
    "        category, reasons = categorize_event_with_reasons(record, 'EMAIL')\n",
    "        timeline.append({\n",
    "            'id': record['id'],\n",
    "            'timestamp': record['timestamp'],\n",
    "            'contact': record.get('sender', 'Unknown'),\n",
    "            'source': 'EMAIL',\n",
    "            'type': 'SENT',\n",
    "            'content': f\"To: {record.get('recipient', 'Unknown')} | Subject: {str(record.get('subject', ''))[:100]}\",\n",
    "            'forensic_tag': category,\n",
    "            'reasons': reasons,\n",
    "            'details': {\n",
    "                'recipient': record.get('recipient'),\n",
    "                'subject': record.get('subject'),\n",
    "                'body_length': len(str(record.get('body', ''))),\n",
    "                'user_involved': user_phone if user_phone else 'Unknown'\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    timeline.sort(key=lambda x: x['timestamp'])\n",
    "    \n",
    "    print(f\"  Created timeline with {len(timeline):,} events\")\n",
    "    if timeline:\n",
    "        print(f\"  Time range: {timeline[0]['timestamp']} to {timeline[-1]['timestamp']}\")\n",
    "    \n",
    "    return timeline\n",
    "\n",
    "def analyze_data(sms_data, call_data, email_data, user_phone=None):\n",
    "    \"\"\"Enhanced analysis for forensic data\"\"\"\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"DATA ANALYSIS\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_events = len(sms_data) + len(call_data) + len(email_data)\n",
    "    \n",
    "    if total_events == 0:\n",
    "        print(\" No data available for analysis.\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"\\n DATA VOLUME ANALYSIS\")\n",
    "    print(f\"Total Forensic Events: {total_events:,}\")\n",
    "    print(f\"‚Ä¢  SMS Messages: {len(sms_data):,} ({len(sms_data)/total_events*100:.1f}%)\")\n",
    "    print(f\"‚Ä¢  Phone Calls: {len(call_data):,} ({len(call_data)/total_events*100:.1f}%)\")\n",
    "    print(f\"‚Ä¢  Emails: {len(email_data):,} ({len(email_data)/total_events*100:.1f}%)\")\n",
    "    \n",
    "    if user_phone:\n",
    "        print(f\"\\n USER IDENTIFICATION\")\n",
    "        print(f\"User's Phone Number: {user_phone}\")\n",
    "    \n",
    "    # Extract contacts\n",
    "    contact_counts, contact_details = extract_contacts(sms_data, call_data, email_data)\n",
    "    print(f\"\\n CONTACT NETWORK ANALYSIS\")\n",
    "    print(f\"Unique Contacts Found: {len(contact_counts):,}\")\n",
    "    \n",
    "    # Show top contacts\n",
    "    if contact_counts:\n",
    "        top_contacts = contact_counts.most_common(15)\n",
    "        print(f\"\\n TOP 15 MOST ACTIVE CONTACTS\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Rank':<5} {'Contact':<35} {'Total':<8} {'SMS':<8} {'Calls':<8} {'Emails':<10}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for i, (contact, total_count) in enumerate(top_contacts[:15], 1):\n",
    "            details = contact_details.get(contact, {})\n",
    "            sms_count = details.get('sms_count', 0)\n",
    "            call_count = details.get('call_count', 0)\n",
    "            email_sent = details.get('sent_email_count', 0)\n",
    "            email_received = details.get('received_email_count', 0)\n",
    "            email_total = email_sent + email_received\n",
    "            \n",
    "            # Mark user's number if found\n",
    "            contact_display = contact\n",
    "            if user_phone and contact == user_phone:\n",
    "                contact_display = f\"üì± {contact} (USER)\"\n",
    "            \n",
    "            contact_display = contact_display[:32] + \"...\" if len(contact_display) > 32 else contact_display\n",
    "            print(f\"{i:<5} {contact_display:<35} {total_count:<8} {sms_count:<8} {call_count:<8} {email_total:<10}\")\n",
    "    \n",
    "    # Create timeline\n",
    "    timeline = create_timeline(sms_data, call_data, email_data, user_phone)\n",
    "    \n",
    "    if timeline:\n",
    "        # Timeline analysis\n",
    "        start_date = timeline[0]['timestamp']\n",
    "        end_date = timeline[-1]['timestamp']\n",
    "        days_span = max((end_date - start_date).days, 1)\n",
    "        \n",
    "        print(f\"\\n TIMELINE ANALYSIS\")\n",
    "        print(f\"Investigation Period: {days_span} days ({start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')})\")\n",
    "        print(f\"Average daily events: {total_events/days_span:.1f}\")\n",
    "        print(f\"Events per hour: {total_events/(days_span*24):.1f}\")\n",
    "        \n",
    "        # Forensic categories with reasons\n",
    "        print(f\"\\n FORENSIC CATEGORY ANALYSIS\")\n",
    "        categories = Counter(event['forensic_tag'] for event in timeline)\n",
    "        total_categorized = len(timeline)\n",
    "        \n",
    "        print(f\"{'Category':<15} {'Count':>10} {'Percentage':>12}\")\n",
    "        print(\"-\" * 40)\n",
    "        for category, count in categories.most_common():\n",
    "            percentage = (count / total_categorized) * 100\n",
    "            print(f\"{category:<15} {count:>10,} {percentage:>11.1f}%\")\n",
    "        \n",
    "        # Show reasons for suspicious communications\n",
    "        suspicious_events = [e for e in timeline if e['forensic_tag'] in ['SUSPICIOUS', 'FINANCIAL', 'URGENT', 'INTERNATIONAL']]\n",
    "        if suspicious_events:\n",
    "            print(f\"\\n SUSPICIOUS COMMUNICATION REASONS\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            # Count common reasons\n",
    "            reason_counter = Counter()\n",
    "            for event in suspicious_events:\n",
    "                for reason in event.get('reasons', []):\n",
    "                    reason_counter[reason] += 1\n",
    "            \n",
    "            for reason, count in reason_counter.most_common(10):\n",
    "                print(f\"‚Ä¢ {reason}: {count:,} occurrences\")\n",
    "        \n",
    "        # Suspicious patterns with detailed explanations\n",
    "        print(f\"\\n DETAILED RISK ASSESSMENT\")\n",
    "        flags = detect_suspicious_patterns_with_details(timeline, user_phone)\n",
    "        \n",
    "        if flags:\n",
    "            risk_score = min(len(flags) * 10, 100)\n",
    "            print(f\"Overall Risk Score: {risk_score}/100\")\n",
    "            print(\"\\nüî¥ RED FLAGS DETECTED:\")\n",
    "            for flag, explanation in flags:\n",
    "                print(f\"  ‚ö† {flag}\")\n",
    "                print(f\"     {explanation}\")\n",
    "        else:\n",
    "            print(\"No significant red flags detected.\")\n",
    "            print(\"Risk Score: 0/100 (Low Risk)\")\n",
    "    \n",
    "    return timeline\n",
    "\n",
    "def detect_suspicious_patterns_with_details(timeline, user_phone=None):\n",
    "    \"\"\"Detect potentially suspicious patterns with detailed explanations\"\"\"\n",
    "    flags = []\n",
    "    \n",
    "    if not timeline or len(timeline) < 10:\n",
    "        return flags\n",
    "    \n",
    "    total_events = len(timeline)\n",
    "    \n",
    "    # 1. Late-night communications (midnight to 5 AM)\n",
    "    late_night = [e for e in timeline if 0 <= e['timestamp'].hour <= 5]\n",
    "    late_night_percentage = len(late_night) / total_events * 100\n",
    "    if late_night_percentage > 20:  # More than 20% at night\n",
    "        flags.append((\n",
    "            f\"High late-night activity: {len(late_night):,} events ({late_night_percentage:.1f}%)\",\n",
    "            f\"Normal business/personal communications typically occur during daytime. High nighttime activity ({late_night_percentage:.1f}%) may indicate covert communications.\"\n",
    "        ))\n",
    "    \n",
    "    # 2. Rapid communications (multiple events within minutes)\n",
    "    timeline.sort(key=lambda x: x['timestamp'])\n",
    "    rapid_sequences = 0\n",
    "    for i in range(1, len(timeline)):\n",
    "        time_diff = (timeline[i]['timestamp'] - timeline[i-1]['timestamp']).seconds\n",
    "        if time_diff < 30:  # Less than 30 seconds\n",
    "            rapid_sequences += 1\n",
    "    \n",
    "    if rapid_sequences > total_events * 0.05:  # More than 5%\n",
    "        flags.append((\n",
    "            f\"Rapid-fire communications: {rapid_sequences:,} sequences <30s apart\",\n",
    "            f\"Multiple communications within seconds may indicate coordination, panic, or automated communications.\"\n",
    "        ))\n",
    "    \n",
    "    # 3. Unknown contacts\n",
    "    unknown_contacts = sum(1 for e in timeline if 'unknown' in str(e.get('contact', '')).lower())\n",
    "    if unknown_contacts > total_events * 0.1:  # More than 10%\n",
    "        flags.append((\n",
    "            f\"High unknown contacts: {unknown_contacts:,} ({unknown_contacts/total_events*100:.1f}%)\",\n",
    "            f\"High percentage of communications with unknown/unidentified contacts may indicate attempts to hide identities.\"\n",
    "        ))\n",
    "    \n",
    "    # 4. Financial-related communications\n",
    "    financial_events = sum(1 for e in timeline if e.get('forensic_tag') == 'FINANCIAL')\n",
    "    if financial_events > 10:\n",
    "        flags.append((\n",
    "            f\"Financial-related communications: {financial_events:,}\",\n",
    "            f\"Multiple financial-related communications may indicate money transfers, scams, or financial crimes.\"\n",
    "        ))\n",
    "    \n",
    "    # 5. Suspicious keyword communications\n",
    "    suspicious_events = sum(1 for e in timeline if e.get('forensic_tag') == 'SUSPICIOUS')\n",
    "    if suspicious_events > 5:\n",
    "        flags.append((\n",
    "            f\"Suspicious keyword communications: {suspicious_events:,}\",\n",
    "            f\"Communications contain suspicious keywords like 'delete', 'secret', 'encrypt', etc.\"\n",
    "        ))\n",
    "    \n",
    "    # 6. International communications\n",
    "    international_events = sum(1 for e in timeline if e.get('forensic_tag') == 'INTERNATIONAL')\n",
    "    if international_events > 3:\n",
    "        flags.append((\n",
    "            f\"International communications: {international_events:,}\",\n",
    "            f\"International communications may indicate foreign contacts or cross-border activities.\"\n",
    "        ))\n",
    "    \n",
    "    # 7. Extended communications\n",
    "    extended_comms = sum(1 for e in timeline if e.get('forensic_tag') == 'EXTENDED_COMM')\n",
    "    if extended_comms > 2:\n",
    "        flags.append((\n",
    "            f\"Extended communications (>1 hour): {extended_comms:,}\",\n",
    "            f\"Exceptionally long communications may indicate detailed planning or negotiations.\"\n",
    "        ))\n",
    "    \n",
    "    # 8. Activity on weekends\n",
    "    weekend_events = sum(1 for e in timeline if e['timestamp'].weekday() >= 5)  # 5=Sat, 6=Sun\n",
    "    weekend_percentage = weekend_events / total_events * 100\n",
    "    if weekend_percentage > 40:  # More than 40% on weekends\n",
    "        flags.append((\n",
    "            f\"High weekend activity: {weekend_percentage:.1f}%\",\n",
    "            f\"Unusually high weekend activity may indicate non-business related communications or shift work.\"\n",
    "        ))\n",
    "    \n",
    "    # 9. Communications with single contact\n",
    "    contact_counts = Counter(e.get('contact', 'Unknown') for e in timeline)\n",
    "    if contact_counts:\n",
    "        top_contact, top_count = contact_counts.most_common(1)[0]\n",
    "        if top_count > total_events * 0.3:  # More than 30% with one contact\n",
    "            flags.append((\n",
    "                f\"High concentration with single contact: {top_contact[:20]}... ({top_count:,} events, {top_count/total_events*100:.1f}%)\",\n",
    "                f\"Over 30% of all communications are with a single contact, which may indicate a primary relationship or dependency.\"\n",
    "            ))\n",
    "    \n",
    "    # 10. Communications during business hours (if user phone is known)\n",
    "    if user_phone:\n",
    "        business_hours_events = sum(1 for e in timeline if 9 <= e['timestamp'].hour <= 17)\n",
    "        business_percentage = business_hours_events / total_events * 100\n",
    "        if business_percentage < 20:  # Less than 20% during business hours\n",
    "            flags.append((\n",
    "                f\"Low business hours activity: {business_percentage:.1f}%\",\n",
    "                f\"Most communications occur outside normal business hours (9AM-5PM), which may indicate non-work related activities.\"\n",
    "            ))\n",
    "    \n",
    "    return flags[:10]\n",
    "\n",
    "def extract_topic_from_content(content, medium):\n",
    "    \"\"\"Extract potential topics from communication content\"\"\"\n",
    "    if not content:\n",
    "        return None\n",
    "    \n",
    "    content_lower = str(content).lower()\n",
    "    \n",
    "    # Common topics (expand based on your needs)\n",
    "    topic_keywords = {\n",
    "        'MEETING': ['meet', 'meeting', 'appointment', 'schedule', 'calendar', 'venue', 'location'],\n",
    "        'PAYMENT': ['payment', 'money', 'transfer', 'bank', 'cash', 'fund', 'bitcoin', 'crypto'],\n",
    "        'URGENT': ['urgent', 'emergency', 'asap', 'immediately', 'now', 'quick', 'rush'],\n",
    "        'SECURITY': ['secure', 'password', 'login', 'access', 'code', 'key', 'encrypt'],\n",
    "        'BUSINESS': ['project', 'deal', 'contract', 'agreement', 'client', 'customer', 'sale'],\n",
    "        'PERSONAL': ['family', 'home', 'love', 'dear', 'miss', 'happy', 'birthday'],\n",
    "        'TRAVEL': ['travel', 'flight', 'ticket', 'hotel', 'reservation', 'trip', 'airport'],\n",
    "    }\n",
    "    \n",
    "    # Try to extract the most prominent topic\n",
    "    detected_topics = []\n",
    "    for topic, keywords in topic_keywords.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword in content_lower:\n",
    "                detected_topics.append(topic)\n",
    "                break\n",
    "    \n",
    "    # Also extract specific keywords\n",
    "    specific_keywords = []\n",
    "    important_words = ['code', 'password', 'address', 'location', 'time', 'date', 'amount', 'price']\n",
    "    for word in important_words:\n",
    "        if word in content_lower:\n",
    "            specific_keywords.append(word)\n",
    "    \n",
    "    if detected_topics or specific_keywords:\n",
    "        return {\n",
    "            'main_topics': list(set(detected_topics)),\n",
    "            'keywords': specific_keywords\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "def detect_coordinated_communications(timeline, user_phone=None, time_window_minutes=30):\n",
    "    \"\"\"\n",
    "    Detect coordinated communications across multiple channels\n",
    "    \n",
    "    Looks for patterns like:\n",
    "    - SMS ‚Üí Call ‚Üí Email to same person within time window\n",
    "    - Multiple communications to same person across channels\n",
    "    - Same topic discussed across different media\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" MULTI-CHANNEL COMMUNICATION ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if not timeline:\n",
    "        print(\" No timeline data available.\")\n",
    "        return []\n",
    "    \n",
    "    if len(timeline) < 3:\n",
    "        print(\" Insufficient data for pattern detection (need at least 3 events).\")\n",
    "        return []\n",
    "    \n",
    "    coordinated_patterns = []\n",
    "    \n",
    "    # Group communications by contact\n",
    "    communications_by_contact = defaultdict(list)\n",
    "    \n",
    "    for event in timeline:\n",
    "        try:\n",
    "            source, destination, medium, direction, content = get_communication_details(event, user_phone)\n",
    "            \n",
    "            # Determine which contact is not the user\n",
    "            user_id = user_phone if user_phone else \"User's Phone\"\n",
    "            contact = destination if source == user_id else source\n",
    "            \n",
    "            # Skip if contact is user\n",
    "            if contact == user_id:\n",
    "                continue\n",
    "            \n",
    "            # Extract topic (with error handling)\n",
    "            topic_info = None\n",
    "            try:\n",
    "                topic_info = extract_topic_from_content(content, medium)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            communications_by_contact[contact].append({\n",
    "                'event': event,\n",
    "                'timestamp': event['timestamp'],\n",
    "                'medium': medium,\n",
    "                'direction': 'FROM_USER' if source == user_id else 'TO_USER',\n",
    "                'content': content[:100] if content else \"No content\",\n",
    "                'topic': topic_info\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error processing event: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Analyze each contact's communication patterns\n",
    "    for contact, comms in communications_by_contact.items():\n",
    "        if len(comms) < 3:  # Need at least 3 communications for pattern\n",
    "            continue\n",
    "        \n",
    "        # Sort by timestamp\n",
    "        comms_sorted = sorted(comms, key=lambda x: x['timestamp'])\n",
    "        \n",
    "        # Look for multi-channel sequences using sliding window\n",
    "        for i in range(len(comms_sorted) - 2):\n",
    "            try:\n",
    "                current = comms_sorted[i]\n",
    "                next1 = comms_sorted[i + 1]\n",
    "                next2 = comms_sorted[i + 2]\n",
    "                \n",
    "                # Check if all within time window (e.g., 30 minutes)\n",
    "                time_diff1 = (next1['timestamp'] - current['timestamp']).total_seconds() / 60\n",
    "                time_diff2 = (next2['timestamp'] - next1['timestamp']).total_seconds() / 60\n",
    "                \n",
    "                if time_diff1 <= time_window_minutes and time_diff2 <= time_window_minutes:\n",
    "                    # Check if using different media\n",
    "                    media_used = {current['medium'], next1['medium'], next2['medium']}\n",
    "                    \n",
    "                    if len(media_used) >= 2:  # At least 2 different media\n",
    "                        # Check for topic consistency\n",
    "                        topics = []\n",
    "                        for comm in [current, next1, next2]:\n",
    "                            if comm['topic'] and comm['topic'].get('main_topics'):\n",
    "                                topics.extend(comm['topic']['main_topics'])\n",
    "                        \n",
    "                        pattern = {\n",
    "                            'contact': contact,\n",
    "                            'time_start': current['timestamp'],\n",
    "                            'time_end': next2['timestamp'],\n",
    "                            'duration_minutes': (next2['timestamp'] - current['timestamp']).total_seconds() / 60,\n",
    "                            'sequence': [\n",
    "                                (current['medium'], current['direction'], current['content'][:50]),\n",
    "                                (next1['medium'], next1['direction'], next1['content'][:50]),\n",
    "                                (next2['medium'], next2['direction'], next2['content'][:50])\n",
    "                            ],\n",
    "                            'media_used': list(media_used),\n",
    "                            'common_topics': [],\n",
    "                            'pattern_type': 'MULTI_CHANNEL_COORDINATED',\n",
    "                            'risk_level': 'HIGH' if len(media_used) == 3 else 'MEDIUM'\n",
    "                        }\n",
    "                        \n",
    "                        # Find common topics (if any)\n",
    "                        if topics:\n",
    "                            topic_counts = Counter(topics)\n",
    "                            pattern['common_topics'] = [topic for topic, count in topic_counts.items() if count > 1]\n",
    "                        \n",
    "                        coordinated_patterns.append(pattern)\n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: Error analyzing sequence: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Print summary\n",
    "    if coordinated_patterns:\n",
    "        high_risk = [p for p in coordinated_patterns if p['risk_level'] == 'HIGH']\n",
    "        medium_risk = [p for p in coordinated_patterns if p['risk_level'] == 'MEDIUM']\n",
    "        \n",
    "        print(f\"\\nüìä **PATTERN DETECTION SUMMARY:**\")\n",
    "        print(f\"   ‚Ä¢ Total patterns found: {len(coordinated_patterns)}\")\n",
    "        print(f\"   ‚Ä¢ HIGH RISK (3 channels): {len(high_risk)}\")\n",
    "        print(f\"   ‚Ä¢ MEDIUM RISK (2 channels): {len(medium_risk)}\")\n",
    "        \n",
    "        # Show example of SMS‚ÜíCall‚ÜíEmail pattern if exists\n",
    "        sms_call_email = [p for p in high_risk if set(['SMS', 'CALL', 'EMAIL']).issubset(p['media_used'])]\n",
    "        if sms_call_email:\n",
    "            print(f\"\\n‚ö†Ô∏è **EXAMPLE SMS‚ÜíCALL‚ÜíEMAIL PATTERN DETECTED:**\")\n",
    "            example = sms_call_email[0]\n",
    "            print(f\"   Contact: {example['contact'][:30]}...\")\n",
    "            print(f\"   Time window: {example['duration_minutes']:.1f} minutes\")\n",
    "            print(f\"   Sequence:\")\n",
    "            for j, (medium, direction, content) in enumerate(example['sequence'], 1):\n",
    "                arrow = \"‚Üí\" if j < 3 else \"\"\n",
    "                print(f\"      {j}. {medium} {arrow}\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No coordinated multi-channel patterns detected.\")\n",
    "    \n",
    "    return coordinated_patterns\n",
    "\n",
    "def enhanced_suspicious_analysis(timeline, user_phone=None):\n",
    "    \"\"\"Enhanced analysis including multi-channel patterns\"\"\"\n",
    "    # Existing analysis\n",
    "    suspicious_tags = ['SUSPICIOUS', 'FINANCIAL', 'URGENT', 'INTERNATIONAL', 'EXTENDED_COMM', 'SPAM']\n",
    "    suspicious_events = [e for e in timeline if e['forensic_tag'] in suspicious_tags]\n",
    "    \n",
    "    # NEW: Detect coordinated multi-channel communications\n",
    "    coordinated_patterns = detect_coordinated_communications(timeline, user_phone)\n",
    "    \n",
    "    print(f\"\\nüîç COORDINATED MULTI-CHANNEL PATTERNS DETECTED: {len(coordinated_patterns):,}\")\n",
    "    \n",
    "    if coordinated_patterns:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\" DETAILED COORDINATED COMMUNICATION PATTERNS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for i, pattern in enumerate(coordinated_patterns[:10], 1):  # Show top 10\n",
    "            print(f\"\\n{i}. üö® **COORDINATED PATTERN WITH {pattern['contact'][:30]}...**\")\n",
    "            print(f\"   Time: {pattern['time_start'].strftime('%Y-%m-%d %H:%M')} ‚Üí {pattern['time_end'].strftime('%H:%M')}\")\n",
    "            print(f\"   Duration: {pattern['duration_minutes']:.1f} minutes\")\n",
    "            print(f\"   Media Used: {', '.join(pattern['media_used'])}\")\n",
    "            print(f\"   Risk Level: {pattern['risk_level']}\")\n",
    "            \n",
    "            if pattern['common_topics']:\n",
    "                print(f\"   Common Topics: {', '.join(pattern['common_topics'])}\")\n",
    "            \n",
    "            print(f\"   Communication Sequence:\")\n",
    "            for j, (medium, direction, content) in enumerate(pattern['sequence'], 1):\n",
    "                dir_symbol = \"üì§\" if direction == 'FROM_USER' else \"üì•\"\n",
    "                print(f\"     {j}. {dir_symbol} {medium}: {content}...\")\n",
    "            \n",
    "            # Add forensic interpretation\n",
    "            print(f\"\\n   üîç **FORENSIC INTERPRETATION:**\")\n",
    "            if len(pattern['media_used']) == 3:\n",
    "                print(f\"     ‚Ä¢ SMS ‚Üí Call ‚Üí Email pattern detected\")\n",
    "                print(f\"     ‚Ä¢ **HIGH RISK**: Coordinated communication across all major channels\")\n",
    "                print(f\"     ‚Ä¢ Could indicate: Urgent coordination, crisis management, or covert planning\")\n",
    "            else:\n",
    "                print(f\"     ‚Ä¢ Multi-channel communication pattern detected\")\n",
    "                print(f\"     ‚Ä¢ Could indicate: Detailed discussion, confirmation seeking, or layered communication\")\n",
    "    \n",
    "    return coordinated_patterns\n",
    "\n",
    "# ============================================================================\n",
    "# ENHANCED FUNCTIONS FOR CLEAR SOURCE/DESTINATION DISPLAY\n",
    "# ============================================================================\n",
    "\n",
    "def get_communication_details(event, user_phone):\n",
    "    \"\"\"Get clear source and destination details from event\"\"\"\n",
    "    source_type = event.get('source', 'UNKNOWN')\n",
    "    contact = event.get('contact', 'Unknown')\n",
    "    \n",
    "    if source_type == 'SMS':\n",
    "        direction = event.get('type', '').upper()\n",
    "        if direction == 'OUTGOING':\n",
    "            # Outgoing SMS: User sent to contact\n",
    "            source = user_phone if user_phone else \"User's Phone\"\n",
    "            return source, contact, 'SMS', direction, event.get('content', '')\n",
    "        elif direction == 'INCOMING':\n",
    "            # Incoming SMS: Contact sent to user\n",
    "            return contact, user_phone if user_phone else \"User's Phone\", 'SMS', direction, event.get('content', '')\n",
    "        else:\n",
    "            return contact, user_phone if user_phone else \"User's Phone\", 'SMS', 'UNKNOWN', event.get('content', '')\n",
    "    \n",
    "    elif source_type == 'CALL':\n",
    "        call_type = event.get('type', 'UNKNOWN')\n",
    "        # For calls: contact called user\n",
    "        # CDR typically shows the caller's number\n",
    "        source = contact\n",
    "        destination = user_phone if user_phone else \"User's Phone\"\n",
    "        return source, destination, 'CALL', call_type, f\"Duration: {event.get('details', {}).get('duration', 0)}s\"\n",
    "    \n",
    "    elif source_type == 'EMAIL':\n",
    "        sender = contact  # In timeline, contact is sender for emails\n",
    "        recipient = event.get('details', {}).get('recipient', 'Unknown')\n",
    "        subject = event.get('content', '').split('Subject:')[1].strip() if 'Subject:' in event.get('content', '') else 'No Subject'\n",
    "        \n",
    "        # For emails, just show sender and recipient as is\n",
    "        return sender, recipient, 'EMAIL', 'SENT', subject\n",
    "    \n",
    "    return contact, user_phone if user_phone else \"User's Phone\", source_type, 'UNKNOWN', ''\n",
    "\n",
    "def display_timeline_events(timeline, user_phone=None):\n",
    "    \"\"\"Display all timeline events with clear source/destination\"\"\"\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\" TIMELINE EVENTS - ALL COMMUNICATIONS\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    if not timeline:\n",
    "        print(\"No timeline events available.\")\n",
    "        return\n",
    "    \n",
    "    total_events = len(timeline)\n",
    "    print(f\"\\nüìä TOTAL COMMUNICATION EVENTS: {total_events:,}\")\n",
    "    \n",
    "    if user_phone:\n",
    "        print(f\"üì± USER'S PHONE NUMBER: {user_phone}\")\n",
    "    \n",
    "    # Group by communication type\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\" 1. SMS MESSAGES\")\n",
    "    print(\"-\"*120)\n",
    "    sms_events = [e for e in timeline if e['source'] == 'SMS']\n",
    "    if sms_events:\n",
    "        print(f\"\\nTotal SMS Messages: {len(sms_events):,}\")\n",
    "        print(\"\\n\" + \"-\" * 120)\n",
    "        print(f\"{'Time':<20} {'From':<25} {'‚Üí':<3} {'To':<25} {'Direction':<10} {'Category':<15} {'Message':<30}\")\n",
    "        print(\"-\" * 120)\n",
    "        \n",
    "        for event in sms_events[:50]:  # Show first 50 SMS\n",
    "            timestamp = event['timestamp'].strftime('%Y-%m-%d %H:%M')\n",
    "            source, destination, medium, direction, content = get_communication_details(event, user_phone)\n",
    "            \n",
    "            # Truncate long strings\n",
    "            source_display = source[:23] + \"...\" if len(source) > 23 else source\n",
    "            dest_display = destination[:23] + \"...\" if len(destination) > 23 else destination\n",
    "            message_preview = content[:28] + \"...\" if len(content) > 28 else content\n",
    "            \n",
    "            # Show actual direction\n",
    "            actual_direction = \"SENT\" if direction == \"OUTGOING\" else \"RECEIVED\"\n",
    "            \n",
    "            # Show forensic category\n",
    "            category = event.get('forensic_tag', 'ROUTINE')\n",
    "            \n",
    "            print(f\"{timestamp:<20} {source_display:<25} {'‚Üí':<3} {dest_display:<25} {actual_direction:<10} {category:<15} {message_preview:<30}\")\n",
    "        \n",
    "        if len(sms_events) > 50:\n",
    "            print(f\"... and {len(sms_events) - 50:,} more SMS messages\")\n",
    "        \n",
    "        # SMS Statistics\n",
    "        incoming_sms = [e for e in sms_events if e.get('type') == 'INCOMING']\n",
    "        outgoing_sms = [e for e in sms_events if e.get('type') == 'OUTGOING']\n",
    "        print(f\"\\nüì± SMS STATISTICS:\")\n",
    "        print(f\"   ‚Ä¢ Received SMS: {len(incoming_sms):,} ({len(incoming_sms)/len(sms_events)*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Sent SMS: {len(outgoing_sms):,} ({len(outgoing_sms)/len(sms_events)*100:.1f}%)\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No SMS messages found.\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\" 2. PHONE CALLS\")\n",
    "    print(\"-\"*120)\n",
    "    call_events = [e for e in timeline if e['source'] == 'CALL']\n",
    "    if call_events:\n",
    "        print(f\"\\nTotal Phone Calls: {len(call_events):,}\")\n",
    "        print(\"\\n\" + \"-\" * 120)\n",
    "        print(f\"{'Time':<20} {'Caller':<25} {'‚Üí':<3} {'Receiver':<25} {'Call Type':<15} {'Duration':<10} {'Category':<15}\")\n",
    "        print(\"-\" * 120)\n",
    "        \n",
    "        for event in call_events[:50]:  # Show first 50 calls\n",
    "            timestamp = event['timestamp'].strftime('%Y-%m-%d %H:%M')\n",
    "            source, destination, medium, call_type, details = get_communication_details(event, user_phone)\n",
    "            \n",
    "            # Get duration\n",
    "            duration = event.get('details', {}).get('duration', 0)\n",
    "            duration_str = f\"{duration//60}:{duration%60:02d}\" if duration > 60 else f\"{duration}s\"\n",
    "            \n",
    "            # Truncate\n",
    "            source_display = source[:23] + \"...\" if len(source) > 23 else source\n",
    "            dest_display = destination[:23] + \"...\" if len(destination) > 23 else destination\n",
    "            \n",
    "            # Show forensic category\n",
    "            category = event.get('forensic_tag', 'ROUTINE')\n",
    "            \n",
    "            print(f\"{timestamp:<20} {source_display:<25} {'‚Üí':<3} {dest_display:<25} {call_type:<15} {duration_str:<10} {category:<15}\")\n",
    "        \n",
    "        if len(call_events) > 50:\n",
    "            print(f\"... and {len(call_events) - 50:,} more phone calls\")\n",
    "        \n",
    "        # Call Statistics\n",
    "        total_duration = sum(e.get('details', {}).get('duration', 0) for e in call_events)\n",
    "        avg_duration = total_duration / len(call_events) if call_events else 0\n",
    "        \n",
    "        call_types = Counter(e.get('type', 'UNKNOWN') for e in call_events)\n",
    "        print(f\"\\nüìû CALL STATISTICS:\")\n",
    "        print(f\"   ‚Ä¢ Total call duration: {total_duration//3600}h {(total_duration%3600)//60}m {total_duration%60}s\")\n",
    "        print(f\"   ‚Ä¢ Average call duration: {avg_duration:.1f} seconds\")\n",
    "        print(f\"   ‚Ä¢ Call types:\")\n",
    "        for call_type, count in call_types.most_common():\n",
    "            print(f\"      - {call_type}: {count:,}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No phone calls found.\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\" 3. EMAILS\")\n",
    "    print(\"-\"*120)\n",
    "    email_events = [e for e in timeline if e['source'] == 'EMAIL']\n",
    "    if email_events:\n",
    "        print(f\"\\nTotal Emails: {len(email_events):,}\")\n",
    "        print(\"\\n\" + \"-\" * 120)\n",
    "        print(f\"{'Time':<20} {'From':<30} {'‚Üí':<3} {'To':<30} {'Category':<15} {'Subject':<30}\")\n",
    "        print(\"-\" * 120)\n",
    "        \n",
    "        for event in email_events[:50]:  # Show first 50 emails\n",
    "            timestamp = event['timestamp'].strftime('%Y-%m-%d %H:%M')\n",
    "            source, destination, medium, _, subject = get_communication_details(event, user_phone)\n",
    "            \n",
    "            subject_display = (subject[:28] + \"...\") if len(subject) > 28 else subject\n",
    "            \n",
    "            # Truncate\n",
    "            source_display = source[:28] + \"...\" if len(source) > 28 else source\n",
    "            dest_display = destination[:28] + \"...\" if len(destination) > 28 else destination\n",
    "            \n",
    "            # Show forensic category\n",
    "            category = event.get('forensic_tag', 'ROUTINE')\n",
    "            \n",
    "            print(f\"{timestamp:<20} {source_display:<30} {'‚Üí':<3} {dest_display:<30} {category:<15} {subject_display:<30}\")\n",
    "        \n",
    "        if len(email_events) > 50:\n",
    "            print(f\"... and {len(email_events) - 50:,} more emails\")\n",
    "        \n",
    "        # Email Statistics\n",
    "        unique_senders = set()\n",
    "        unique_recipients = set()\n",
    "        for event in email_events:\n",
    "            source, destination, _, _, _ = get_communication_details(event, user_phone)\n",
    "            unique_senders.add(source)\n",
    "            unique_recipients.add(destination)\n",
    "        \n",
    "        print(f\"\\nüìß EMAIL STATISTICS:\")\n",
    "        print(f\"   ‚Ä¢ Unique senders: {len(unique_senders):,}\")\n",
    "        print(f\"   ‚Ä¢ Unique recipients: {len(unique_recipients):,}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No emails found.\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\" COMMUNICATION SUMMARY\")\n",
    "    print(\"-\"*120)\n",
    "    print(f\"\\nüìà TOTAL EVENTS: {total_events:,}\")\n",
    "    print(f\"   ‚Ä¢ SMS Messages: {len(sms_events):,} ({len(sms_events)/total_events*100:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ Phone Calls: {len(call_events):,} ({len(call_events)/total_events*100:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ Emails: {len(email_events):,} ({len(email_events)/total_events*100:.1f}%)\")\n",
    "    \n",
    "    # Time range\n",
    "    if timeline:\n",
    "        earliest = timeline[0]['timestamp']\n",
    "        latest = timeline[-1]['timestamp']\n",
    "        days_span = (latest - earliest).days + 1\n",
    "        print(f\"\\nüìÖ TIME RANGE: {earliest.strftime('%Y-%m-%d')} to {latest.strftime('%Y-%m-%d')}\")\n",
    "        print(f\"   ‚Ä¢ Duration: {days_span} days\")\n",
    "        print(f\"   ‚Ä¢ Average daily events: {total_events/days_span:.1f}\")\n",
    "        \n",
    "        # Most active day\n",
    "        daily_counts = {}\n",
    "        for event in timeline:\n",
    "            date = event['timestamp'].date()\n",
    "            daily_counts[date] = daily_counts.get(date, 0) + 1\n",
    "        \n",
    "        if daily_counts:\n",
    "            busiest_date = max(daily_counts, key=daily_counts.get)\n",
    "            print(f\"   ‚Ä¢ Busiest day: {busiest_date} ({daily_counts[busiest_date]:,} events)\")\n",
    "\n",
    "def view_detailed_analysis(timeline, sms_data, call_data, email_data, user_phone=None):\n",
    "    \"\"\"Display detailed analysis with source/destination information\"\"\"\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\" DETAILED COMMUNICATION ANALYSIS\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    if not timeline:\n",
    "        print(\"No timeline data available.\")\n",
    "        return\n",
    "    \n",
    "    total_events = len(timeline)\n",
    "    print(f\"\\nüìä TOTAL COMMUNICATION EVENTS: {total_events:,}\")\n",
    "    \n",
    "    if user_phone:\n",
    "        print(f\"üì± USER'S PHONE NUMBER: {user_phone}\")\n",
    "    \n",
    "    # 1. Communication Flow Analysis\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\" 1. COMMUNICATION FLOW ANALYSIS\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    # Count communications by type with source/destination\n",
    "    communication_flows = defaultdict(int)\n",
    "    \n",
    "    for event in timeline:\n",
    "        source, destination, medium, direction, _ = get_communication_details(event, user_phone)\n",
    "        flow_key = f\"{source} ‚Üí {destination}\"\n",
    "        communication_flows[flow_key] += 1\n",
    "    \n",
    "    # Show top communication flows\n",
    "    print(\"\\nTOP COMMUNICATION FLOWS:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Rank':<5} {'From ‚Üí To':<50} {'Count':<10} {'%':<8}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    sorted_flows = sorted(communication_flows.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, (flow, count) in enumerate(sorted_flows[:20], 1):\n",
    "        percentage = (count / total_events) * 100\n",
    "        flow_display = flow[:48] + \"...\" if len(flow) > 48 else flow\n",
    "        print(f\"{i:<5} {flow_display:<50} {count:<10,} {percentage:>7.1f}%\")\n",
    "    \n",
    "    # 2. Contact Analysis\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\" 2. CONTACT ANALYSIS\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    contact_counts, contact_details = extract_contacts(sms_data, call_data, email_data)\n",
    "    print(f\"\\nüë• UNIQUE CONTACTS: {len(contact_counts):,}\")\n",
    "    \n",
    "    # Show incoming communications (to user)\n",
    "    incoming_communications = Counter()\n",
    "    # Show outgoing communications (from user)\n",
    "    outgoing_communications = Counter()\n",
    "    \n",
    "    for event in timeline:\n",
    "        source, destination, medium, direction, _ = get_communication_details(event, user_phone)\n",
    "        \n",
    "        # Determine if this is incoming or outgoing relative to user\n",
    "        user_identifier = user_phone if user_phone else \"User's Phone\"\n",
    "        \n",
    "        if destination == user_identifier and source != user_identifier:\n",
    "            # Incoming communication to user\n",
    "            incoming_communications[source] += 1\n",
    "        \n",
    "        if source == user_identifier and destination != user_identifier:\n",
    "            # Outgoing communication from user\n",
    "            outgoing_communications[destination] += 1\n",
    "    \n",
    "    if incoming_communications:\n",
    "        print(f\"\\nüì• COMMUNICATIONS RECEIVED BY USER:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Rank':<5} {'From':<40} {'Count':<10} {'%':<8}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        total_incoming = sum(incoming_communications.values())\n",
    "        for i, (contact, count) in enumerate(incoming_communications.most_common(15), 1):\n",
    "            percentage = (count / total_incoming) * 100\n",
    "            contact_display = contact[:38] + \"...\" if len(contact) > 38 else contact\n",
    "            print(f\"{i:<5} {contact_display:<40} {count:<10,} {percentage:>7.1f}%\")\n",
    "    \n",
    "    if outgoing_communications:\n",
    "        print(f\"\\nüì§ COMMUNICATIONS SENT BY USER:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Rank':<5} {'To':<40} {'Count':<10} {'%':<8}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        total_outgoing = sum(outgoing_communications.values())\n",
    "        for i, (contact, count) in enumerate(outgoing_communications.most_common(15), 1):\n",
    "            percentage = (count / total_outgoing) * 100\n",
    "            contact_display = contact[:38] + \"...\" if len(contact) > 38 else contact\n",
    "            print(f\"{i:<5} {contact_display:<40} {count:<10,} {percentage:>7.1f}%\")\n",
    "    \n",
    "    # 3. Communication Pattern Analysis\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\" 3. COMMUNICATION PATTERNS\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    # Analyze communication patterns by type\n",
    "    communication_patterns = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for event in timeline:\n",
    "        source, destination, medium, direction, _ = get_communication_details(event, user_phone)\n",
    "        pattern_key = f\"{source} ‚Üî {destination}\"\n",
    "        communication_patterns[pattern_key][medium] += 1\n",
    "    \n",
    "    print(f\"\\nTOP COMMUNICATION PATTERNS BY MEDIUM:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Rank':<5} {'Parties':<40} {'SMS':<8} {'Calls':<8} {'Emails':<8} {'Total':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    # Calculate total communications per pattern\n",
    "    pattern_totals = []\n",
    "    for pattern, mediums in communication_patterns.items():\n",
    "        total = sum(mediums.values())\n",
    "        pattern_totals.append((pattern, total, mediums))\n",
    "    \n",
    "    # Sort by total communications\n",
    "    pattern_totals.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for i, (pattern, total, mediums) in enumerate(pattern_totals[:15], 1):\n",
    "        pattern_display = pattern[:38] + \"...\" if len(pattern) > 38 else pattern\n",
    "        print(f\"{i:<5} {pattern_display:<40} \"\n",
    "              f\"{mediums.get('SMS', 0):<8} \"\n",
    "              f\"{mediums.get('CALL', 0):<8} \"\n",
    "              f\"{mediums.get('EMAIL', 0):<8} \"\n",
    "              f\"{total:<10,}\")\n",
    "    \n",
    "    # 4. Temporal Analysis\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\" 4. TEMPORAL ANALYSIS\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    timeline_sorted = sorted(timeline, key=lambda x: x['timestamp'])\n",
    "    if timeline_sorted:\n",
    "        earliest = timeline_sorted[0]['timestamp']\n",
    "        latest = timeline_sorted[-1]['timestamp']\n",
    "        days_span = (latest - earliest).days + 1\n",
    "        \n",
    "        print(f\"\\nüìÖ INVESTIGATION PERIOD: {days_span} days\")\n",
    "        print(f\"   ‚Ä¢ From: {earliest.strftime('%Y-%m-%d %H:%M')}\")\n",
    "        print(f\"   ‚Ä¢ To: {latest.strftime('%Y-%m-%d %H:%M')}\")\n",
    "        print(f\"   ‚Ä¢ Average daily communications: {total_events/days_span:.1f}\")\n",
    "        \n",
    "        # Busiest hours\n",
    "        hourly_counts = {hour: 0 for hour in range(24)}\n",
    "        for event in timeline:\n",
    "            hour = event['timestamp'].hour\n",
    "            hourly_counts[hour] += 1\n",
    "        \n",
    "        peak_hour = max(hourly_counts, key=hourly_counts.get)\n",
    "        print(f\"\\n‚è∞ PEAK ACTIVITY HOUR: {peak_hour:02d}:00 ({hourly_counts[peak_hour]:,} events)\")\n",
    "        \n",
    "        # Communication by time of day\n",
    "        morning = sum(hourly_counts[h] for h in range(6, 12))\n",
    "        afternoon = sum(hourly_counts[h] for h in range(12, 18))\n",
    "        evening = sum(hourly_counts[h] for h in range(18, 24))\n",
    "        night = sum(hourly_counts[h] for h in range(0, 6))\n",
    "        \n",
    "        print(f\"\\nüåÖ COMMUNICATION BY TIME OF DAY:\")\n",
    "        print(f\"   ‚Ä¢ Morning (6AM-12PM): {morning:,} ({morning/total_events*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Afternoon (12PM-6PM): {afternoon:,} ({afternoon/total_events*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Evening (6PM-12AM): {evening:,} ({evening/total_events*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Night (12AM-6AM): {night:,} ({night/total_events*100:.1f}%)\")\n",
    "    \n",
    "    # 5. Forensic Category Analysis with Reasons\n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\" 5. FORENSIC CATEGORY ANALYSIS WITH REASONS\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    # Group events by category and collect reasons\n",
    "    category_events = defaultdict(list)\n",
    "    for event in timeline:\n",
    "        category = event.get('forensic_tag', 'ROUTINE')\n",
    "        category_events[category].append(event)\n",
    "    \n",
    "    # Show categories with example reasons\n",
    "    suspicious_categories = ['SUSPICIOUS', 'FINANCIAL', 'URGENT', 'INTERNATIONAL', 'EXTENDED_COMM', 'SPAM']\n",
    "    \n",
    "    for category in suspicious_categories:\n",
    "        if category_events[category]:\n",
    "            events = category_events[category]\n",
    "            print(f\"\\nüîç {category} COMMUNICATIONS: {len(events):,} events\")\n",
    "            \n",
    "            # Show top reasons for this category\n",
    "            reason_counter = Counter()\n",
    "            for event in events[:100]:  # Check first 100 events for reasons\n",
    "                for reason in event.get('reasons', []):\n",
    "                    reason_counter[reason] += 1\n",
    "            \n",
    "            if reason_counter:\n",
    "                print(f\"   Top reasons for {category} classification:\")\n",
    "                for reason, count in reason_counter.most_common(5):\n",
    "                    print(f\"      ‚Ä¢ {reason}: {count:,} occurrences\")\n",
    "            \n",
    "            # Show example events\n",
    "            if len(events) > 0:\n",
    "                print(f\"   Example {category.lower()} communication:\")\n",
    "                example = events[0]\n",
    "                timestamp = example['timestamp'].strftime('%Y-%m-%d %H:%M')\n",
    "                source, destination, medium, _, content = get_communication_details(example, user_phone)\n",
    "                print(f\"      Time: {timestamp}\")\n",
    "                print(f\"      From: {source}\")\n",
    "                print(f\"      To: {destination}\")\n",
    "                print(f\"      Content: {content[:100]}...\")\n",
    "                if example.get('reasons'):\n",
    "                    print(f\"      Reasons: {', '.join(example['reasons'][:3])}\")\n",
    "\n",
    "def suspicious_communications_analysis(timeline, user_phone=None):\n",
    "    \"\"\"Analyze and display suspicious communications with detailed reasons\"\"\"\n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\" SUSPICIOUS COMMUNICATIONS ANALYSIS\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    if not timeline:\n",
    "        print(\"No timeline data available.\")\n",
    "        return\n",
    "    \n",
    "    if user_phone:\n",
    "        print(f\"üì± USER'S PHONE NUMBER: {user_phone}\")\n",
    "    \n",
    "    # Get suspicious events based on forensic tags\n",
    "    suspicious_tags = ['SUSPICIOUS', 'FINANCIAL', 'URGENT', 'INTERNATIONAL', 'EXTENDED_COMM', 'SPAM']\n",
    "    suspicious_events = [e for e in timeline if e['forensic_tag'] in suspicious_tags]\n",
    "    \n",
    "    total_events = len(timeline)\n",
    "    suspicious_count = len(suspicious_events)\n",
    "    \n",
    "    print(f\"\\nüîç SUSPICIOUS COMMUNICATIONS DETECTED: {suspicious_count:,} of {total_events:,} total events\")\n",
    "    print(f\"   ‚Ä¢ Suspicious Rate: {suspicious_count/total_events*100:.1f}%\")\n",
    "    \n",
    "    if suspicious_events:\n",
    "        # Group by suspicious category with detailed breakdown\n",
    "        print(\"\\n\" + \"-\"*120)\n",
    "        print(\" DETAILED SUSPICIOUS COMMUNICATIONS BREAKDOWN\")\n",
    "        print(\"-\"*120)\n",
    "        \n",
    "        # Create detailed breakdown by category\n",
    "        category_details = defaultdict(lambda: {\n",
    "            'count': 0,\n",
    "            'reasons': Counter(),\n",
    "            'contacts': Counter(),\n",
    "            'times': []\n",
    "        })\n",
    "        \n",
    "        for event in suspicious_events:\n",
    "            category = event['forensic_tag']\n",
    "            details = category_details[category]\n",
    "            details['count'] += 1\n",
    "            \n",
    "            # Count reasons\n",
    "            for reason in event.get('reasons', []):\n",
    "                details['reasons'][reason] += 1\n",
    "            \n",
    "            # Count contacts\n",
    "            contact = event.get('contact', 'Unknown')\n",
    "            details['contacts'][contact] += 1\n",
    "            \n",
    "            # Record time\n",
    "            details['times'].append(event['timestamp'])\n",
    "        \n",
    "        # Display detailed breakdown\n",
    "        print(f\"\\n{'Category':<20} {'Count':>10} {'% of Suspicious':>15} {'Top Reason':<40} {'Risk':<10}\")\n",
    "        print(\"-\" * 95)\n",
    "        \n",
    "        for category, details in sorted(category_details.items(), key=lambda x: x[1]['count'], reverse=True):\n",
    "            count = details['count']\n",
    "            percentage = (count / suspicious_count) * 100\n",
    "            \n",
    "            # Get top reason\n",
    "            top_reason = \"Unknown\"\n",
    "            if details['reasons']:\n",
    "                top_reason, reason_count = details['reasons'].most_common(1)[0]\n",
    "                top_reason = f\"{top_reason} ({reason_count}x)\"\n",
    "            \n",
    "            # Determine risk level\n",
    "            if category in ['SUSPICIOUS', 'FINANCIAL']:\n",
    "                risk = 'HIGH'\n",
    "            elif category in ['URGENT', 'INTERNATIONAL']:\n",
    "                risk = 'MEDIUM'\n",
    "            else:\n",
    "                risk = 'LOW'\n",
    "            \n",
    "            print(f\"{category:<20} {count:>10,} {percentage:>14.1f}% {top_reason:<40} {risk:<10}\")\n",
    "        \n",
    "        # Show detailed suspicious communications with reasons\n",
    "        print(\"\\n\" + \"-\"*120)\n",
    "        print(\" DETAILED SUSPICIOUS COMMUNICATIONS WITH REASONS\")\n",
    "        print(\"-\"*120)\n",
    "        \n",
    "        print(f\"\\nShowing {min(15, len(suspicious_events))} of {len(suspicious_events):,} suspicious communications:\")\n",
    "        print(\"\\n\" + \"-\" * 140)\n",
    "        print(f\"{'No.':<4} {'Time':<18} {'From':<25} {'‚Üí':<3} {'To':<25} {'Medium':<8} {'Category':<15} {'Reasons':<60}\")\n",
    "        print(\"-\" * 140)\n",
    "        \n",
    "        for i, event in enumerate(suspicious_events[:15], 1):\n",
    "            timestamp = event['timestamp'].strftime('%m-%d %H:%M')\n",
    "            source, destination, medium, _, content = get_communication_details(event, user_phone)\n",
    "            \n",
    "            # Truncate\n",
    "            source_display = source[:23] + \"...\" if len(source) > 23 else source\n",
    "            dest_display = destination[:23] + \"...\" if len(destination) > 23 else destination\n",
    "            \n",
    "            # Get reasons (truncate if too many)\n",
    "            reasons = event.get('reasons', [])\n",
    "            if len(reasons) > 2:\n",
    "                reasons_display = ', '.join(reasons[:2]) + f\" (+{len(reasons)-2} more)\"\n",
    "            else:\n",
    "                reasons_display = ', '.join(reasons)\n",
    "            \n",
    "            reasons_display = reasons_display[:58] + \"...\" if len(reasons_display) > 58 else reasons_display\n",
    "            \n",
    "            print(f\"{i:<4} {timestamp:<18} {source_display:<25} {'‚Üí':<3} {dest_display:<25} {medium:<8} {event['forensic_tag']:<15} {reasons_display:<60}\")\n",
    "        \n",
    "        if len(suspicious_events) > 15:\n",
    "            print(f\"\\n... and {len(suspicious_events) - 15:,} more suspicious communications\")\n",
    "        \n",
    "        # Show most suspicious contacts\n",
    "        print(\"\\n\" + \"-\"*120)\n",
    "        print(\" MOST SUSPICIOUS CONTACTS\")\n",
    "        print(\"-\"*120)\n",
    "        \n",
    "        # Count suspicious communications by contact\n",
    "        contact_suspicion = Counter()\n",
    "        contact_reasons = defaultdict(set)\n",
    "        \n",
    "        for event in suspicious_events:\n",
    "            source, destination, _, _, _ = get_communication_details(event, user_phone)\n",
    "            \n",
    "            # Don't count user\n",
    "            user_identifier = user_phone if user_phone else \"User's Phone\"\n",
    "            if source != user_identifier:\n",
    "                contact_suspicion[source] += 1\n",
    "                for reason in event.get('reasons', []):\n",
    "                    contact_reasons[source].add(reason)\n",
    "            \n",
    "            if destination != user_identifier:\n",
    "                contact_suspicion[destination] += 1\n",
    "                for reason in event.get('reasons', []):\n",
    "                    contact_reasons[destination].add(reason)\n",
    "        \n",
    "        if contact_suspicion:\n",
    "            print(f\"\\nContacts with suspicious communications:\")\n",
    "            print(\"-\" * 100)\n",
    "            print(f\"{'Rank':<5} {'Contact':<40} {'Suspicious Count':<20} {'Example Reasons':<40}\")\n",
    "            print(\"-\" * 100)\n",
    "            \n",
    "            for i, (contact, count) in enumerate(contact_suspicion.most_common(10), 1):\n",
    "                contact_display = contact[:38] + \"...\" if len(contact) > 38 else contact\n",
    "                \n",
    "                # Get example reasons\n",
    "                reasons = list(contact_reasons.get(contact, set()))\n",
    "                if len(reasons) > 3:\n",
    "                    reasons_display = ', '.join(reasons[:3]) + f\" (+{len(reasons)-3} more)\"\n",
    "                else:\n",
    "                    reasons_display = ', '.join(reasons)\n",
    "                \n",
    "                reasons_display = reasons_display[:38] + \"...\" if len(reasons_display) > 38 else reasons_display\n",
    "                \n",
    "                print(f\"{i:<5} {contact_display:<40} {count:<20,} {reasons_display:<40}\")\n",
    "        \n",
    "        # Risk Assessment with detailed scoring\n",
    "        print(\"\\n\" + \"-\"*120)\n",
    "        print(\" DETAILED RISK ASSESSMENT\")\n",
    "        print(\"-\"*120)\n",
    "        \n",
    "        # Calculate risk score based on multiple factors\n",
    "        risk_factors = []\n",
    "        total_risk_score = 0\n",
    "        max_risk_score = 0\n",
    "        \n",
    "        # Factor 1: Number of suspicious events\n",
    "        suspicious_ratio = suspicious_count / total_events\n",
    "        if suspicious_ratio > 0.3:\n",
    "            factor_score = 30\n",
    "            risk_factors.append((\"High volume of suspicious communications (>{:.1f}%)\".format(suspicious_ratio*100), factor_score))\n",
    "        elif suspicious_ratio > 0.1:\n",
    "            factor_score = 20\n",
    "            risk_factors.append((\"Moderate volume of suspicious communications (>{:.1f}%)\".format(suspicious_ratio*100), factor_score))\n",
    "        elif suspicious_ratio > 0.05:\n",
    "            factor_score = 10\n",
    "            risk_factors.append((\"Some suspicious communications (>{:.1f}%)\".format(suspicious_ratio*100), factor_score))\n",
    "        else:\n",
    "            factor_score = 5\n",
    "            risk_factors.append((\"Low volume of suspicious communications\", factor_score))\n",
    "        \n",
    "        total_risk_score += factor_score\n",
    "        max_risk_score += 30\n",
    "        \n",
    "        # Factor 2: High-risk categories\n",
    "        high_risk_events = sum(1 for e in suspicious_events if e['forensic_tag'] in ['SUSPICIOUS', 'FINANCIAL'])\n",
    "        if high_risk_events > 10:\n",
    "            factor_score = 25\n",
    "            risk_factors.append((f\"Multiple high-risk communications ({high_risk_events})\", factor_score))\n",
    "        elif high_risk_events > 5:\n",
    "            factor_score = 15\n",
    "            risk_factors.append((f\"Several high-risk communications ({high_risk_events})\", factor_score))\n",
    "        elif high_risk_events > 0:\n",
    "            factor_score = 5\n",
    "            risk_factors.append((f\"Some high-risk communications ({high_risk_events})\", factor_score))\n",
    "        else:\n",
    "            factor_score = 0\n",
    "            risk_factors.append((\"No high-risk communications detected\", factor_score))\n",
    "        \n",
    "        total_risk_score += factor_score\n",
    "        max_risk_score += 25\n",
    "        \n",
    "        # Factor 3: Time patterns\n",
    "        late_night = sum(1 for e in suspicious_events if 0 <= e['timestamp'].hour <= 5)\n",
    "        late_night_ratio = late_night / suspicious_count if suspicious_count > 0 else 0\n",
    "        if late_night_ratio > 0.3:\n",
    "            factor_score = 20\n",
    "            risk_factors.append((f\"High late-night suspicious activity ({late_night_ratio*100:.1f}%)\", factor_score))\n",
    "        elif late_night_ratio > 0.1:\n",
    "            factor_score = 10\n",
    "            risk_factors.append((f\"Moderate late-night suspicious activity ({late_night_ratio*100:.1f}%)\", factor_score))\n",
    "        else:\n",
    "            factor_score = 0\n",
    "            risk_factors.append((\"Normal time distribution for suspicious communications\", factor_score))\n",
    "        \n",
    "        total_risk_score += factor_score\n",
    "        max_risk_score += 20\n",
    "        \n",
    "        # Factor 4: Contact concentration\n",
    "        if contact_suspicion:\n",
    "            top_contact_count = contact_suspicion.most_common(1)[0][1]\n",
    "            concentration_ratio = top_contact_count / suspicious_count\n",
    "            if concentration_ratio > 0.5:\n",
    "                factor_score = 25\n",
    "                risk_factors.append((f\"High concentration with single contact ({concentration_ratio*100:.1f}%)\", factor_score))\n",
    "            elif concentration_ratio > 0.3:\n",
    "                factor_score = 15\n",
    "                risk_factors.append((f\"Moderate concentration with contacts ({concentration_ratio*100:.1f}%)\", factor_score))\n",
    "            else:\n",
    "                factor_score = 5\n",
    "                risk_factors.append((\"Diverse suspicious contacts\", factor_score))\n",
    "        else:\n",
    "            factor_score = 0\n",
    "            risk_factors.append((\"No suspicious contacts identified\", factor_score))\n",
    "        \n",
    "        total_risk_score += factor_score\n",
    "        max_risk_score += 25\n",
    "        \n",
    "        # Calculate final risk score\n",
    "        final_risk_score = min((total_risk_score / max_risk_score) * 100, 100) if max_risk_score > 0 else 0\n",
    "        \n",
    "        print(f\"\\nüìä OVERALL RISK SCORE: {final_risk_score:.1f}/100\")\n",
    "        print(\"\\nRisk Factors Assessment:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Factor':<50} {'Score':<10} {'Max':<10}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for factor, score in risk_factors:\n",
    "            max_for_factor = 30 if \"volume\" in factor else 25 if \"high-risk\" in factor else 20 if \"late-night\" in factor else 25\n",
    "            print(f\"{factor:<50} {score:<10} {max_for_factor:<10}\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'TOTAL':<50} {total_risk_score:<10} {max_risk_score:<10}\")\n",
    "        \n",
    "        print(f\"\\nüîç RISK LEVEL ANALYSIS:\")\n",
    "        if final_risk_score < 20:\n",
    "            print(\"   ‚Ä¢ Risk Level: üü¢ LOW - Minimal suspicious activity\")\n",
    "            print(\"   ‚Ä¢ Forensic Priority: Low\")\n",
    "            print(\"   ‚Ä¢ Recommendation: Routine monitoring sufficient\")\n",
    "        elif final_risk_score < 50:\n",
    "            print(\"   ‚Ä¢ Risk Level: üü° MODERATE - Some concerning patterns\")\n",
    "            print(\"   ‚Ä¢ Forensic Priority: Medium\")\n",
    "            print(\"   ‚Ä¢ Recommendation: Increased monitoring recommended\")\n",
    "        elif final_risk_score < 75:\n",
    "            print(\"   ‚Ä¢ Risk Level: üü† HIGH - Significant suspicious activity\")\n",
    "            print(\"   ‚Ä¢ Forensic Priority: High\")\n",
    "            print(\"   ‚Ä¢ Recommendation: Immediate investigation recommended\")\n",
    "        else:\n",
    "            print(\"   ‚Ä¢ Risk Level: üî¥ CRITICAL - Extensive suspicious activity\")\n",
    "            print(\"   ‚Ä¢ Forensic Priority: Critical\")\n",
    "            print(\"   ‚Ä¢ Recommendation: Urgent investigation required\")\n",
    "        \n",
    "        # Additional suspicious patterns\n",
    "        detailed_flags = detect_suspicious_patterns_with_details(timeline, user_phone)\n",
    "        if detailed_flags:\n",
    "            print(f\"\\nüö® ADDITIONAL ANOMALIES DETECTED ({len(detailed_flags)}):\")\n",
    "            for flag, explanation in detailed_flags[:5]:\n",
    "                print(f\"   ‚ö† {flag}\")\n",
    "            if len(detailed_flags) > 5:\n",
    "                print(f\"   ‚Ä¢ ... and {len(detailed_flags) - 5} more anomalies\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No suspicious communications detected.\")\n",
    "        print(\"   ‚Ä¢ Risk Level: üü¢ LOW\")\n",
    "        print(\"   ‚Ä¢ Forensic Priority: Low\")\n",
    "        print(\"   ‚Ä¢ Recommendation: Normal monitoring sufficient\")\n",
    "\n",
    "    print(\"\")\n",
    "    \n",
    "    coordinated_patterns = detect_coordinated_communications(timeline, user_phone)\n",
    "    \n",
    "    if coordinated_patterns:\n",
    "        print(f\"\\nüö® **CRITICAL FINDING:** {len(coordinated_patterns):,} coordinated multi-channel patterns detected!\")\n",
    "        \n",
    "        # Count patterns by type\n",
    "        sms_call_email = sum(1 for p in coordinated_patterns if set(['SMS', 'CALL', 'EMAIL']).issubset(p['media_used']))\n",
    "        two_channel = len(coordinated_patterns) - sms_call_email\n",
    "        \n",
    "        print(f\"üìä **Pattern Distribution:**\")\n",
    "        print(f\"   üî¥ Full coordination (SMS‚ÜíCall‚ÜíEmail): {sms_call_email:,}\")\n",
    "        print(f\"   üü° Partial coordination (2 channels): {two_channel:,}\")\n",
    "        \n",
    "        # Update risk score based on coordinated patterns\n",
    "        if sms_call_email > 0:\n",
    "            print(f\"\\n‚ö†Ô∏è **RISK ELEVATION:** Full 3-channel coordination increases overall risk score by +20 points\")\n",
    "            # Adjust your risk scoring logic accordingly\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ No coordinated multi-channel patterns detected.\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXPORT FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def export_forensic_report(timeline, sms_data, call_data, email_data, user_phone=None):\n",
    "    \"\"\"Export comprehensive forensic report\"\"\"\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\" EXPORTING THE REPORT\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    if not timeline:\n",
    "        print(\" No data to export.\")\n",
    "        return\n",
    "    \n",
    "    report_content = []\n",
    "    report_content.append(\"-\" * 80)\n",
    "    report_content.append(\"DIGITAL INVESTIGATION REPORT\")\n",
    "    report_content.append(\"-\" * 80)\n",
    "    report_content.append(f\"Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    report_content.append(f\"Case Reference: DF-{datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
    "    \n",
    "    if user_phone:\n",
    "        report_content.append(f\"User's Phone Number: {user_phone}\")\n",
    "    \n",
    "    report_content.append(\"\")\n",
    "    \n",
    "    # Executive Summary\n",
    "    report_content.append(\"EXECUTIVE SUMMARY\")\n",
    "    report_content.append(\"-\" * 40)\n",
    "    total_events = len(sms_data) + len(call_data) + len(email_data)\n",
    "    report_content.append(f\"Total Events Analyzed: {total_events:,}\")\n",
    "    \n",
    "    if timeline:\n",
    "        days_span = max((timeline[-1]['timestamp'] - timeline[0]['timestamp']).days, 1)\n",
    "        report_content.append(f\"Analysis Period: {days_span} days\")\n",
    "        report_content.append(f\"Date Range: {timeline[0]['timestamp'].strftime('%Y-%m-%d')} to {timeline[-1]['timestamp'].strftime('%Y-%m-%d')}\")\n",
    "        report_content.append(f\"Average Daily Events: {total_events/days_span:.1f}\")\n",
    "    \n",
    "    # Data Sources\n",
    "    report_content.append(\"\")\n",
    "    report_content.append(\"DATA SOURCES\")\n",
    "    report_content.append(\"-\" * 40)\n",
    "    report_content.append(f\"SMS Messages: {len(sms_data):,}\")\n",
    "    report_content.append(f\"Phone Calls: {len(call_data):,}\")\n",
    "    report_content.append(f\"Emails: {len(email_data):,}\")\n",
    "    \n",
    "    # Contact Analysis\n",
    "    contact_counts, contact_details = extract_contacts(sms_data, call_data, email_data)\n",
    "    report_content.append(\"\")\n",
    "    report_content.append(\"CONTACT ANALYSIS\")\n",
    "    report_content.append(\"-\" * 40)\n",
    "    report_content.append(f\"Unique Contacts Identified: {len(contact_counts):,}\")\n",
    "    \n",
    "    if contact_counts:\n",
    "        top_contacts = contact_counts.most_common(20)\n",
    "        report_content.append(\"\")\n",
    "        report_content.append(\"TOP 20 CONTACTS BY INTERACTION VOLUME:\")\n",
    "        report_content.append(\"-\" * 80)\n",
    "        report_content.append(f\"{'Rank':<5} {'Contact':<40} {'Total':<8} {'SMS':<8} {'Calls':<8} {'Emails':<10}\")\n",
    "        report_content.append(\"-\" * 80)\n",
    "        \n",
    "        for i, (contact, total_count) in enumerate(top_contacts, 1):\n",
    "            details = contact_details.get(contact, {})\n",
    "            sms_count = details.get('sms_count', 0)\n",
    "            call_count = details.get('call_count', 0)\n",
    "            email_sent = details.get('sent_email_count', 0)\n",
    "            email_received = details.get('received_email_count', 0)\n",
    "            email_total = email_sent + email_received\n",
    "            \n",
    "            # Mark user's number\n",
    "            contact_display = contact\n",
    "            if user_phone and contact == user_phone:\n",
    "                contact_display = f\"{contact} (USER)\"\n",
    "            \n",
    "            contact_display = contact_display[:38] + \"...\" if len(contact_display) > 38 else contact_display\n",
    "            report_content.append(f\"{i:<5} {contact_display:<40} {total_count:<8} {sms_count:<8} {call_count:<8} {email_total:<10}\")\n",
    "    \n",
    "    # Suspicious Communications Analysis\n",
    "    suspicious_tags = ['SUSPICIOUS', 'FINANCIAL', 'URGENT', 'INTERNATIONAL', 'EXTENDED_COMM', 'SPAM']\n",
    "    suspicious_events = [e for e in timeline if e['forensic_tag'] in suspicious_tags]\n",
    "    \n",
    "    if suspicious_events:\n",
    "        report_content.append(\"\")\n",
    "        report_content.append(\"SUSPICIOUS COMMUNICATIONS ANALYSIS\")\n",
    "        report_content.append(\"-\" * 40)\n",
    "        report_content.append(f\"Total Suspicious Communications: {len(suspicious_events):,}\")\n",
    "        report_content.append(f\"Suspicious Rate: {len(suspicious_events)/len(timeline)*100:.1f}%\")\n",
    "        \n",
    "        # Group by category\n",
    "        category_counts = Counter(e['forensic_tag'] for e in suspicious_events)\n",
    "        report_content.append(\"\")\n",
    "        report_content.append(\"SUSPICIOUS COMMUNICATIONS BY CATEGORY:\")\n",
    "        for category, count in category_counts.most_common():\n",
    "            report_content.append(f\"  ‚Ä¢ {category}: {count:,} events\")\n",
    "        \n",
    "        # Top reasons\n",
    "        reason_counter = Counter()\n",
    "        for event in suspicious_events:\n",
    "            for reason in event.get('reasons', []):\n",
    "                reason_counter[reason] += 1\n",
    "        \n",
    "        if reason_counter:\n",
    "            report_content.append(\"\")\n",
    "            report_content.append(\"TOP REASONS FOR SUSPICIOUS CLASSIFICATION:\")\n",
    "            for reason, count in reason_counter.most_common(10):\n",
    "                report_content.append(f\"  ‚Ä¢ {reason}: {count:,} occurrences\")\n",
    "    \n",
    "    # Risk Assessment\n",
    "    report_content.append(\"\")\n",
    "    report_content.append(\"RISK ASSESSMENT\")\n",
    "    report_content.append(\"-\" * 40)\n",
    "    \n",
    "    flags = detect_suspicious_patterns_with_details(timeline, user_phone)\n",
    "    risk_score = min(len(flags) * 10, 100)\n",
    "    \n",
    "    report_content.append(f\"Overall Risk Score: {risk_score}/100\")\n",
    "    \n",
    "    if risk_score < 30:\n",
    "        report_content.append(\"Risk Level: LOW\")\n",
    "    elif risk_score < 70:\n",
    "        report_content.append(\"Risk Level: MEDIUM\")\n",
    "    else:\n",
    "        report_content.append(\"Risk Level: HIGH\")\n",
    "    \n",
    "    if flags:\n",
    "        report_content.append(\"\")\n",
    "        report_content.append(\"DETECTED RED FLAGS / ANOMALIES:\")\n",
    "        for flag, explanation in flags:\n",
    "            report_content.append(f\"  ‚ö† {flag}\")\n",
    "            report_content.append(f\"    {explanation}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    report_content.append(\"\")\n",
    "    report_content.append(\"INVESTIGATIVE RECOMMENDATIONS\")\n",
    "    report_content.append(\"-\" * 40)\n",
    "    \n",
    "    if flags:\n",
    "        report_content.append(\"1. Further investigation recommended for identified anomalies\")\n",
    "        report_content.append(\"2. Review communications with top suspicious contacts\")\n",
    "        report_content.append(\"3. Analyze late-night and rapid-fire communications\")\n",
    "        if any('financial' in flag[0].lower() for flag in flags):\n",
    "            report_content.append(\"4. Scrutinize financial-related communications\")\n",
    "        if any('international' in flag[0].lower() for flag in flags):\n",
    "            report_content.append(\"5. Review international communications\")\n",
    "        if suspicious_events:\n",
    "            report_content.append(\"6. Examine suspicious communications for potential illegal activities\")\n",
    "    else:\n",
    "        report_content.append(\"No significant anomalies detected. Standard monitoring recommended.\")\n",
    "    \n",
    "    # Save report\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    report_filename = f'forensic_report_{timestamp}.txt'\n",
    "    \n",
    "    with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(report_content))\n",
    "    \n",
    "    print(f\" Comprehensive forensic report saved to '{report_filename}'\")\n",
    "    \n",
    "    # Export additional files\n",
    "    export_timeline_csv(timeline)\n",
    "    export_contacts_csv(contact_counts, contact_details, user_phone)\n",
    "    export_summary_json(timeline, sms_data, call_data, email_data, contact_counts, contact_details, user_phone)\n",
    "\n",
    "def export_timeline_csv(timeline):\n",
    "    \"\"\"Export timeline to CSV\"\"\"\n",
    "    if not timeline:\n",
    "        return\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'forensic_timeline_{timestamp}.csv'\n",
    "    \n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "        fieldnames = ['timestamp', 'id', 'source', 'contact', 'type', 'content', 'forensic_tag', 'reasons']\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for event in timeline:\n",
    "            row = event.copy()\n",
    "            row['timestamp'] = event['timestamp'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "            row['reasons'] = '; '.join(event.get('reasons', []))\n",
    "            # Remove details field if present\n",
    "            if 'details' in row:\n",
    "                del row['details']\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    print(f\" Detailed timeline saved to '{filename}'\")\n",
    "\n",
    "def export_contacts_csv(contact_counts, contact_details, user_phone=None):\n",
    "    \"\"\"Export contacts to CSV\"\"\"\n",
    "    if not contact_counts:\n",
    "        return\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'forensic_contacts_{timestamp}.csv'\n",
    "    \n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Contact', 'Is_User', 'Total_Interactions', 'SMS_Count', 'Call_Count', \n",
    "                        'Email_Sent_Count', 'Email_Received_Count', 'Last_Contact_Date'])\n",
    "        \n",
    "        for contact, total_count in contact_counts.most_common():\n",
    "            details = contact_details.get(contact, {})\n",
    "            sms_count = details.get('sms_count', 0)\n",
    "            call_count = details.get('call_count', 0)\n",
    "            email_sent = details.get('sent_email_count', 0)\n",
    "            email_received = details.get('received_email_count', 0)\n",
    "            \n",
    "            # Check if this is user's number\n",
    "            is_user = 'Yes' if user_phone and contact == user_phone else 'No'\n",
    "            \n",
    "            # Get last contact date\n",
    "            last_dates = []\n",
    "            if 'last_contact' in details:\n",
    "                last_dates.append(details['last_contact'])\n",
    "            if 'last_call' in details:\n",
    "                last_dates.append(details['last_call'])\n",
    "            if 'last_email_sent' in details:\n",
    "                last_dates.append(details['last_email_sent'])\n",
    "            if 'last_email_received' in details:\n",
    "                last_dates.append(details['last_email_received'])\n",
    "            \n",
    "            last_contact = max(last_dates) if last_dates else 'Unknown'\n",
    "            if last_contact != 'Unknown':\n",
    "                last_contact = last_contact.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "            writer.writerow([contact, is_user, total_count, sms_count, call_count, \n",
    "                           email_sent, email_received, last_contact])\n",
    "    \n",
    "    print(f\" Contact analysis saved to '{filename}'\")\n",
    "\n",
    "def export_summary_json(timeline, sms_data, call_data, email_data, contact_counts, contact_details, user_phone=None):\n",
    "    \"\"\"Export summary data to JSON\"\"\"\n",
    "    if not timeline:\n",
    "        return\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'forensic_summary_{timestamp}.json'\n",
    "    \n",
    "    # Get suspicious events\n",
    "    suspicious_tags = ['SUSPICIOUS', 'FINANCIAL', 'URGENT', 'INTERNATIONAL', 'EXTENDED_COMM', 'SPAM']\n",
    "    suspicious_events = [e for e in timeline if e['forensic_tag'] in suspicious_tags]\n",
    "    \n",
    "    summary = {\n",
    "        'report_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'user_phone': user_phone,\n",
    "        'data_summary': {\n",
    "            'total_events': len(sms_data) + len(call_data) + len(email_data),\n",
    "            'sms_count': len(sms_data),\n",
    "            'call_count': len(call_data),\n",
    "            'email_count': len(email_data)\n",
    "        },\n",
    "        'timeline_summary': {\n",
    "            'start_date': timeline[0]['timestamp'].strftime('%Y-%m-%d %H:%M:%S') if timeline else None,\n",
    "            'end_date': timeline[-1]['timestamp'].strftime('%Y-%m-%d %H:%M:%S') if timeline else None,\n",
    "            'total_events': len(timeline)\n",
    "        },\n",
    "        'contact_summary': {\n",
    "            'unique_contacts': len(contact_counts),\n",
    "            'top_contacts': dict(contact_counts.most_common(10))\n",
    "        },\n",
    "        'suspicious_analysis': {\n",
    "            'total_suspicious': len(suspicious_events),\n",
    "            'suspicious_rate': len(suspicious_events) / len(timeline) if timeline else 0,\n",
    "            'categories': dict(Counter(e['forensic_tag'] for e in suspicious_events))\n",
    "        },\n",
    "        'risk_assessment': {\n",
    "            'flags': [flag for flag, _ in detect_suspicious_patterns_with_details(timeline, user_phone)],\n",
    "            'risk_score': min(len(detect_suspicious_patterns_with_details(timeline, user_phone)) * 10, 100)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\" Summary data saved to '{filename}'\")\n",
    "\n",
    "# ============================================================================\n",
    "# SIMPLIFIED VISUALIZATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def check_matplotlib():\n",
    "    \"\"\"Check if matplotlib is installed and import it\"\"\"\n",
    "    try:\n",
    "        import matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        return True, plt, sns\n",
    "    except ImportError:\n",
    "        print(\" Matplotlib/Seaborn not installed. Install with: pip install matplotlib seaborn\")\n",
    "        return False, None, None\n",
    "\n",
    "def create_jupyter_dashboard(timeline):\n",
    "    \"\"\"Create interactive dashboard in Jupyter\"\"\"\n",
    "    if not IN_JUPYTER:\n",
    "        return\n",
    "    \n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output\n",
    "    \n",
    "    # Create interactive controls\n",
    "    date_range = widgets.DateRangePicker(\n",
    "        description='Date Range',\n",
    "        value=(timeline[0]['timestamp'], timeline[-1]['timestamp'])\n",
    "    )\n",
    "    \n",
    "    risk_filter = widgets.Dropdown(\n",
    "        options=['All', 'High Risk', 'Medium Risk', 'Low Risk'],\n",
    "        value='All',\n",
    "        description='Risk Level:'\n",
    "    )\n",
    "    \n",
    "    def update_dashboard(change):\n",
    "        clear_output(wait=True)\n",
    "        # Filter and display based on selections\n",
    "        filtered = filter_timeline(timeline, date_range.value, risk_filter.value)\n",
    "        display_timeline_events(filtered)\n",
    "    \n",
    "    # Display controls\n",
    "    display(date_range, risk_filter)\n",
    "    date_range.observe(update_dashboard, names='value')\n",
    "    risk_filter.observe(update_dashboard, names='value')\n",
    "\n",
    "def create_simple_visualizations(timeline, sms_data, call_data, email_data):\n",
    "    \"\"\"Create simple visualizations\"\"\"\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\" CREATING VISUALIZATIONS\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    if not timeline:\n",
    "        print(\" No data available for visualization.\")\n",
    "        return\n",
    "    \n",
    "    # Check for matplotlib\n",
    "    matplotlib_available, plt, sns = check_matplotlib()\n",
    "    if not matplotlib_available:\n",
    "        return\n",
    "    \n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    \n",
    "    # Convert to DataFrame for easier manipulation\n",
    "    df = pd.DataFrame(timeline)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day_of_week'] = df['timestamp'].dt.day_name()\n",
    "    \n",
    "    # Get current timestamp for filenames\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    try:\n",
    "        # 1. Communication Source Distribution\n",
    "        print(\"\\n1. Communication Source Distribution...\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        source_counts = df['source'].value_counts()\n",
    "        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "        \n",
    "        # Pie chart\n",
    "        ax1.pie(source_counts.values, labels=source_counts.index, autopct='%1.1f%%',\n",
    "                colors=colors[:len(source_counts)], startangle=90)\n",
    "        ax1.set_title('Communication Source Distribution', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Bar chart\n",
    "        bars = ax2.bar(range(len(source_counts)), source_counts.values, \n",
    "                       color=colors[:len(source_counts)], alpha=0.8)\n",
    "        ax2.set_title('Communication Source Counts', fontsize=12, fontweight='bold')\n",
    "        ax2.set_xlabel('Source Type')\n",
    "        ax2.set_ylabel('Number of Events')\n",
    "        ax2.set_xticks(range(len(source_counts)))\n",
    "        ax2.set_xticklabels(source_counts.index, rotation=0)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{int(height):,}', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        plt.suptitle('Communication Sources Analysis', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'communication_sources_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"   Saved: communication_sources_{timestamp}.png\")\n",
    "        if IN_JUPYTER:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "        \n",
    "        # 2. Hourly Activity Pattern\n",
    "        print(\"\\n2. Hourly Activity Pattern...\")\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        hourly_counts = df['hour'].value_counts().sort_index()\n",
    "        bars = ax.bar(hourly_counts.index, hourly_counts.values, alpha=0.7, color='#4ECDC4')\n",
    "        \n",
    "        ax.set_title('Hourly Communication Activity', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Hour of Day', fontsize=12)\n",
    "        ax.set_ylabel('Number of Events', fontsize=12)\n",
    "        ax.set_xticks(range(0, 24, 2))\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'hourly_activity_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"   Saved: hourly_activity_{timestamp}.png\")\n",
    "        if IN_JUPYTER:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "        \n",
    "        # 3. Day of Week Analysis\n",
    "        print(\"\\n3. Day of Week Analysis...\")\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        day_counts = df['day_of_week'].value_counts().reindex(day_order)\n",
    "        \n",
    "        bars = ax.bar(range(len(day_counts)), day_counts.values, alpha=0.7, color='#FF6B6B')\n",
    "        ax.set_title('Activity by Day of Week', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Day of Week', fontsize=12)\n",
    "        ax.set_ylabel('Number of Events', fontsize=12)\n",
    "        ax.set_xticks(range(len(day_counts)))\n",
    "        ax.set_xticklabels([d[:3] for d in day_counts.index], rotation=0)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'day_of_week_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"   Saved: day_of_week_{timestamp}.png\")\n",
    "        if IN_JUPYTER:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "        \n",
    "        # 4. Forensic Category Distribution\n",
    "        print(\"\\n4. Forensic Category Distribution...\")\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        category_counts = df['forensic_tag'].value_counts()\n",
    "        \n",
    "        # Sort categories by count\n",
    "        categories_sorted = category_counts.sort_values(ascending=False)\n",
    "        \n",
    "        bars = ax.bar(range(len(categories_sorted)), categories_sorted.values, alpha=0.7, color='#45B7D1')\n",
    "        ax.set_title('Forensic Category Distribution', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Forensic Category', fontsize=12)\n",
    "        ax.set_ylabel('Number of Events', fontsize=12)\n",
    "        ax.set_xticks(range(len(categories_sorted)))\n",
    "        ax.set_xticklabels(categories_sorted.index, rotation=45, ha='right')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{int(height):,}', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'forensic_categories_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"   Saved: forensic_categories_{timestamp}.png\")\n",
    "        if IN_JUPYTER:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "        \n",
    "        print(f\"\\n All visualizations saved with timestamp: {timestamp}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Visualization error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN FUNCTION WITH SIMPLIFIED MENU\n",
    "# ============================================================================\n",
    "\n",
    "def main_jupyter():\n",
    "    \"\"\"Jupyter-optimized main function\"\"\"\n",
    "    if not IN_JUPYTER:\n",
    "        print(\"Not running in Jupyter. Use main() instead.\")\n",
    "        return\n",
    "    \n",
    "    from IPython.display import display, Markdown, HTML\n",
    "    \n",
    "    display(Markdown(\"# üîç Digital Forensics Analysis\"))\n",
    "    \n",
    "    # Load data\n",
    "    sms_data, call_data, email_data = data()\n",
    "    \n",
    "    if not any([sms_data, call_data, email_data]):\n",
    "        display(Markdown(\"## No data loaded\"))\n",
    "        return\n",
    "    \n",
    "    # Find user\n",
    "    user_phone = find_user_phone_number(sms_data, call_data)\n",
    "    \n",
    "    # Create timeline\n",
    "    timeline = create_timeline(sms_data, call_data, email_data, user_phone)\n",
    "    \n",
    "    # Display summary\n",
    "    display_summary_jupyter(timeline, user_phone)\n",
    "    \n",
    "    # Create dashboard\n",
    "    create_jupyter_dashboard(timeline)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function with simplified menu\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" MULTI SOURCE EVENT RECONSTRUCTION SYSTEM \")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        sms_data, call_data, email_data = data()\n",
    "        \n",
    "        if not sms_data and not call_data and not email_data:\n",
    "            print(\"\\n No data available. Exiting.\")\n",
    "            return\n",
    "        \n",
    "        # Find user's phone number from data\n",
    "        print(\"\\n\" + \"-\"*70)\n",
    "        print(\" USER IDENTIFICATION\")\n",
    "        print(\"-\"*70)\n",
    "        user_phone = find_user_phone_number(sms_data, call_data)\n",
    "        \n",
    "        if user_phone:\n",
    "            print(f\"\\n‚úÖ USER'S PHONE NUMBER IDENTIFIED: {user_phone}\")\n",
    "            print(f\"   Based on communication frequency and patterns\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è  User's phone number could not be identified from data.\")\n",
    "            print(\"   Analysis will continue with inferred relationships.\")\n",
    "            user_phone = None\n",
    "        \n",
    "        # Create timeline with user's phone number\n",
    "        print(\"\\n\" + \"-\"*70)\n",
    "        print(\" CREATING UNIFIED TIMELINE\")\n",
    "        print(\"-\"*70)\n",
    "        timeline = create_timeline(sms_data, call_data, email_data, user_phone)\n",
    "        \n",
    "        if not timeline:\n",
    "            print(\" Failed to create timeline. Exiting.\")\n",
    "            return\n",
    "        \n",
    "        # Display total events first\n",
    "        total_events = len(timeline)\n",
    "        print(f\"\\nüìä TOTAL COMMUNICATION EVENTS LOADED: {total_events:,}\")\n",
    "        \n",
    "        # Show contact summary\n",
    "        contact_counts, _ = extract_contacts(sms_data, call_data, email_data)\n",
    "        print(f\"üë• UNIQUE CONTACTS IDENTIFIED: {len(contact_counts):,}\")\n",
    "        \n",
    "        if user_phone:\n",
    "            print(f\"üì± USER'S PHONE NUMBER: {user_phone}\")\n",
    "        \n",
    "        # Initial analysis\n",
    "        print(\"\\n\" + \"-\"*70)\n",
    "        print(\" INITIAL ANALYSIS\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        # Count suspicious communications\n",
    "        suspicious_tags = ['SUSPICIOUS', 'FINANCIAL', 'URGENT', 'INTERNATIONAL', 'EXTENDED_COMM', 'SPAM']\n",
    "        suspicious_events = [e for e in timeline if e['forensic_tag'] in suspicious_tags]\n",
    "        print(f\"üîç SUSPICIOUS COMMUNICATIONS: {len(suspicious_events):,} ({len(suspicious_events)/total_events*100:.1f}%)\")\n",
    "        \n",
    "        # Show top suspicious reasons\n",
    "        if suspicious_events:\n",
    "            reason_counter = Counter()\n",
    "            for event in suspicious_events:\n",
    "                for reason in event.get('reasons', []):\n",
    "                    reason_counter[reason] += 1\n",
    "            \n",
    "            if reason_counter:\n",
    "                print(f\"   Top suspicious reasons:\")\n",
    "                for reason, count in reason_counter.most_common(3):\n",
    "                    print(f\"      ‚Ä¢ {reason}: {count:,}\")\n",
    "        \n",
    "        # Main menu loop\n",
    "        while True:\n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(\" MAIN MENU\")\n",
    "            print(\"=\"*70)\n",
    "            print(\"1. Timeline Events (Show all communications)\")\n",
    "            print(\"2. View Detailed Analysis\")\n",
    "            print(\"3. Suspicious Communications Analysis\")\n",
    "            print(\"4. Multi Channel Pattern Detection\")\n",
    "            print(\"5. Visualize Data Patterns\")\n",
    "            print(\"6. Export the Report\")\n",
    "            print(\"7. Exit\")\n",
    "            print(\"=\"*70)\n",
    "            \n",
    "            choice = input(\"\\nSelect option (1-7): \").strip()\n",
    "            \n",
    "            if choice == '1':\n",
    "                display_timeline_events(timeline, user_phone)\n",
    "            \n",
    "            elif choice == '2':\n",
    "                view_detailed_analysis(timeline, sms_data, call_data, email_data, user_phone)\n",
    "            \n",
    "            elif choice == '3':\n",
    "                suspicious_communications_analysis(timeline, user_phone)\n",
    "\n",
    "            elif choice == '4':\n",
    "                coordinated_patterns = detect_coordinated_communications(timeline, user_phone)\n",
    "                if coordinated_patterns:\n",
    "                 print(f\"\\nüö® **DETECTED {len(coordinated_patterns)} MULTI-CHANNEL PATTERNS**\")\n",
    "        \n",
    "                # Initialize counters\n",
    "                high_risk = []\n",
    "                medium_risk = []\n",
    "        \n",
    "                # Group by risk level\n",
    "                for pattern in coordinated_patterns:\n",
    "                  if pattern['risk_level'] == 'HIGH':\n",
    "                      high_risk.append(pattern)\n",
    "                  else:\n",
    "                      medium_risk.append(pattern)\n",
    "        \n",
    "                      print(f\"\\nüìä **RISK DISTRIBUTION:**\")\n",
    "                      print(f\"   üî¥ HIGH RISK: {len(high_risk):,} patterns (SMS ‚Üí Call ‚Üí Email)\")\n",
    "                      print(f\"   üü° MEDIUM RISK: {len(medium_risk):,} patterns (2-channel coordination)\")\n",
    "        \n",
    "                    # Show most suspicious pattern\n",
    "                      if high_risk:\n",
    "                             print(f\"\\n‚ö†Ô∏è **MOST SUSPICIOUS PATTERN DETECTED:**\")\n",
    "                             pattern = high_risk[0]\n",
    "                             print(f\"   Contact: {pattern['contact']}\")\n",
    "                             print(f\"   Time: {pattern['time_start'].strftime('%Y-%m-%d %H:%M')}\")\n",
    "                             print(f\"   Pattern: {' ‚Üí '.join([seq[0] for seq in pattern['sequence']])}\")\n",
    "            \n",
    "                      # Ask if user wants to see details\n",
    "                      show_details = input(\"\\nShow detailed pattern? (y/n): \").lower()\n",
    "                      if show_details == 'y':\n",
    "                         print(f\"\\nüìã **DETAILED SEQUENCE:**\")\n",
    "                         for i, (medium, direction, content) in enumerate(pattern['sequence'], 1):\n",
    "                             dir_text = \"User ‚Üí Contact\" if direction == 'FROM_USER' else \"Contact ‚Üí User\"\n",
    "                             print(f\"   {i}. {medium.upper()}: {dir_text}\")\n",
    "                             print(f\"      Content: {content}...\")\n",
    "                      else:\n",
    "                         print(f\"\\nüìã **MEDIUM RISK PATTERNS:**\")\n",
    "                         for i, pattern in enumerate(medium_risk[:3], 1):\n",
    "                             print(f\"\\n   {i}. Contact: {pattern['contact'][:30]}...\")\n",
    "                             print(f\"      Time: {pattern['time_start'].strftime('%H:%M')} - {pattern['time_end'].strftime('%H:%M')}\")\n",
    "                             print(f\"      Channels: {' ‚Üí '.join(pattern['media_used'])}\")\n",
    "            \n",
    "            elif choice == '5':\n",
    "                create_simple_visualizations(timeline, sms_data, call_data, email_data)\n",
    "            \n",
    "            elif choice == '6':\n",
    "                export_forensic_report(timeline, sms_data, call_data, email_data, user_phone)\n",
    "            \n",
    "            elif choice == '7':\n",
    "                print(\"\\n\" + \"=\"*70)\n",
    "                print(\" ANALYSIS COMPLETED\")\n",
    "                print(\"=\"*70)\n",
    "                print(\"Thank you for using the System.\")\n",
    "                break\n",
    "            \n",
    "            else:\n",
    "                print(\" Invalid option. Please select 1-6.\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n Analysis interrupted by user.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n Unexpected error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
